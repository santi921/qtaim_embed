{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from qtaim_embed.models.utils import load_graph_level_model_from_config\n",
    "from qtaim_embed.utils.tests import get_dataset_graph_level\n",
    "from qtaim_embed.data.dataloader import DataLoaderMoleculeGraphTask\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config\n",
    "from qtaim_embed.core.dataset import HeteroGraphGraphLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model_lightning_epoch=1006-val_mae=0.17.ckpt'\n",
      "'model_lightning_epoch=1160-val_mae=0.17.ckpt'\n",
      "'model_lightning_epoch=348-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=410-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=442-val_mae=0.10.ckpt'\n",
      "'model_lightning_epoch=469-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=478-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=479-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=562-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=578-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=612-val_mae=0.17.ckpt'\n",
      "'model_lightning_epoch=662-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=696-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=714-val_mae=0.17.ckpt'\n",
      "'model_lightning_epoch=760-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=832-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=859-val_mae=0.18.ckpt'\n",
      "'model_lightning_epoch=927-val_mae=0.18.ckpt'\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../data/saved_models/1119/qm8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::RESTORING MODEL FROM EXISTING FILE:::\n",
      "... > number of tasks: 4\n",
      ":::MODEL LOADED:::\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_config ={\n",
    "    \"model\": {\n",
    "        \"restore\": True,\n",
    "        \"restore_path\": \"../../../data/saved_models/1119/qm8/model_lightning_epoch=1160-val_mae=0.17.ckpt\"\n",
    "    }\n",
    "}\n",
    "model = load_graph_level_model_from_config(model_config[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNGraphPred(\n",
       "  (activation): ReLU()\n",
       "  (embedding): UnifySize(\n",
       "    (linears): ModuleDict(\n",
       "      (atom): Linear(in_features=13, out_features=100, bias=False)\n",
       "      (bond): Linear(in_features=9, out_features=100, bias=False)\n",
       "      (global): Linear(in_features=3, out_features=100, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (a2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (a2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (a2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=4, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=4, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=4, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (batch_norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout): SumPoolingThenCat()\n",
       "  (loss): ModuleList(\n",
       "    (0-3): 4 x MeanAbsoluteError()\n",
       "  )\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=204, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       "  (train_r2): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x R2Score()\n",
       "    )\n",
       "  )\n",
       "  (train_torch_l1): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x MeanAbsoluteError()\n",
       "    )\n",
       "  )\n",
       "  (train_torch_mse): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x MeanSquaredError()\n",
       "    )\n",
       "  )\n",
       "  (val_r2): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x R2Score()\n",
       "    )\n",
       "  )\n",
       "  (val_torch_l1): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x MeanAbsoluteError()\n",
       "    )\n",
       "  )\n",
       "  (val_torch_mse): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x MeanSquaredError()\n",
       "    )\n",
       "  )\n",
       "  (test_r2): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x R2Score()\n",
       "    )\n",
       "  )\n",
       "  (test_torch_l1): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x MeanAbsoluteError()\n",
       "    )\n",
       "  )\n",
       "  (test_torch_mse): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-3): 4 x MeanSquaredError()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to cpu\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/qm8_splits_1109/test_qm8_qtaim_1109_labelled.pkl\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../data/qm8_splits_1109/test_qm8_qtaim_1109_labelled.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['molecule', 'molecule_graph', 'bonds', 'ids', 'names',\n",
       "       'extra_feat_atom_Lagrangian_K', 'extra_feat_atom_Hamiltonian_K',\n",
       "       'extra_feat_atom_e_density', 'extra_feat_atom_lap_e_density',\n",
       "       'extra_feat_atom_e_loc_func', 'extra_feat_atom_ave_loc_ion_E',\n",
       "       'extra_feat_atom_delta_g_promolecular', 'extra_feat_atom_delta_g_hirsh',\n",
       "       'extra_feat_atom_esp_nuc', 'extra_feat_atom_esp_e',\n",
       "       'extra_feat_atom_esp_total', 'extra_feat_atom_grad_norm',\n",
       "       'extra_feat_atom_lap_norm', 'extra_feat_atom_eig_hess',\n",
       "       'extra_feat_atom_det_hessian', 'extra_feat_atom_ellip_e_dens',\n",
       "       'extra_feat_atom_eta', 'extra_feat_bond_Lagrangian_K',\n",
       "       'extra_feat_bond_Hamiltonian_K', 'extra_feat_bond_e_density',\n",
       "       'extra_feat_bond_lap_e_density', 'extra_feat_bond_e_loc_func',\n",
       "       'extra_feat_bond_ave_loc_ion_E', 'extra_feat_bond_delta_g_promolecular',\n",
       "       'extra_feat_bond_delta_g_hirsh', 'extra_feat_bond_esp_nuc',\n",
       "       'extra_feat_bond_esp_e', 'extra_feat_bond_esp_total',\n",
       "       'extra_feat_bond_grad_norm', 'extra_feat_bond_lap_norm',\n",
       "       'extra_feat_bond_eig_hess', 'extra_feat_bond_det_hessian',\n",
       "       'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta',\n",
       "       'extra_feat_bond_indices_qtaim', 'bonds_original', 'gdb9_index',\n",
       "       'E1-CC2', 'E2-CC2', 'f1-CC2', 'f2-CC2', 'E1-PBE0', 'E2-PBE0', 'f1-PBE0',\n",
       "       'f2-PBE0', 'E1-CAM', 'E2-CAM', 'f1-CAM', 'f2-CAM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "loc = \"../../../data/qm8_splits_1109/test_qm8_qtaim_1109_labelled.pkl\"\n",
    "df = pd.read_pickle(loc)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2178/2178 [00:00<00:00, 11320.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'C', 'N', 'H', 'F', 'O'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'bond_length']\n",
      "selected global keys ['E1-PBE0', 'E2-PBE0', 'f1-PBE0', 'f2-PBE0']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2178/2178 [00:03<00:00, 576.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['E1-PBE0', 'E2-PBE0', 'f1-PBE0', 'f2-PBE0']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_C', 'chemical_symbol_N', 'chemical_symbol_H', 'chemical_symbol_F', 'chemical_symbol_O', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2178/2178 [00:00<00:00, 35794.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [6.96288349e-01 1.98805120e-01 3.06581282e-02 1.70433033e-02\n",
      " 1.07412447e-02 2.45740653e-03 4.16173686e-04 2.36842463e-01\n",
      " 4.23506270e-02 3.57830099e-01 1.44669900e-03 5.46772952e-02\n",
      " 8.97849822e+00]\n",
      "std [0.59387727 0.36630958 0.14251552 0.10734544 0.08561477 0.04119837\n",
      " 0.01697929 0.32874357 0.16601699 0.34639074 0.03163356 0.18684166\n",
      " 5.64546124]\n",
      "mean [0.00000000e+00 4.11220402e-02 2.28632193e-02 1.43953603e-02\n",
      " 3.33421948e-03 5.55703246e-04 8.78703706e-01 6.88907803e-01\n",
      " 7.66750873e-02]\n",
      "std [0.         0.16374555 0.12379358 0.09884775 0.04795819 0.01961824\n",
      " 0.37055057 0.20704947 0.12734476]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [2.8203675  2.55656197 4.69623492]\n",
      "std [0.18514822 0.15003455 0.08921086]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([6.9629e-01, 1.9881e-01, 3.0658e-02, 1.7043e-02, 1.0741e-02, 2.4574e-03,\n",
      "        4.1617e-04, 2.3684e-01, 4.2351e-02, 3.5783e-01, 1.4467e-03, 5.4677e-02,\n",
      "        8.9785e+00]), 'bond': tensor([0.0000e+00, 4.1122e-02, 2.2863e-02, 1.4395e-02, 3.3342e-03, 5.5570e-04,\n",
      "        8.7870e-01, 6.8891e-01, 7.6675e-02]), 'global': tensor([2.8204, 2.5566, 4.6962])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([0.5939, 0.3663, 0.1425, 0.1073, 0.0856, 0.0412, 0.0170, 0.3287, 0.1660,\n",
      "        0.3464, 0.0316, 0.1868, 5.6455]), 'bond': tensor([0.0010, 0.1637, 0.1238, 0.0988, 0.0480, 0.0196, 0.3706, 0.2070, 0.1273]), 'global': tensor([0.1851, 0.1500, 0.0892])}\n",
      "... > Scaling targets\n",
      "mean [0.21776996 0.24318481 0.02275137 0.03234926]\n",
      "std [0.04699785 0.03946203 0.05718271 0.05674876]\n",
      "... > Scaling targets complete\n",
      "... > feature mean(s): \n",
      " {'global': tensor([0.2178, 0.2432, 0.0228, 0.0323])}\n",
      "... > feature std(s):  \n",
      " {'global': tensor([0.0470, 0.0395, 0.0572, 0.0567])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "qm8_loc = \"../../../data/qm8_splits_1109/test_qm8_qtaim_1109_labelled.pkl\"\n",
    "dataset = HeteroGraphGraphLabelDataset(\n",
    "    file=qm8_loc,\n",
    "    allowed_ring_size=[4, 5, 6, 7],\n",
    "    allowed_charges=None,\n",
    "    allowed_spins=None,\n",
    "    self_loop=True,\n",
    "    extra_keys={\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\n",
    "            \"extra_feat_bond_esp_total\",\n",
    "            \"extra_feat_bond_ellip_e_dens\",\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": [\"E1-PBE0\", \"E2-PBE0\", \"f1-PBE0\", \"f2-PBE0\"],\n",
    "    },\n",
    "    target_list=[\"E1-PBE0\", \"E2-PBE0\", \"f1-PBE0\", \"f2-PBE0\"],\n",
    "    extra_dataset_info={},\n",
    "    debug=False,\n",
    "    log_scale_features=True,\n",
    "    log_scale_targets=False,\n",
    "    standard_scale_features=True,\n",
    "    standard_scale_targets=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': 13, 'bond': 9, 'global': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def evaluate_manually(model, batch_graph, batch_label, scaler_list):\\n\\n    # batch_graph, batch_label = batch\\n\\n    # batch_label = batch_label[\"global\"]\\n    preds = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\\n\\n    preds_unscaled = deepcopy(preds.detach())\\n    labels_unscaled = deepcopy(batch_label)\\n    # print(\"preds unscaled\", preds_unscaled)  # * this looks good\\n    #print(\"labels unscaled\", labels_unscaled[\"global\"].shape)  # * this looks good\\n    for scaler in scaler_list:\\n        labels_unscaled = scaler.inverse_feats(labels_unscaled)\\n        preds_unscaled = scaler.inverse_feats({\"global\": preds_unscaled})\\n\\n    # reshape to (batch_size, n_tasks)\\n    \\n    preds_unscaled = preds_unscaled[\"global\"].view(-1, model.hparams.ntasks)\\n    labels_unscaled = labels_unscaled[\"global\"].view(-1, model.hparams.ntasks)\\n    \\n    # manually compute metrics\\n    #r2_eval = torchmetrics.R2Score()\\n    #mae_eval = torchmetrics.MeanAbsoluteError()\\n    #mse_eval = torchmetrics.MeanSquaredError(squared=False)\\n    r2_eval = MultioutputWrapper(\\n        torchmetrics.R2Score(), num_outputs=model.hparams.ntasks\\n    )\\n    mae_eval = MultioutputWrapper(\\n        torchmetrics.MeanAbsoluteError(), num_outputs=model.hparams.ntasks\\n    )\\n    mse_eval = MultioutputWrapper(\\n        torchmetrics.MeanSquaredError(squared=False),\\n        num_outputs=model.hparams.ntasks,\\n    )\\n    \\n\\n    r2_eval.update(preds_unscaled, labels_unscaled)\\n    mae_eval.update(preds_unscaled, labels_unscaled)\\n    mse_eval.update(preds_unscaled, labels_unscaled)\\n\\n    r2_val = r2_eval.compute()\\n    mae_val = mae_eval.compute()\\n    mse_val = mse_eval.compute()\\n\\n    return r2_val, mae_val, mse_val\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoaderMoleculeGraphTask(\n",
    "    dataset, batch_size=len(dataset.graphs), shuffle=False\n",
    ")\n",
    "\n",
    "batch_graph, batched_labels = next(iter(data_loader))\n",
    "\n",
    "from torchmetrics.wrappers import MultioutputWrapper\n",
    "import torchmetrics\n",
    "from copy import deepcopy\n",
    "\n",
    "\"\"\"def evaluate_manually(model, batch_graph, batch_label, scaler_list):\n",
    "\n",
    "    # batch_graph, batch_label = batch\n",
    "\n",
    "    # batch_label = batch_label[\"global\"]\n",
    "    preds = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "\n",
    "    preds_unscaled = deepcopy(preds.detach())\n",
    "    labels_unscaled = deepcopy(batch_label)\n",
    "    # print(\"preds unscaled\", preds_unscaled)  # * this looks good\n",
    "    #print(\"labels unscaled\", labels_unscaled[\"global\"].shape)  # * this looks good\n",
    "    for scaler in scaler_list:\n",
    "        labels_unscaled = scaler.inverse_feats(labels_unscaled)\n",
    "        preds_unscaled = scaler.inverse_feats({\"global\": preds_unscaled})\n",
    "\n",
    "    # reshape to (batch_size, n_tasks)\n",
    "    \n",
    "    preds_unscaled = preds_unscaled[\"global\"].view(-1, model.hparams.ntasks)\n",
    "    labels_unscaled = labels_unscaled[\"global\"].view(-1, model.hparams.ntasks)\n",
    "    \n",
    "    # manually compute metrics\n",
    "    #r2_eval = torchmetrics.R2Score()\n",
    "    #mae_eval = torchmetrics.MeanAbsoluteError()\n",
    "    #mse_eval = torchmetrics.MeanSquaredError(squared=False)\n",
    "    r2_eval = MultioutputWrapper(\n",
    "        torchmetrics.R2Score(), num_outputs=model.hparams.ntasks\n",
    "    )\n",
    "    mae_eval = MultioutputWrapper(\n",
    "        torchmetrics.MeanAbsoluteError(), num_outputs=model.hparams.ntasks\n",
    "    )\n",
    "    mse_eval = MultioutputWrapper(\n",
    "        torchmetrics.MeanSquaredError(squared=False),\n",
    "        num_outputs=model.hparams.ntasks,\n",
    "    )\n",
    "    \n",
    "\n",
    "    r2_eval.update(preds_unscaled, labels_unscaled)\n",
    "    mae_eval.update(preds_unscaled, labels_unscaled)\n",
    "    mse_eval.update(preds_unscaled, labels_unscaled)\n",
    "\n",
    "    r2_val = r2_eval.compute()\n",
    "    mae_val = mae_eval.compute()\n",
    "    mse_val = mse_eval.compute()\n",
    "\n",
    "    return r2_val, mae_val, mse_val\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_pre tensor([0.8123, 0.7346, 0.2341, 0.0152])\n",
      "mae tensor([0.0142, 0.0148, 0.0202, 0.0312])\n",
      "mse tensor([0.0204, 0.0203, 0.0500, 0.0563])\n"
     ]
    }
   ],
   "source": [
    "r2_pre, mae, mse = model.evaluate_manually(batch_graph, batched_labels, dataset.label_scalers)\n",
    "print(\"r2_pre\", r2_pre)\n",
    "print(\"mae\", mae)\n",
    "print(\"mse\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "#r2_pre tensor([0.6515, 0.6175, 0.3415, 0.2957])\n",
    "#mae tensor([0.0201, 0.0179, 0.0165, 0.0266])\n",
    "#mse tensor([0.0283, 0.0250, 0.0409, 0.0509])\n",
    "\n",
    "# testing\n",
    "#r2_pre tensor([0.6003, 0.5739, 0.3209, 0.1669])\n",
    "#mae tensor([0.0213, 0.0188, 0.0203, 0.0286])\n",
    "#mse tensor([0.0297, 0.0258, 0.0471, 0.0518])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
