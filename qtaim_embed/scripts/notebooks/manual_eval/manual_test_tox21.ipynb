{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from qtaim_embed.models.utils import load_graph_level_model_from_config\n",
    "from qtaim_embed.data.dataloader import DataLoaderMoleculeGraphTask\n",
    "from qtaim_embed.core.dataset import HeteroGraphGraphLabelClassifierDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model_lightning_epoch=111-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=143-val_loss=4.45.ckpt'\n",
      "'model_lightning_epoch=255-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=322-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=399-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=42-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=46-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=65-val_loss=4.46.ckpt'\n",
      "'model_lightning_epoch=68-val_loss=4.47.ckpt'\n",
      "'model_lightning_epoch=68-val_loss=4.47-v1.ckpt'\n",
      "'model_lightning_epoch=74-val_loss=4.46.ckpt'\n",
      "'model_lightning_epoch=80-val_loss=4.46.ckpt'\n",
      "'model_lightning_epoch=84-val_loss=4.47.ckpt'\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../data/saved_models/1119/tox21/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::RESTORING MODEL FROM EXISTING FILE:::\n",
      "... > number of tasks: 12\n",
      "... > number of tasks: 12\n",
      ":::MODEL LOADED:::\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_config ={\n",
    "    \"model\": {\n",
    "        \"restore\": True,\n",
    "        \"restore_path\": \"../../../data/saved_models/1119/tox21/model_lightning_epoch=143-val_loss=4.45.ckpt\"\n",
    "    }\n",
    "}\n",
    "model = load_graph_level_model_from_config(model_config[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNGraphPredClassifier(\n",
       "  (activation): ReLU()\n",
       "  (embedding): UnifySize(\n",
       "    (linears): ModuleDict(\n",
       "      (atom): Linear(in_features=32, out_features=100, bias=False)\n",
       "      (bond): Linear(in_features=10, out_features=100, bias=False)\n",
       "      (global): Linear(in_features=3, out_features=100, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conv_layers): ModuleList(\n",
       "    (0-2): 3 x HeteroGraphConv(\n",
       "      (mods): ModuleDict(\n",
       "        (a2b): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (b2a): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (a2g): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (g2a): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (b2g): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (g2b): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (a2a): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (b2b): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (g2g): GraphConvDropoutBatch(\n",
       "          (graph_conv): GraphConv(\n",
       "            in=100, out=100, normalization=both\n",
       "            (_activation): ReLU()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout): SumPoolingThenCat()\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=300, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MultitaskLinearSoftmax(\n",
       "      (layers_dict): ModuleDict(\n",
       "        (0): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (6): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (7): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (8): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (9): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (10): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "        (11): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "          (1): Softmax(dim=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (train_auroc): MultilabelAUROC()\n",
       "  (train_acc): MultilabelAccuracy()\n",
       "  (train_f1): MultilabelF1Score()\n",
       "  (val_auroc): MultilabelAUROC()\n",
       "  (val_acc): MultilabelAccuracy()\n",
       "  (val_f1): MultilabelF1Score()\n",
       "  (test_auroc): MultilabelAUROC()\n",
       "  (test_acc): MultilabelAccuracy()\n",
       "  (test_f1): MultilabelF1Score()\n",
       "  (loss): ModuleList(\n",
       "    (0-11): 12 x CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to cpu\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/splits_1101/test_tox21_qtaim_1026_labelled.pkl\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../data/splits_1101/test_tox21_qtaim_1026_labelled.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:00<00:00, 5416.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'Ca', 'F', 'P', 'Cu', 'C', 'Fe', 'Ti', 'B', 'N', 'Al', 'V', 'H', 'Si', 'Ge', 'As', 'Se', 'Ni', 'S', 'Zn', 'O', 'Cl', 'Br', 'Cr', 'Na'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta', 'bond_length']\n",
      "selected global keys ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:02<00:00, 324.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'chemical_symbol_Ca', 'chemical_symbol_F', 'chemical_symbol_P', 'chemical_symbol_Cu', 'chemical_symbol_C', 'chemical_symbol_Fe', 'chemical_symbol_Ti', 'chemical_symbol_B', 'chemical_symbol_N', 'chemical_symbol_Al', 'chemical_symbol_V', 'chemical_symbol_H', 'chemical_symbol_Si', 'chemical_symbol_Ge', 'chemical_symbol_As', 'chemical_symbol_Se', 'chemical_symbol_Ni', 'chemical_symbol_S', 'chemical_symbol_Zn', 'chemical_symbol_O', 'chemical_symbol_Cl', 'chemical_symbol_Br', 'chemical_symbol_Cr', 'chemical_symbol_Na', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'bond_length', 'extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "744it [00:00, 17691.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > number of categories for each label: \n",
      "...... > label  NR-AR :  2 with distribution:  [719, 25]\n",
      "...... > label  NR-AR-LBD :  2 with distribution:  [727, 17]\n",
      "...... > label  NR-AhR :  2 with distribution:  [672, 72]\n",
      "...... > label  NR-Aromatase :  2 with distribution:  [716, 28]\n",
      "...... > label  NR-ER :  2 with distribution:  [680, 64]\n",
      "...... > label  NR-ER-LBD :  2 with distribution:  [715, 29]\n",
      "...... > label  NR-PPAR-gamma :  2 with distribution:  [729, 15]\n",
      "...... > label  SR-ARE :  2 with distribution:  [661, 83]\n",
      "...... > label  SR-ATAD5 :  2 with distribution:  [729, 15]\n",
      "...... > label  SR-HSE :  2 with distribution:  [713, 31]\n",
      "...... > label  SR-MMP :  2 with distribution:  [654, 90]\n",
      "...... > label  SR-p53 :  2 with distribution:  [706, 38]\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "number of graphs imputed:  430\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [7.84704601e-01 2.45471391e-01 3.81892213e-02 6.15128397e-04\n",
      " 8.25297267e-03 1.90946107e-02 1.02265096e-02 0.00000000e+00\n",
      " 3.53698829e-03 6.15128397e-04 0.00000000e+00 2.59276620e-01\n",
      " 0.00000000e+00 0.00000000e+00 2.56303499e-05 2.64761514e-02\n",
      " 2.56303499e-05 0.00000000e+00 3.39499615e-01 2.05042799e-04\n",
      " 0.00000000e+00 7.68910497e-05 7.68910497e-05 0.00000000e+00\n",
      " 4.45968088e-03 0.00000000e+00 5.22090227e-02 6.15128397e-03\n",
      " 5.12606998e-04 0.00000000e+00 0.00000000e+00 8.71441072e+00]\n",
      "std [6.28869071e-01 3.96705902e-01 1.58152883e-01 2.06396738e-02\n",
      " 7.51825325e-02 1.13449422e-01 8.35697004e-02 0.00000000e+00\n",
      " 4.93876825e-02 2.06396738e-02 0.00000000e+00 3.35399005e-01\n",
      " 0.00000000e+00 0.00000000e+00 4.21484850e-03 1.32856626e-01\n",
      " 4.21484850e-03 0.00000000e+00 3.46501390e-01 1.19198488e-02\n",
      " 0.00000000e+00 7.30006179e-03 7.30006179e-03 0.00000000e+00\n",
      " 5.54195497e-02 0.00000000e+00 1.82928278e-01 6.50069755e-02\n",
      " 1.88427527e-02 0.00000000e+00 0.00000000e+00 5.79472678e+00]\n",
      "Standard deviation for feature 7 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 10 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 12 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 13 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 17 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 20 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 23 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 25 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 29 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 30 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [0.00000000e+00 4.41502510e-02 7.05463398e-04 9.52375587e-03\n",
      " 2.23984629e-02 1.18165119e-02 9.53379425e-01 6.36812806e-01\n",
      " 1.13504519e-01 8.53023932e-01]\n",
      "std [0.         0.16927309 0.02210186 0.08068868 0.12257137 0.0897271\n",
      " 0.37668269 0.27257048 0.22146808 0.30183131]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [3.46954676 3.30484108 5.47169801]\n",
      "std [0.54971246 0.6037215  0.51976442]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([7.8470e-01, 2.4547e-01, 3.8189e-02, 6.1513e-04, 8.2530e-03, 1.9095e-02,\n",
      "        1.0227e-02, 0.0000e+00, 3.5370e-03, 6.1513e-04, 0.0000e+00, 2.5928e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.5630e-05, 2.6476e-02, 2.5630e-05, 0.0000e+00,\n",
      "        3.3950e-01, 2.0504e-04, 0.0000e+00, 7.6891e-05, 7.6891e-05, 0.0000e+00,\n",
      "        4.4597e-03, 0.0000e+00, 5.2209e-02, 6.1513e-03, 5.1261e-04, 0.0000e+00,\n",
      "        0.0000e+00, 8.7144e+00]), 'bond': tensor([0.0000e+00, 4.4150e-02, 7.0546e-04, 9.5238e-03, 2.2398e-02, 1.1817e-02,\n",
      "        9.5338e-01, 6.3681e-01, 1.1350e-01, 8.5302e-01]), 'global': tensor([3.4695, 3.3048, 5.4717])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([6.2887e-01, 3.9671e-01, 1.5815e-01, 2.0640e-02, 7.5183e-02, 1.1345e-01,\n",
      "        8.3570e-02, 1.0000e-03, 4.9388e-02, 2.0640e-02, 1.0000e-03, 3.3540e-01,\n",
      "        1.0000e-03, 1.0000e-03, 4.2148e-03, 1.3286e-01, 4.2148e-03, 1.0000e-03,\n",
      "        3.4650e-01, 1.1920e-02, 1.0000e-03, 7.3001e-03, 7.3001e-03, 1.0000e-03,\n",
      "        5.5420e-02, 1.0000e-03, 1.8293e-01, 6.5007e-02, 1.8843e-02, 1.0000e-03,\n",
      "        1.0000e-03, 5.7947e+00]), 'bond': tensor([0.0010, 0.1693, 0.0221, 0.0807, 0.1226, 0.0897, 0.3767, 0.2726, 0.2215,\n",
      "        0.3018]), 'global': tensor([0.5497, 0.6037, 0.5198])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "qtaim_keys = {\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\n",
    "            \"extra_feat_bond_esp_total\",\n",
    "            \"extra_feat_bond_ellip_e_dens\",\n",
    "            \"extra_feat_bond_eta\",\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": ['NR-AR', 'NR-AR-LBD',\n",
    "       'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma',\n",
    "       'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'],\n",
    "}\n",
    "\n",
    "base_dict = {\n",
    "        \"atom\": [],\n",
    "        \"bond\": [\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": ['NR-AR', 'NR-AR-LBD',\n",
    "       'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma',\n",
    "       'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'],\n",
    "}\n",
    "\n",
    "tox21_loc = \"../../../data/splits_1101/test_tox21_qtaim_1026_labelled.pkl\"\n",
    "dataset = HeteroGraphGraphLabelClassifierDataset(\n",
    "    file=tox21_loc,\n",
    "    allowed_ring_size=[3, 4, 5, 6],\n",
    "    allowed_charges=None,\n",
    "    allowed_spins=None,\n",
    "    self_loop=True,\n",
    "    extra_keys=qtaim_keys,\n",
    "    target_list=['NR-AR', 'NR-AR-LBD',\n",
    "       'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma',\n",
    "       'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'],\n",
    "    extra_dataset_info={},\n",
    "    debug=False,\n",
    "    impute=True,\n",
    "    element_set={'Fe', 'H', 'Cu', 'Cr', 'Ge', 'Na', 'P', 'N', 'C', 'Br', 'S', 'V', 'F', 'Se', 'B', 'Cl', 'Zn', 'Ti', 'O', 'Si', 'Ni', 'Ca', 'Al', 'As'},\n",
    "    log_scale_features=True,\n",
    "    standard_scale_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': 32, 'bond': 10, 'global': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': ['total_degree',\n",
       "  'total_H',\n",
       "  'is_in_ring',\n",
       "  'ring_size_3',\n",
       "  'ring_size_4',\n",
       "  'ring_size_5',\n",
       "  'ring_size_6',\n",
       "  'chemical_symbol_Ca',\n",
       "  'chemical_symbol_F',\n",
       "  'chemical_symbol_P',\n",
       "  'chemical_symbol_Cu',\n",
       "  'chemical_symbol_C',\n",
       "  'chemical_symbol_Fe',\n",
       "  'chemical_symbol_Ti',\n",
       "  'chemical_symbol_B',\n",
       "  'chemical_symbol_N',\n",
       "  'chemical_symbol_Al',\n",
       "  'chemical_symbol_V',\n",
       "  'chemical_symbol_H',\n",
       "  'chemical_symbol_Si',\n",
       "  'chemical_symbol_Ge',\n",
       "  'chemical_symbol_As',\n",
       "  'chemical_symbol_Se',\n",
       "  'chemical_symbol_Ni',\n",
       "  'chemical_symbol_S',\n",
       "  'chemical_symbol_Zn',\n",
       "  'chemical_symbol_O',\n",
       "  'chemical_symbol_Cl',\n",
       "  'chemical_symbol_Br',\n",
       "  'chemical_symbol_Cr',\n",
       "  'chemical_symbol_Na',\n",
       "  'extra_feat_atom_esp_total'],\n",
       " 'bond': ['metal bond',\n",
       "  'ring inclusion',\n",
       "  'ring size_3',\n",
       "  'ring size_4',\n",
       "  'ring size_5',\n",
       "  'ring size_6',\n",
       "  'bond_length',\n",
       "  'extra_feat_bond_esp_total',\n",
       "  'extra_feat_bond_ellip_e_dens',\n",
       "  'extra_feat_bond_eta'],\n",
       " 'global': ['num atoms', 'num bonds', 'molecule weight']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.exclude_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744, 12])\n",
      "torch.Size([744, 12])\n",
      "task:  12\n",
      "--------------------------------------------------\n",
      "Prior to training:\t acc: 0.9420\t auroc: 0.9567\t f1: 0.9420\n",
      "acc manual:  tensor([0.9691, 0.9798, 0.9005, 0.9624, 0.8965, 0.9597, 0.9798, 0.8911, 0.9798,\n",
      "        0.9570, 0.8844, 0.9435])\n",
      "auroc manual:  [tensor(0.9787), tensor(0.9842), tensor(0.9531), tensor(0.9607), tensor(0.9242), tensor(0.9674), tensor(0.9807), tensor(0.9008), tensor(0.9839), tensor(0.9639), tensor(0.9249), tensor(0.9572)]\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.wrappers import MultioutputWrapper\n",
    "import torchmetrics\n",
    "\n",
    "data_loader = DataLoaderMoleculeGraphTask(\n",
    "    dataset, batch_size=len(dataset.graphs), shuffle=False\n",
    ")\n",
    "\n",
    "def evaluate_manually(model, batch_graph, batch_label):\n",
    "    \"\"\"\n",
    "    Evaluate a set of data manually\n",
    "    Takes\n",
    "        feats: dict, dictionary of batched features\n",
    "        scaler_list: list, list of scalers\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    labels = batch_label[\"global\"]\n",
    "    labels_one_hot = torch.argmax(labels, axis=2)\n",
    "    logits = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "    logits_one_hot = torch.argmax(logits, axis=-1)\n",
    "    print(logits_one_hot.shape)\n",
    "    print(labels_one_hot.shape)\n",
    "    print(\"task: \", model.hparams.ntasks)\n",
    "\n",
    "    if model.hparams.ntasks > 1:\n",
    "        # create a dict of softmax layers\n",
    "        test_auroc = torchmetrics.classification.MultilabelAUROC(\n",
    "            num_labels=model.hparams.ntasks\n",
    "        )\n",
    "        test_acc = torchmetrics.classification.MultilabelAccuracy(\n",
    "            num_labels=model.hparams.ntasks\n",
    "        )\n",
    "        test_f1 = torchmetrics.classification.MultilabelF1Score(\n",
    "            num_labels=model.hparams.ntasks\n",
    "        )\n",
    "\n",
    "        test_acc.update(logits, labels)\n",
    "        test_f1.update(logits, labels)\n",
    "        test_auroc.update(logits, labels)\n",
    "\n",
    "        # compute accuracy manually for each task outside of torchmetrics\n",
    "        acc_manual = []\n",
    "        for i in range(model.hparams.ntasks):\n",
    "            acc_manual.append(\n",
    "                torch.sum(logits_one_hot[:, i] == labels_one_hot[:, i])\n",
    "                / len(labels_one_hot[:, i])\n",
    "            )\n",
    "        acc_manual = torch.stack(acc_manual)\n",
    "\n",
    "        auroc_manual = []\n",
    "        for i in range(model.hparams.ntasks):\n",
    "            auroc_manual.append(\n",
    "                torchmetrics.functional.auroc(\n",
    "                    logits[:, i], labels[:, i], num_classes=2, task=\"binary\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        labels_one_hot = labels_one_hot.reshape(-1)\n",
    "    \n",
    "        test_auroc = torchmetrics.classification.AUROC(\n",
    "            num_labels=1, task=\"binary\"\n",
    "        )\n",
    "        test_f1 = torchmetrics.F1Score(num_classes=2, task=\"binary\")\n",
    "        test_acc = torchmetrics.Accuracy(num_classes=2, task=\"binary\")\n",
    "\n",
    "        test_f1.update(logits_one_hot, labels_one_hot)\n",
    "        test_auroc.update(logits_one_hot, labels_one_hot)\n",
    "        test_acc.update(logits_one_hot, labels_one_hot)\n",
    "        \n",
    "    auroc = test_auroc.compute()\n",
    "    acc = test_acc.compute()\n",
    "    f1 = test_f1.compute()\n",
    "        \n",
    "    return acc, acc_manual, auroc, auroc_manual, f1\n",
    "\n",
    "batch_graph, batched_labels = next(iter(data_loader))\n",
    "acc, acc_manual, auroc, auroc_manual, f1 = evaluate_manually(\n",
    "    model, batch_graph, batched_labels\n",
    ")\n",
    "print(\"-\" * 50)\n",
    "print(\n",
    "    \"Prior to training:\\t acc: {:.4f}\\t auroc: {:.4f}\\t f1: {:.4f}\".format(\n",
    "        acc, auroc, f1\n",
    "    )\n",
    ")\n",
    "print(\"acc manual: \", acc_manual)\n",
    "print(\"auroc manual: \", auroc_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808198570891312\n",
      "0.9894697254606996\n",
      "0.9503572771718691\n",
      "0.9823241820233171\n",
      "0.9217751034223393\n",
      "0.978939450921399\n",
      "0.9905979691613388\n",
      "0.9386987589319293\n",
      "0.9958631064309891\n",
      "0.9838285069575028\n",
      "0.9548702519744264\n",
      "0.9909740503948853\n"
     ]
    }
   ],
   "source": [
    "# distro for training set, no impute\n",
    "print(2608/(2608+51)) \n",
    "print(2631/(2631+28))\n",
    "print(2527/(2527+132))\n",
    "print(2612/(2612+47))\n",
    "print(2451/(2451+208))\n",
    "print(2603/(2603+56))\n",
    "print(2634/(2634+25))\n",
    "print(2496/(2496+163))\n",
    "print(2648/(2648+11))\n",
    "print(2616/(2616+43))\n",
    "print(2539/(2539+120))\n",
    "print(2635/(2635+24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9567)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
