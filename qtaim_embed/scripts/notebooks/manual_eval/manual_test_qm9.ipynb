{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from qtaim_embed.models.utils import load_graph_level_model_from_config\n",
    "from qtaim_embed.utils.tests import get_dataset_graph_level\n",
    "from qtaim_embed.data.dataloader import DataLoaderMoleculeGraphTask\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config\n",
    "from qtaim_embed.core.dataset import HeteroGraphGraphLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model_lightning_epoch=1268-val_mae=0.11.ckpt'\n",
      "'model_lightning_epoch=209-val_mae=0.11.ckpt'\n",
      "'model_lightning_epoch=310-val_mae=0.10.ckpt'\n",
      "'model_lightning_epoch=441-val_mae=0.11.ckpt'\n",
      "'model_lightning_epoch=467-val_mae=0.11.ckpt'\n",
      "'model_lightning_epoch=478-val_mae=0.10.ckpt'\n",
      "'model_lightning_epoch=492-val_mae=0.09.ckpt'\n",
      "'model_lightning_epoch=517-val_mae=0.11.ckpt'\n",
      "'model_lightning_epoch=606-val_mae=0.10.ckpt'\n",
      "'model_lightning_epoch=702-val_mae=0.11.ckpt'\n",
      "'model_lightning_epoch=818-val_mae=0.08.ckpt'\n",
      "'model_lightning_epoch=973-val_mae=0.09.ckpt'\n",
      "'model_lightning_epoch=975-val_mae=0.11.ckpt'\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../data/saved_models/1119/qm9/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::RESTORING MODEL FROM EXISTING FILE:::\n",
      "... > number of tasks: 10\n",
      ":::MODEL LOADED:::\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_config ={\n",
    "    \"model\": {\n",
    "        \"restore\": True,\n",
    "        \"restore_path\": \"../../../data/saved_models/1119/qm9/model_lightning_epoch=818-val_mae=0.08.ckpt\"\n",
    "    }\n",
    "}\n",
    "model = load_graph_level_model_from_config(model_config[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNGraphPred(\n",
       "  (activation): ReLU()\n",
       "  (embedding): UnifySize(\n",
       "    (linears): ModuleDict(\n",
       "      (atom): Linear(in_features=14, out_features=100, bias=False)\n",
       "      (bond): Linear(in_features=11, out_features=100, bias=False)\n",
       "      (global): Linear(in_features=3, out_features=100, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conv_layers): ModuleList(\n",
       "    (0-1): 2 x ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (a2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (a2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (a2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=10, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=10, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (a2a): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (b2b): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=100, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (g2g): GraphConvDropoutBatch(\n",
       "              (graph_conv): GraphConv(\n",
       "                in=100, out=10, normalization=both\n",
       "                (_activation): ReLU()\n",
       "              )\n",
       "              (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout): Set2SetThenCat(\n",
       "    (layers): ModuleDict(\n",
       "      (atom): Set2Set(\n",
       "        n_iters=5\n",
       "        (lstm): LSTM(200, 100, num_layers=3)\n",
       "      )\n",
       "      (bond): Set2Set(\n",
       "        n_iters=5\n",
       "        (lstm): LSTM(200, 100, num_layers=3)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss): ModuleList(\n",
       "    (0-9): 10 x MeanSquaredError()\n",
       "  )\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=410, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       "  (train_r2): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x R2Score()\n",
       "    )\n",
       "  )\n",
       "  (train_torch_l1): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x MeanAbsoluteError()\n",
       "    )\n",
       "  )\n",
       "  (train_torch_mse): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x MeanSquaredError()\n",
       "    )\n",
       "  )\n",
       "  (val_r2): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x R2Score()\n",
       "    )\n",
       "  )\n",
       "  (val_torch_l1): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x MeanAbsoluteError()\n",
       "    )\n",
       "  )\n",
       "  (val_torch_mse): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x MeanSquaredError()\n",
       "    )\n",
       "  )\n",
       "  (test_r2): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x R2Score()\n",
       "    )\n",
       "  )\n",
       "  (test_torch_l1): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x MeanAbsoluteError()\n",
       "    )\n",
       "  )\n",
       "  (test_torch_mse): MultioutputWrapper(\n",
       "    (metrics): ModuleList(\n",
       "      (0-9): 10 x MeanSquaredError()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to cpu\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/splits_1101/test_qm9_qtaim_1025_labelled.pkl\n"
     ]
    }
   ],
   "source": [
    "! ls ../../../data/splits_1101/test_qm9_qtaim_1025_labelled.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13385/13385 [00:01<00:00, 9119.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'C', 'N', 'F', 'O', 'H'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta', 'bond_length']\n",
      "selected global keys ['u0', 'mu', 'A', 'B', 'C', 'r2', 'homo', 'lumo', 'gap', 'zpve']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13385/13385 [00:24<00:00, 548.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['u0', 'mu', 'A', 'B', 'C', 'r2', 'homo', 'lumo', 'gap', 'zpve']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_C', 'chemical_symbol_N', 'chemical_symbol_F', 'chemical_symbol_O', 'chemical_symbol_H', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13385/13385 [00:00<00:00, 33294.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [7.16472429e-01 2.10014239e-01 4.41537971e-02 6.12078483e-03\n",
      " 1.66736634e-02 1.53307793e-02 5.10929920e-03 9.19270414e-04\n",
      " 2.43572079e-01 4.04306079e-02 1.07200186e-03 5.42023737e-02\n",
      " 3.53870120e-01 8.24627475e+00]\n",
      "std [0.60361099 0.37272858 0.16927942 0.06484706 0.10620401 0.10193848\n",
      " 0.05929074 0.02522587 0.3309138  0.16244915 0.02723795 0.18609762\n",
      " 0.34649677 5.54945037]\n",
      "mean [0.         0.05742644 0.00796355 0.02181642 0.02000517 0.00673012\n",
      " 0.00132232 0.90044921 0.68194622 0.08337147 0.89935398]\n",
      "std [0.         0.19106852 0.07386807 0.12102079 0.11604448 0.06796817\n",
      " 0.03024588 0.37210301 0.22738615 0.14920395 0.23739863]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [2.93044471 2.69820193 4.81651674]\n",
      "std [0.16002986 0.13290438 0.06586737]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([7.1647e-01, 2.1001e-01, 4.4154e-02, 6.1208e-03, 1.6674e-02, 1.5331e-02,\n",
      "        5.1093e-03, 9.1927e-04, 2.4357e-01, 4.0431e-02, 1.0720e-03, 5.4202e-02,\n",
      "        3.5387e-01, 8.2463e+00]), 'bond': tensor([0.0000, 0.0574, 0.0080, 0.0218, 0.0200, 0.0067, 0.0013, 0.9004, 0.6819,\n",
      "        0.0834, 0.8994]), 'global': tensor([2.9304, 2.6982, 4.8165])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([0.6036, 0.3727, 0.1693, 0.0648, 0.1062, 0.1019, 0.0593, 0.0252, 0.3309,\n",
      "        0.1624, 0.0272, 0.1861, 0.3465, 5.5495]), 'bond': tensor([0.0010, 0.1911, 0.0739, 0.1210, 0.1160, 0.0680, 0.0302, 0.3721, 0.2274,\n",
      "        0.1492, 0.2374]), 'global': tensor([0.1600, 0.1329, 0.0659])}\n",
      "... > Scaling targets\n",
      "mean [-4.11839673e+02  2.71560095e+00  2.08245724e+01  1.39841945e+00\n",
      "  1.11954027e+00  1.18791161e+03 -2.40051363e-01  1.10595518e-02\n",
      "  2.51110587e-01  1.48394690e-01]\n",
      "std [3.97974533e+01 1.51211242e+00 2.01093107e+03 4.62216660e-01\n",
      " 3.32729311e-01 2.78532528e+02 2.20221091e-02 4.66571660e-02\n",
      " 4.72401831e-02 3.29989287e-02]\n",
      "... > Scaling targets complete\n",
      "... > feature mean(s): \n",
      " {'global': tensor([-4.1184e+02,  2.7156e+00,  2.0825e+01,  1.3984e+00,  1.1195e+00,\n",
      "         1.1879e+03, -2.4005e-01,  1.1060e-02,  2.5111e-01,  1.4839e-01])}\n",
      "... > feature std(s):  \n",
      " {'global': tensor([3.9797e+01, 1.5121e+00, 2.0109e+03, 4.6222e-01, 3.3273e-01, 2.7853e+02,\n",
      "        2.2022e-02, 4.6657e-02, 4.7240e-02, 3.2999e-02])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "qtaim_keys = {\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\n",
    "            \"extra_feat_bond_esp_total\",\n",
    "            \"extra_feat_bond_ellip_e_dens\",\n",
    "            \"extra_feat_bond_eta\",\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": [\"u0\", \"mu\", \"A\", \"B\", \"C\", \"r2\", \"homo\", \"lumo\", \"gap\", \"zpve\"],\n",
    "}\n",
    "\n",
    "base_dict = {\n",
    "        \"atom\": [],\n",
    "        \"bond\": [\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": [\"u0\", \"mu\", \"A\", \"B\", \"C\", \"r2\", \"homo\", \"lumo\", \"gap\", \"zpve\"],\n",
    "}\n",
    "\n",
    "qm8_loc = \"../../../data/splits_1101/test_qm9_qtaim_1025_labelled.pkl\"\n",
    "dataset = HeteroGraphGraphLabelDataset(\n",
    "    file=qm8_loc,\n",
    "    allowed_ring_size=[3, 4, 5, 6, 7],\n",
    "    allowed_charges=None,\n",
    "    allowed_spins=None,\n",
    "    self_loop=True,\n",
    "    extra_keys=qtaim_keys,\n",
    "    target_list=[\"u0\", \"mu\", \"A\", \"B\", \"C\", \"r2\", \"homo\", \"lumo\", \"gap\", \"zpve\"],\n",
    "    extra_dataset_info={},\n",
    "    debug=False,\n",
    "    log_scale_features=True,\n",
    "    log_scale_targets=False,\n",
    "    standard_scale_features=True,\n",
    "    standard_scale_targets=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': 14, 'bond': 11, 'global': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.wrappers import MultioutputWrapper\n",
    "import torchmetrics\n",
    "from copy import deepcopy\n",
    "\n",
    "data_loader = DataLoaderMoleculeGraphTask(\n",
    "    dataset, batch_size=len(dataset.graphs), shuffle=False\n",
    ")\n",
    "\n",
    "batch_graph, batched_labels = next(iter(data_loader))\n",
    "\n",
    "def evaluate_manually(model, batch_graph, batch_label, scaler_list):\n",
    "    \"\"\"\n",
    "    Evaluate a set of data manually\n",
    "    Takes\n",
    "        feats: dict, dictionary of batched features\n",
    "        scaler_list: list, list of scalers\n",
    "    \"\"\"\n",
    "    # batch_graph, batch_label = batch\n",
    "\n",
    "    # batch_label = batch_label[\"global\"]\n",
    "    preds = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "\n",
    "    preds_unscaled = deepcopy(preds.detach())\n",
    "    labels_unscaled = deepcopy(batch_label)\n",
    "    # print(\"preds unscaled\", preds_unscaled)  # * this looks good\n",
    "    #print(\"labels unscaled\", labels_unscaled[\"global\"].shape)  # * this looks good\n",
    "    for scaler in scaler_list:\n",
    "        labels_unscaled = scaler.inverse_feats(labels_unscaled)\n",
    "        preds_unscaled = scaler.inverse_feats({\"global\": preds_unscaled})\n",
    "\n",
    "    # reshape to (batch_size, n_tasks)\n",
    "    \n",
    "    preds_unscaled = preds_unscaled[\"global\"].view(-1, model.hparams.ntasks)\n",
    "    labels_unscaled = labels_unscaled[\"global\"].view(-1, model.hparams.ntasks)\n",
    "    \n",
    "    # manually compute metrics\n",
    "    #r2_eval = torchmetrics.R2Score()\n",
    "    #mae_eval = torchmetrics.MeanAbsoluteError()\n",
    "    #mse_eval = torchmetrics.MeanSquaredError(squared=False)\n",
    "    r2_eval = MultioutputWrapper(\n",
    "        torchmetrics.R2Score(), num_outputs=model.hparams.ntasks\n",
    "    )\n",
    "    mae_eval = MultioutputWrapper(\n",
    "        torchmetrics.MeanAbsoluteError(), num_outputs=model.hparams.ntasks\n",
    "    )\n",
    "    mse_eval = MultioutputWrapper(\n",
    "        torchmetrics.MeanSquaredError(squared=False),\n",
    "        num_outputs=model.hparams.ntasks,\n",
    "    )\n",
    "    \n",
    "\n",
    "    r2_eval.update(preds_unscaled, labels_unscaled)\n",
    "    mae_eval.update(preds_unscaled, labels_unscaled)\n",
    "    mse_eval.update(preds_unscaled, labels_unscaled)\n",
    "\n",
    "    r2_val = r2_eval.compute()\n",
    "    mae_val = mae_eval.compute()\n",
    "    mse_val = mse_eval.compute()\n",
    "\n",
    "    return r2_val, mae_val, mse_val\n",
    "\n",
    "\n",
    "r2_pre, mae, mse = evaluate_manually(\n",
    "    model,\n",
    "    batch_graph,\n",
    "    batched_labels,\n",
    "    scaler_list=dataset.label_scalers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_pre [ 0.8117762   0.21504116 -0.25984633  0.09911817  0.1532762   0.13207507\n",
      "  0.44254476  0.5692729   0.40031952  0.737764  ]\n",
      "mae [1.2769387e+01 1.0268080e+00 8.7206985e+01 3.1082767e-01 2.1220919e-01\n",
      " 1.8874388e+02 1.2627140e-02 2.3618367e-02 2.8215254e-02 1.3480508e-02]\n",
      "mse [1.7266220e+01 1.3397003e+00 2.2571270e+03 4.3871191e-01 3.0616960e-01\n",
      " 2.5948816e+02 1.6442539e-02 3.0621009e-02 3.6582340e-02 1.6898416e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"r2_pre\", r2_pre.numpy())\n",
    "print(\"mae\", mae.numpy())\n",
    "print(\"mse\", mse.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01262714 0.02361837 0.02821525]\n",
      "0.021486921\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(mae.numpy()[-4:-1]) \n",
    "print(np.mean(mae.numpy()[-4:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uni-mol uses homo, lumo, gap\n",
    "dfdfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
