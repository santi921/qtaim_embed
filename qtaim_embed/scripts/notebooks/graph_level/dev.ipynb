{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline GNN model for node-level regression\n",
    "\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from torchmetrics.wrappers import MultioutputWrapper\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "\n",
    "from qtaim_embed.models.graph_level.base_gcn import GCNGraphPred\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config\n",
    "from qtaim_embed.models.layers import (\n",
    "    GraphConvDropoutBatch,\n",
    "    ResidualBlock,\n",
    "    UnifySize,\n",
    "    Set2SetThenCat,\n",
    "    SumPoolingThenCat,\n",
    "    WeightAndSumThenCat,\n",
    "    GlobalAttentionPoolingThenCat,\n",
    ")\n",
    "\n",
    "from qtaim_embed.utils.models import (\n",
    "    get_layer_args,\n",
    "    link_fmt_to_node_fmt,\n",
    "    _split_batched_output,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNGraphPred(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Basic GNN model for graph-level regression\n",
    "    Takes\n",
    "        atom_input_size: int, dimension of atom features\n",
    "        bond_input_size: int, dimension of bond features\n",
    "        global_input_size: int, dimension of global features\n",
    "        target_dict: dict, dictionary of targets\n",
    "        n_conv_layers: int, number of convolution layers\n",
    "        conv_fn: str \"GraphConvDropoutBatch\"\n",
    "        dropout: float, dropout rate\n",
    "        batch_norm: bool, whether to use batch norm\n",
    "        activation: str, activation function\n",
    "        bias: bool, whether to use bias\n",
    "        norm: str, normalization type\n",
    "        aggregate: str, aggregation type\n",
    "        lr: float, learning rate\n",
    "        scheduler_name: str, scheduler type\n",
    "        weight_decay: float, weight decay\n",
    "        lr_plateau_patience: int, patience for lr scheduler\n",
    "        lr_scale_factor: float, scale factor for lr scheduler\n",
    "        loss_fn: str, loss function\n",
    "        resid_n_graph_convs: int, number of graph convolutions per residual block\n",
    "        scalers: list, list of scalers applied to each node type\n",
    "        embedding_size: int, size of embedding layer\n",
    "        global_pooling: str, type of global pooling\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        atom_input_size=12,\n",
    "        bond_input_size=8,\n",
    "        global_input_size=3,\n",
    "        n_conv_layers=3,\n",
    "        target_dict={\"atom\": \"E\"},\n",
    "        conv_fn=\"GraphConvDropoutBatch\",\n",
    "        global_pooling=\"WeightAndSumThenCat\",\n",
    "        resid_n_graph_convs=None,\n",
    "        dropout=0.2,\n",
    "        batch_norm=True,\n",
    "        activation=\"ReLU\",\n",
    "        bias=True,\n",
    "        norm=\"both\",\n",
    "        aggregate=\"sum\",\n",
    "        lr=1e-3,\n",
    "        scheduler_name=\"reduce_on_plateau\",\n",
    "        weight_decay=0.0,\n",
    "        lr_plateau_patience=5,\n",
    "        lr_scale_factor=0.5,\n",
    "        loss_fn=\"mse\",\n",
    "        embedding_size=128,\n",
    "        fc_layer_size=[128, 64],\n",
    "        fc_dropout=0.0,\n",
    "        fc_batch_norm=True,\n",
    "        lstm_iters=3,\n",
    "        lstm_layers=1,\n",
    "        pooling_ntypes=[\"atom\", \"bond\"],\n",
    "        pooling_ntypes_direct=[\"global\"],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.learning_rate = lr\n",
    "\n",
    "        # output_dims = 0\n",
    "        # for k, v in target_dict.items():\n",
    "        #    output_dims += len(v)\n",
    "\n",
    "        assert conv_fn == \"GraphConvDropoutBatch\" or conv_fn == \"ResidualBlock\", (\n",
    "            \"conv_fn must be either GraphConvDropoutBatch or ResidualBlock\"\n",
    "            + f\"but got {conv_fn}\"\n",
    "        )\n",
    "\n",
    "        if conv_fn == \"ResidualBlock\":\n",
    "            assert resid_n_graph_convs is not None, (\n",
    "                \"resid_n_graph_convs must be specified for ResidualBlock\"\n",
    "                + f\"but got {resid_n_graph_convs}\"\n",
    "            )\n",
    "\n",
    "        assert global_pooling in [\n",
    "            \"WeightAndSumThenCat\",\n",
    "            \"SumPoolingThenCat\",\n",
    "            \"GlobalAttentionPoolingThenCat\",\n",
    "            \"Set2SetThenCat\",\n",
    "        ], (\n",
    "            \"global_pooling must be either WeightAndSumThenCat, SumPoolingThenCat, or GlobalAttentionPoolingThenCat\"\n",
    "            + f\"but got {global_pooling}\"\n",
    "        )\n",
    "\n",
    "        params = {\n",
    "            \"atom_input_size\": atom_input_size,\n",
    "            \"bond_input_size\": bond_input_size,\n",
    "            \"global_input_size\": global_input_size,\n",
    "            \"conv_fn\": conv_fn,\n",
    "            \"target_dict\": target_dict,\n",
    "            \"dropout\": dropout,\n",
    "            \"batch_norm_tf\": batch_norm,\n",
    "            \"activation\": activation,\n",
    "            \"bias\": bias,\n",
    "            \"norm\": norm,\n",
    "            \"aggregate\": aggregate,\n",
    "            \"n_conv_layers\": n_conv_layers,\n",
    "            \"lr\": lr,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"lr_plateau_patience\": lr_plateau_patience,\n",
    "            \"lr_scale_factor\": lr_scale_factor,\n",
    "            \"scheduler_name\": scheduler_name,\n",
    "            \"loss_fn\": loss_fn,\n",
    "            \"resid_n_graph_convs\": resid_n_graph_convs,\n",
    "            \"embedding_size\": embedding_size,\n",
    "            \"fc_layer_size\": fc_layer_size,\n",
    "            \"fc_dropout\": fc_dropout,\n",
    "            \"fc_batch_norm\": fc_batch_norm,\n",
    "            \"n_fc_layers\": len(fc_layer_size),\n",
    "            \"global_pooling\": global_pooling,\n",
    "            \"ntypes_pool\": pooling_ntypes,\n",
    "            \"ntypes_pool_direct_cat\": pooling_ntypes_direct,\n",
    "            \"lstm_iters\": lstm_iters,\n",
    "            \"lstm_layers\": lstm_layers,\n",
    "            \"ntasks\": len(target_dict[\"global\"]),\n",
    "        }\n",
    "\n",
    "        self.hparams.update(params)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # convert string activation to function\n",
    "        if self.hparams.activation is not None:\n",
    "            self.activation = getattr(torch.nn, self.hparams.activation)()\n",
    "        else: \n",
    "            self.activation = None\n",
    "\n",
    "        input_size = {\n",
    "            \"atom\": self.hparams.atom_input_size,\n",
    "            \"bond\": self.hparams.bond_input_size,\n",
    "            \"global\": self.hparams.global_input_size,\n",
    "        }\n",
    "        # print(\"input size\", input_size)\n",
    "        self.embedding = UnifySize(\n",
    "            input_dim=input_size,\n",
    "            output_dim=self.hparams.embedding_size,\n",
    "        )\n",
    "        # self.embedding_output_size = self.hparams.embedding_size\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "\n",
    "        if self.hparams.conv_fn == \"GraphConvDropoutBatch\":\n",
    "            for i in range(self.hparams.n_conv_layers):\n",
    "                # embedding_in = False\n",
    "                # if i == 0:\n",
    "                embedding_in = True\n",
    "\n",
    "                layer_args = get_layer_args(self.hparams, i, activation=self.activation, embedding_in=embedding_in)\n",
    "                # print(\"resid layer args\", layer_args)\n",
    "\n",
    "                self.conv_layers.append(\n",
    "                    dglnn.HeteroGraphConv(\n",
    "                        {\n",
    "                            \"a2b\": GraphConvDropoutBatch(**layer_args[\"a2b\"]),\n",
    "                            \"b2a\": GraphConvDropoutBatch(**layer_args[\"b2a\"]),\n",
    "                            \"a2g\": GraphConvDropoutBatch(**layer_args[\"a2g\"]),\n",
    "                            \"g2a\": GraphConvDropoutBatch(**layer_args[\"g2a\"]),\n",
    "                            \"b2g\": GraphConvDropoutBatch(**layer_args[\"b2g\"]),\n",
    "                            \"g2b\": GraphConvDropoutBatch(**layer_args[\"g2b\"]),\n",
    "                            \"a2a\": GraphConvDropoutBatch(**layer_args[\"a2a\"]),\n",
    "                            \"b2b\": GraphConvDropoutBatch(**layer_args[\"b2b\"]),\n",
    "                            \"g2g\": GraphConvDropoutBatch(**layer_args[\"g2g\"]),\n",
    "                        },\n",
    "                        aggregate=self.hparams.aggregate,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        elif self.hparams.conv_fn == \"ResidualBlock\":\n",
    "            layer_tracker = 0\n",
    "            embedding_in = True\n",
    "\n",
    "            while layer_tracker < self.hparams.n_conv_layers:\n",
    "                if (\n",
    "                    layer_tracker + self.hparams.resid_n_graph_convs\n",
    "                    > self.hparams.n_conv_layers - 1\n",
    "                ):\n",
    "                    # print(\"triggered output_layer args\")\n",
    "                    layer_ind = self.hparams.n_conv_layers - layer_tracker - 1\n",
    "                else:\n",
    "                    layer_ind = -1\n",
    "\n",
    "                layer_args = get_layer_args(\n",
    "                    self.hparams, layer_ind, embedding_in=embedding_in, activation=self.activation\n",
    "                )\n",
    "                # print(\"resid layer args\", layer_args)\n",
    "                # for k, v in layer_args.items():\n",
    "                #    print(k, v[\"in_feats\"], v[\"out_feats\"])\n",
    "\n",
    "                # embedding_in = False\n",
    "                output_block = False\n",
    "                if layer_ind != -1:\n",
    "                    output_block = True\n",
    "\n",
    "                self.conv_layers.append(\n",
    "                    ResidualBlock(\n",
    "                        layer_args,\n",
    "                        resid_n_graph_convs=self.hparams.resid_n_graph_convs,\n",
    "                        aggregate=self.hparams.aggregate,\n",
    "                        output_block=output_block,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                layer_tracker += self.hparams.resid_n_graph_convs\n",
    "\n",
    "        self.conv_layers = nn.ModuleList(self.conv_layers)\n",
    "        # print(\"conv layer out modes\", self.conv_layers[-1].mods)\n",
    "\n",
    "        # print(\"conv layer out feats\", self.conv_layers[-1].out_feats)\n",
    "        # conv_out_size = self.conv_layers[-1].out_feats\n",
    "\n",
    "        if self.hparams.conv_fn == \"GraphConvDropoutBatch\":\n",
    "            conv_out_size = {}\n",
    "            for k, v in self.conv_layers[-1].mods.items():\n",
    "                conv_out_size[k] = v.out_feats\n",
    "        elif self.hparams.conv_fn == \"ResidualBlock\":\n",
    "            conv_out_size = self.conv_layers[-1].out_feats\n",
    "\n",
    "        # print(\"conv out raw\", conv_out_size)\n",
    "        self.conv_out_size = link_fmt_to_node_fmt(conv_out_size)\n",
    "        # print(\"conv out size: \", self.conv_out_size)\n",
    "\n",
    "        if self.hparams.global_pooling == \"WeightAndSumThenCat\":\n",
    "            readout_fn = WeightAndSumThenCat\n",
    "        elif self.hparams.global_pooling == \"SumPoolingThenCat\":\n",
    "            readout_fn = SumPoolingThenCat\n",
    "        elif self.hparams.global_pooling == \"GlobalAttentionPoolingThenCat\":\n",
    "            readout_fn = GlobalAttentionPoolingThenCat\n",
    "        elif self.hparams.global_pooling == \"Set2SetThenCat\":\n",
    "            readout_fn = Set2SetThenCat\n",
    "\n",
    "        list_in_feats = []\n",
    "        for type_feat in self.hparams.pooling_ntypes:\n",
    "            list_in_feats.append(self.conv_out_size[type_feat])\n",
    "\n",
    "        self.readout_out_size = 0\n",
    "        if self.hparams.global_pooling == \"Set2SetThenCat\":\n",
    "            # print(\"using set2setthencat\")\n",
    "\n",
    "            self.readout = readout_fn(\n",
    "                n_iters=self.hparams.lstm_iters,\n",
    "                n_layers=self.hparams.lstm_layers,\n",
    "                in_feats=list_in_feats,\n",
    "                ntypes=self.hparams.pooling_ntypes,\n",
    "                ntypes_direct_cat=self.hparams.ntypes_pool_direct_cat,\n",
    "            )\n",
    "            for i in self.hparams.pooling_ntypes:\n",
    "                if i not in self.hparams.ntypes_pool_direct_cat:\n",
    "                    self.readout_out_size += self.conv_out_size[i] * 2\n",
    "                else:\n",
    "                    self.readout_out_size += self.conv_out_size[i]\n",
    "\n",
    "        else:\n",
    "            # print(\"other readout used\")\n",
    "            self.readout = readout_fn(\n",
    "                ntypes=self.hparams.pooling_ntypes,\n",
    "                in_feats=list_in_feats,\n",
    "                ntypes_direct_cat=self.hparams.ntypes_pool_direct_cat,\n",
    "            )\n",
    "\n",
    "            for i in self.hparams.pooling_ntypes:\n",
    "                if i in self.hparams.ntypes_pool_direct_cat:\n",
    "                    self.readout_out_size += self.conv_out_size[i]\n",
    "                else:\n",
    "                    self.readout_out_size += self.conv_out_size[i]\n",
    "\n",
    "        # print(\"readout out size\", self.readout_out_size)\n",
    "        # self.readout_out_size = readout_out_size\n",
    "        self.loss = self.loss_function()\n",
    "\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "\n",
    "        input_size = self.readout_out_size\n",
    "        for i in range(self.hparams.n_fc_layers):\n",
    "            out_size = self.hparams.fc_layer_size[i]\n",
    "            self.fc_layers.append(nn.Linear(input_size, out_size))\n",
    "            if self.hparams.fc_batch_norm:\n",
    "                self.fc_layers.append(nn.BatchNorm1d(out_size))\n",
    "            if self.activation is not None:\n",
    "                self.fc_layers.append(self.activation)\n",
    "            if self.hparams.fc_dropout > 0:\n",
    "                self.fc_layers.append(nn.Dropout(self.hparams.fc_dropout))\n",
    "            input_size = out_size\n",
    "\n",
    "        self.fc_layers.append(nn.Linear(input_size, self.hparams.ntasks))\n",
    "\n",
    "        # print(\"number of output dims\", output_dims)\n",
    "        print(\"... > number of tasks:\", self.hparams.ntasks)\n",
    "\n",
    "        # create multioutput wrapper for metrics\n",
    "        self.train_r2 = MultioutputWrapper(\n",
    "            torchmetrics.R2Score(), num_outputs=self.hparams.ntasks\n",
    "        )\n",
    "        self.train_torch_l1 = MultioutputWrapper(\n",
    "            torchmetrics.MeanAbsoluteError(), num_outputs=self.hparams.ntasks\n",
    "        )\n",
    "        self.train_torch_mse = MultioutputWrapper(\n",
    "            torchmetrics.MeanSquaredError(squared=False),\n",
    "            num_outputs=self.hparams.ntasks,\n",
    "        )\n",
    "        self.val_r2 = MultioutputWrapper(\n",
    "            torchmetrics.R2Score(), num_outputs=self.hparams.ntasks\n",
    "        )\n",
    "        self.val_torch_l1 = MultioutputWrapper(\n",
    "            torchmetrics.MeanAbsoluteError(), num_outputs=self.hparams.ntasks\n",
    "        )\n",
    "        self.val_torch_mse = MultioutputWrapper(\n",
    "            torchmetrics.MeanSquaredError(squared=False),\n",
    "            num_outputs=self.hparams.ntasks,\n",
    "        )\n",
    "        self.test_r2 = MultioutputWrapper(\n",
    "            torchmetrics.R2Score(), num_outputs=self.hparams.ntasks\n",
    "        )\n",
    "        self.test_torch_l1 = MultioutputWrapper(\n",
    "            torchmetrics.MeanAbsoluteError(), num_outputs=self.hparams.ntasks\n",
    "        )\n",
    "        self.test_torch_mse = MultioutputWrapper(\n",
    "            torchmetrics.MeanSquaredError(squared=False),\n",
    "            num_outputs=self.hparams.ntasks,\n",
    "        )\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "\n",
    "        feats = self.embedding(inputs)\n",
    "        for ind, conv in enumerate(self.conv_layers):\n",
    "            # print(\"conv layer\", ind)\n",
    "            feats = conv(graph, feats)\n",
    "\n",
    "        readout_feats = self.readout(graph, feats)\n",
    "        for ind, layer in enumerate(self.fc_layers):\n",
    "            readout_feats = layer(readout_feats)\n",
    "\n",
    "        #print(\"preds shape:\", readout_feats.shape)\n",
    "        return readout_feats\n",
    "    \n",
    "    def loss_function(self):\n",
    "        \"\"\"\n",
    "        Initialize loss function\n",
    "        \"\"\"\n",
    "        if self.hparams.ntasks > 1:\n",
    "            loss_fn = nn.ModuleList()\n",
    "            for i in range(self.hparams.ntasks):\n",
    "                if self.hparams.loss_fn == \"mse\":\n",
    "                    loss_fn.append(torchmetrics.MeanSquaredError())\n",
    "                elif self.hparams.loss_fn == \"smape\":\n",
    "                    loss_fn.append(torchmetrics.SymmetricMeanAbsolutePercentageError())\n",
    "                elif self.hparams.loss_fn == \"mae\":\n",
    "                    loss_fn.append(torchmetrics.MeanAbsoluteError())\n",
    "                else:\n",
    "                    loss_fn.append(torchmetrics.MeanSquaredError())\n",
    "\n",
    "        else: \n",
    "            if self.hparams.loss_fn == \"mse\":\n",
    "                loss_fn = torchmetrics.MeanSquaredError()\n",
    "                \n",
    "            elif self.hparams.loss_fn == \"smape\":\n",
    "                loss_fn = torchmetrics.SymmetricMeanAbsolutePercentageError()\n",
    "            elif self.hparams.loss_fn == \"mae\":\n",
    "                loss_fn = torchmetrics.MeanAbsoluteError()\n",
    "            else:\n",
    "                loss_fn = torchmetrics.MeanSquaredError()\n",
    "\n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qtaim_embed.utils.grapher import get_grapher\n",
    "# from qtaim_embed.data.molwrapper import mol_wrappers_from_df\n",
    "\n",
    "from qtaim_embed.core.dataset import (\n",
    "    HeteroGraphNodeLabelDataset,\n",
    "    Subset,\n",
    "    HeteroGraphGraphLabelDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_default_graph_level_config()\n",
    "config[\"log_scale_features\"] = True\n",
    "config[\"log_scale_targets\"] = False\n",
    "config[\"standard_scale_features\"] = True\n",
    "config[\"standard_scale_targets\"] = True\n",
    "config[\"debug\"] = False\n",
    "config[\n",
    "    \"train_dataset_loc\"\n",
    "] = \"/home/santiagovargas/dev/qtaim_embed/data/xyz_qm8/molecules_qtaim_labelled.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 5314.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'N', 'C', 'O', 'H'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['extra_feat_global_E1_CAM']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 326.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['extra_feat_global_E1_CAM']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_N', 'chemical_symbol_C', 'chemical_symbol_O', 'chemical_symbol_H', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 32924.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [1.03348744 0.29579238 0.1931437  0.02300363 0.03993083 0.06814284\n",
      " 0.04296905 0.01909736 0.04557323 0.23654678 0.05555594 0.35547122\n",
      " 9.03963532]\n",
      "std [0.3914866  0.46054609 0.3107612  0.12416012 0.16150379 0.2063724\n",
      " 0.16714525 0.11345734 0.17179068 0.32864473 0.18820728 0.34645936\n",
      " 5.66985947]\n",
      "mean [0.         0.19579709 0.02420918 0.04417114 0.07007922 0.04587003\n",
      " 0.0208114  0.81517279 0.66599706]\n",
      "std [0.         0.31205721 0.12725739 0.16931041 0.2089596  0.17230968\n",
      " 0.11828885 0.09367724 0.18940919]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [2.81851833 2.8375313  4.69764359]\n",
      "std [0.16318695 0.17198598 0.06353343]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([1.0335, 0.2958, 0.1931, 0.0230, 0.0399, 0.0681, 0.0430, 0.0191, 0.0456,\n",
      "        0.2365, 0.0556, 0.3555, 9.0396]), 'bond': tensor([0.0000, 0.1958, 0.0242, 0.0442, 0.0701, 0.0459, 0.0208, 0.8152, 0.6660]), 'global': tensor([2.8185, 2.8375, 4.6976])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([0.3915, 0.4605, 0.3108, 0.1242, 0.1615, 0.2064, 0.1671, 0.1135, 0.1718,\n",
      "        0.3286, 0.1882, 0.3465, 5.6699]), 'bond': tensor([0.0010, 0.3121, 0.1273, 0.1693, 0.2090, 0.1723, 0.1183, 0.0937, 0.1894]), 'global': tensor([0.1632, 0.1720, 0.0635])}\n",
      "... > Scaling targets\n",
      "mean [0.21248137]\n",
      "std [0.04254279]\n",
      "... > Scaling targets complete\n",
      "... > feature mean(s): \n",
      " {'global': tensor([0.2125])}\n",
      "... > feature std(s):  \n",
      " {'global': tensor([0.0425])}\n",
      "... > loaded dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HeteroGraphGraphLabelDataset(\n",
    "    file=config[\"dataset\"][\"train_dataset_loc\"],\n",
    "    allowed_ring_size=config[\"dataset\"][\"allowed_ring_size\"],\n",
    "    allowed_charges=config[\"dataset\"][\"allowed_charges\"],\n",
    "    self_loop=True,\n",
    "    extra_keys=config[\"dataset\"][\"extra_keys\"],\n",
    "    target_list=config[\"dataset\"][\"target_list\"],\n",
    "    extra_dataset_info=config[\"dataset\"][\"extra_dataset_info\"],\n",
    "    debug=config[\"debug\"],\n",
    "    standard_scale_features=config[\"standard_scale_features\"],\n",
    "    standard_scale_targets=config[\"standard_scale_targets\"],\n",
    "    log_scale_features=config[\"log_scale_features\"],\n",
    "    log_scale_targets=config[\"log_scale_targets\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 9158.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'N', 'C', 'O', 'H'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['extra_feat_global_E1_CAM']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 325.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['extra_feat_global_E1_CAM']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_N', 'chemical_symbol_C', 'chemical_symbol_O', 'chemical_symbol_H', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 34433.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "... > Scaling features\n",
      "mean [2.04383219e+00 5.20350657e-01 2.78647464e-01 3.31872260e-02\n",
      " 5.76080150e-02 9.83093300e-02 6.19912336e-02 2.75516594e-02\n",
      " 6.57482780e-02 3.41264872e-01 8.01502818e-02 5.12836569e-01\n",
      " 2.08447046e+06]\n",
      "std [1.25340657e+00 8.73526527e-01 4.48333642e-01 1.79125191e-01\n",
      " 2.33000712e-01 2.97732440e-01 2.41139629e-01 1.63684347e-01\n",
      " 2.47841566e-01 4.74134115e-01 2.71525715e-01 4.99835195e-01\n",
      " 5.20377426e+06]\n",
      "mean [0.         0.28247549 0.03492647 0.06372549 0.10110294 0.06617647\n",
      " 0.03002451 1.26981778 0.98419271]\n",
      "std [0.         0.45020338 0.18359361 0.24426328 0.30146498 0.24859032\n",
      " 0.17065474 0.22397461 0.42073796]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [ 15.97        16.32       108.90153938]\n",
      "std [2.67003745 2.85615126 6.59715147]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([2.0438e+00, 5.2035e-01, 2.7865e-01, 3.3187e-02, 5.7608e-02, 9.8309e-02,\n",
      "        6.1991e-02, 2.7552e-02, 6.5748e-02, 3.4126e-01, 8.0150e-02, 5.1284e-01,\n",
      "        2.0845e+06]), 'bond': tensor([0.0000, 0.2825, 0.0349, 0.0637, 0.1011, 0.0662, 0.0300, 1.2698, 0.9842]), 'global': tensor([ 15.9700,  16.3200, 108.9015])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([1.2534e+00, 8.7353e-01, 4.4833e-01, 1.7913e-01, 2.3300e-01, 2.9773e-01,\n",
      "        2.4114e-01, 1.6368e-01, 2.4784e-01, 4.7413e-01, 2.7153e-01, 4.9984e-01,\n",
      "        5.2038e+06]), 'bond': tensor([0.0010, 0.4502, 0.1836, 0.2443, 0.3015, 0.2486, 0.1707, 0.2240, 0.4207]), 'global': tensor([2.6700, 2.8562, 6.5972])}\n",
      "... > Scaling targets\n",
      "mean [0.21248137]\n",
      "std [0.04254279]\n",
      "... > Scaling targets complete\n",
      "... > feature mean(s): \n",
      " {'global': tensor([0.2125])}\n",
      "... > feature std(s):  \n",
      " {'global': tensor([0.0425])}\n",
      "... > loaded dataset\n",
      "training set size:  75\n",
      "validation set size:  15\n",
      "test set size:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from qtaim_embed.core.datamodule import QTAIMGraphTaskDataModule\n",
    "\n",
    "dm = QTAIMGraphTaskDataModule(config=config,)\n",
    "feat_names, feat_size = dm.prepare_data(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > number of tasks: 1\n"
     ]
    }
   ],
   "source": [
    "model = GCNGraphPred(\n",
    "    atom_input_size=feat_size[\"atom\"],\n",
    "    bond_input_size=feat_size[\"bond\"],\n",
    "    global_input_size=feat_size[\"global\"],\n",
    "    n_conv_layers=3,\n",
    "    resid_n_graph_convs=2,\n",
    "    target_dict={\"global\": [\"extra_feat_global_E1_CAM\"]},\n",
    "    conv_fn=\"GraphConvDropoutBatch\",\n",
    "    global_pooling=\"Set2SetThenCat\",\n",
    "    dropout=0.2,\n",
    "    batch_norm=False,\n",
    "    activation=\"ReLU\",\n",
    "    bias=True,\n",
    "    norm=\"both\",\n",
    "    aggregate=\"sum\",\n",
    "    lr=0.01,\n",
    "    scheduler_name=\"reduce_on_plateau\",\n",
    "    weight_decay=0.00001,\n",
    "    lr_plateau_patience=25,\n",
    "    lr_scale_factor=0.8,\n",
    "    loss_fn=\"mae\",\n",
    "    embedding_size=10,\n",
    "    fc_layer_size=[256, 128, 128],\n",
    "    fc_dropout=0.2,\n",
    "    fc_batch_norm=True,\n",
    "    lstm_iters=3,\n",
    "    lstm_layers=2,\n",
    "    pooling_ntypes=[\"atom\", \"bond\", \"global\"],\n",
    "    pooling_ntypes_direct=[\"global\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic training loop\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "\n",
    "# move model to cpu\n",
    "model = model.cpu()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "dataloader = dm.train_dataloader()\n",
    "\n",
    "for epoch in range(50):\n",
    "    training_loss_list = []\n",
    "    with tqdm(dataloader) as tq:\n",
    "        model.train()\n",
    "        r2_list = []\n",
    "        tq.set_description(f\"Epoch {epoch+1}\")\n",
    "        training_loss = 0\n",
    "        for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "            # forward propagation by using all nodes and extracting the user embeddings\n",
    "            batch_graph, batch_label = next(iter(dataloader))\n",
    "            labels = batch_label[\"global\"]\n",
    "            logits = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "            loss = F.mse_loss(logits, labels)\n",
    "            training_loss_list.append(loss.item())\n",
    "            # loss_mae = F.l1_loss(logits, labels)\n",
    "            # compute r2 score\n",
    "            r2 = r2_score(logits.detach().numpy(), labels.detach().numpy())\n",
    "            r2_list.append(r2)\n",
    "            # Compute validation accuracy.  Omitted in this example.\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            training_loss += loss.item()\n",
    "            # tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\n",
    "\n",
    "        r2_mean = np.mean(r2_list)\n",
    "        loss = np.mean(training_loss_list)\n",
    "        tq.set_postfix({\"final_t_loss\": training_loss, \"R_2\": r2_mean})\n",
    "        print(r2_mean, loss)\n",
    "\n",
    "        # tq.update()\n",
    "        tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nfrom qtaim_embed.models.utils import LogParameters\\nimport wandb\\n\\nwith wandb.init(project=\"qtaim_embed_test\") as run:\\n    logger_tb = TensorBoardLogger(\"./test_logs\", name=\"test_logs\")\\n    torch.set_float32_matmul_precision(\"high\")\\n\\n    checkpoint_callback = ModelCheckpoint(\\n        dirpath=\"test_logs\",\\n        filename=\"model_lightning_{epoch:02d}-{val_mae:.2f}\",\\n        monitor=\"val_mae\",\\n        mode=\"min\",\\n        auto_insert_metric_name=True,\\n        save_last=True,\\n    )\\n\\n    early_stopping_callback = EarlyStopping(\\n        monitor=\"val_mae\",\\n        min_delta=0.00,\\n        patience=500,\\n        verbose=False,\\n        mode=\"min\",\\n    )\\n    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\\n    logger_wb = WandbLogger(name=\"test_logs\")\\n    log_parameters = LogParameters()\\n    trainer_transfer = pl.Trainer(\\n        max_epochs=100,\\n        accelerator=\"gpu\",\\n        devices=1,\\n        enable_progress_bar=True,\\n        gradient_clip_val=3.0,\\n        default_root_dir=\"./test/\",\\n        precision=\"32\",\\n        log_every_n_steps=10,\\n        callbacks=[\\n            early_stopping_callback,\\n            lr_monitor,\\n            log_parameters,\\n            checkpoint_callback,\\n        ],\\n        enable_checkpointing=True,\\n        logger=[logger_tb, logger_wb],\\n    )\\n\\n    # move model to gpu\\n    # model = model.cuda()\\n\\n    trainer_transfer.fit(model, dm)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to test migration to pytorch lightning\n",
    "\"\"\"\n",
    "import torch\n",
    "from qtaim_embed.models.utils import LogParameters\n",
    "import wandb\n",
    "\n",
    "with wandb.init(project=\"qtaim_embed_test\") as run:\n",
    "    logger_tb = TensorBoardLogger(\"./test_logs\", name=\"test_logs\")\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"test_logs\",\n",
    "        filename=\"model_lightning_{epoch:02d}-{val_mae:.2f}\",\n",
    "        monitor=\"val_mae\",\n",
    "        mode=\"min\",\n",
    "        auto_insert_metric_name=True,\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_mae\",\n",
    "        min_delta=0.00,\n",
    "        patience=500,\n",
    "        verbose=False,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "    logger_wb = WandbLogger(name=\"test_logs\")\n",
    "    log_parameters = LogParameters()\n",
    "    trainer_transfer = pl.Trainer(\n",
    "        max_epochs=100,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        enable_progress_bar=True,\n",
    "        gradient_clip_val=3.0,\n",
    "        default_root_dir=\"./test/\",\n",
    "        precision=\"32\",\n",
    "        log_every_n_steps=10,\n",
    "        callbacks=[\n",
    "            early_stopping_callback,\n",
    "            lr_monitor,\n",
    "            log_parameters,\n",
    "            checkpoint_callback,\n",
    "        ],\n",
    "        enable_checkpointing=True,\n",
    "        logger=[logger_tb, logger_wb],\n",
    "    )\n",
    "\n",
    "    # move model to gpu\n",
    "    # model = model.cuda()\n",
    "\n",
    "    trainer_transfer.fit(model, dm)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.706716169536922 1.2563227415084839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3983241182551056 2.0212724208831787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7148510374074393 1.2483052015304565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.539191972896186 1.0911214351654053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.723811502874459 0.9582868218421936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.639770496413697 0.8587819337844849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1261253613246844 0.9117791652679443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.95253979835489 0.8274208307266235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4056793121236808 0.8707172870635986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.791804759288356 1.000211238861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.491617478234931 0.8373774886131287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7458898657745694 0.7644603252410889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0861239177874613 0.7337958216667175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1962182765540614 0.7722698450088501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31999188805274703 0.726051390171051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12738258103716338 0.692328929901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31854787554838704 0.7864364385604858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.39762750609146735 0.5873829126358032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6424235047680962 0.6314237713813782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4283076501852314 0.6118025779724121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8453563196924185 0.6320540904998779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4260981578313654 0.5974157452583313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4930299432271279 0.6182008385658264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17325167270188224 0.5168570280075073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.30197512141280525 0.6157616972923279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06443522568908033 0.5305404663085938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050929932884290596 0.5510839223861694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025027063218400536 0.6333790421485901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027946459581460137 0.5735399723052979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03133004618599933 0.5084571838378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21852559408565442 0.46218088269233704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04141748729422001 0.5380799174308777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048598987120388015 0.5072619915008545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004108584452037878 0.5699867010116577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012709744257602962 0.5088305473327637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23534292550090052 0.39804184436798096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1592162633566102 0.4461435377597809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13827649100004857 0.47478580474853516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4726753301462394 0.3412294387817383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4825239031743138 0.38162314891815186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4832985566867498 0.36891889572143555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568211023482711 0.3676278293132782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4922894158856249 0.4315352439880371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4810685229684698 0.40943554043769836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46177722633310403 0.35901570320129395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4603494783730592 0.3340469002723694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43464958825280176 0.34476080536842346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4961700937994765 0.3397064805030823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123852892144399 0.28567981719970703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5212500520451349 0.308574378490448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
