{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model dir\n",
    "import os\n",
    "from qtaim_embed.core.datamodule import QTAIMGraphTaskClassifyDataModule\n",
    "import pandas as pd\n",
    "\n",
    "from qtaim_embed.core.dataset import HeteroGraphGraphLabelClassifierDataset\n",
    "\n",
    "project_name = \"tox21_classifier_dev\"\n",
    "dataset_loc = \"../../../data/tox21_qtaim_1026_labelled.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dataset_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule</th>\n",
       "      <th>molecule_graph</th>\n",
       "      <th>ids</th>\n",
       "      <th>names</th>\n",
       "      <th>extra_feat_atom_Lagrangian_K</th>\n",
       "      <th>extra_feat_atom_Hamiltonian_K</th>\n",
       "      <th>extra_feat_atom_e_density</th>\n",
       "      <th>extra_feat_atom_lap_e_density</th>\n",
       "      <th>extra_feat_atom_e_loc_func</th>\n",
       "      <th>extra_feat_atom_ave_loc_ion_E</th>\n",
       "      <th>...</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-5.59927678  1.48112456 -1.33989568] O, [-4....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H25 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>TOX29129.xyz</td>\n",
       "      <td>[50.81971018, 5.585443688, 5.711909341, 5.7019...</td>\n",
       "      <td>[290541.2389, 64661.38151, 64623.63811, 64635....</td>\n",
       "      <td>[-290541.2389, -64661.38151, -64623.63811, -64...</td>\n",
       "      <td>[-1161961.677, -258623.1843, -258471.7048, -25...</td>\n",
       "      <td>[0.9999977849, 0.9999994459, 0.9999994196, 0.9...</td>\n",
       "      <td>[17.74301941, 9.605406321, 9.562594876, 9.5598...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[ 1.06758983 -0.21282923  0.88839297] C, [ 0....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H6 C...</td>\n",
       "      <td>1</td>\n",
       "      <td>TOX4798.xyz</td>\n",
       "      <td>[5.734997064, 5.735076844, 5.735076844, 12542....</td>\n",
       "      <td>[64635.5859, 64635.60486, 64635.60486, 1392991...</td>\n",
       "      <td>[-64635.5859, -64635.60486, -64635.60486, -139...</td>\n",
       "      <td>[-258519.4036, -258519.4791, -258519.4791, -55...</td>\n",
       "      <td>[0.9999994152, 0.9999994152, 0.9999994152, 0.9...</td>\n",
       "      <td>[9.596681144, 9.596663915, 9.596663915, 93.340...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-5.61752152  0.74657833  4.0187152 ] C, [-4....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H29 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>TOX27257.xyz</td>\n",
       "      <td>[5.760381358, 5.760381358, 5.760381358, 5.7834...</td>\n",
       "      <td>[64799.95269, 64799.95269, 64799.95269, 64791....</td>\n",
       "      <td>[-64799.95269, -64799.95269, -64799.95269, -64...</td>\n",
       "      <td>[-259176.7693, -259176.7693, -259176.7693, -25...</td>\n",
       "      <td>[0.9999994144, 0.9999994144, 0.9999994144, 0.9...</td>\n",
       "      <td>[9.544216068, 9.544216068, 9.544216068, 9.5404...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.38462572  6.17370301 -0.95055578] C, [-0....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H26 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>TOX1296.xyz</td>\n",
       "      <td>[5.705418111, 5.728445003, 5.702548032, 5.8418...</td>\n",
       "      <td>[64628.11906, 64633.90074, 64645.96397, 64666....</td>\n",
       "      <td>[-64628.11906, -64633.90074, -64645.96397, -64...</td>\n",
       "      <td>[-258489.6546, -258512.6892, -258561.0457, -25...</td>\n",
       "      <td>[0.999999421, 0.9999994165, 0.999999422, 0.999...</td>\n",
       "      <td>[9.564748614, 9.563678997, 9.582420779, 9.5963...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-6.28839743  0.46064045 -1.76454156] C, [-6....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H20 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>TOX26480.xyz</td>\n",
       "      <td>[5.788115695, 5.825572445, 51.25525193, 5.6533...</td>\n",
       "      <td>[64796.0617, 64794.11082, 290906.8442, 64738.7...</td>\n",
       "      <td>[-64796.0617, -64794.11082, -290906.8442, -647...</td>\n",
       "      <td>[-259161.0943, -259153.141, -1163422.356, -258...</td>\n",
       "      <td>[0.9999994085, 0.9999994008, 0.9999977548, 0.9...</td>\n",
       "      <td>[9.634017141, 9.627194883, 17.81962548, 9.7254...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>[[ 2.40515855 -0.70636691  0.21986178] C, [ 1....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H9 C...</td>\n",
       "      <td>7582</td>\n",
       "      <td>TOX1363.xyz</td>\n",
       "      <td>[5.740901694, 5.85087358, 5.757131288, 5.83672...</td>\n",
       "      <td>[64610.00982, 64754.52467, 64824.13541, 64754....</td>\n",
       "      <td>[-64610.00982, -64754.52467, -64824.13541, -64...</td>\n",
       "      <td>[-258417.0757, -258994.6952, -259273.5131, -25...</td>\n",
       "      <td>[0.9999994133, 0.9999993946, 0.9999994157, 0.9...</td>\n",
       "      <td>[9.558765871, 9.530822629, 9.537826796, 9.5336...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>[[2.89964224 0.29445404 0.26058588] C, [ 1.536...</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H14 ...</td>\n",
       "      <td>7583</td>\n",
       "      <td>TOX6714.xyz</td>\n",
       "      <td>[5.705500034, 5.705500034, 5.722837749, 5.7177...</td>\n",
       "      <td>[64634.43649, 64634.43649, 64649.54335, 64620....</td>\n",
       "      <td>[-64634.43649, -64634.43649, -64649.54335, -64...</td>\n",
       "      <td>[-258514.924, -258514.924, -258575.2821, -2584...</td>\n",
       "      <td>[0.9999994212, 0.9999994212, 0.999999418, 0.99...</td>\n",
       "      <td>[9.554152974, 9.554152974, 9.55711582, 9.55626...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>[[-2.48985245  1.44945143  0.32189716] C, [-1....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H16 ...</td>\n",
       "      <td>7585</td>\n",
       "      <td>TOX24756.xyz</td>\n",
       "      <td>[5.737948507, 5.752416845, 5.737522607, 5.7375...</td>\n",
       "      <td>[64858.03648, 64826.86106, 64652.59767, 64652....</td>\n",
       "      <td>[-64858.03648, -64826.86106, -64652.59767, -64...</td>\n",
       "      <td>[-259409.1941, -259284.4346, -258587.4406, -25...</td>\n",
       "      <td>[0.9999994204, 0.9999994167, 0.9999994151, 0.9...</td>\n",
       "      <td>[9.534232803, 9.531660645, 9.563305261, 9.5633...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>[[-3.76490062 -2.82818984 -0.20446281] O, [-2....</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H10 ...</td>\n",
       "      <td>7586</td>\n",
       "      <td>TOX3063.xyz</td>\n",
       "      <td>[50.44032334, 5.547025545, 51.26326322, 5.5470...</td>\n",
       "      <td>[291062.3089, 64824.58571, 290599.4879, 64824....</td>\n",
       "      <td>[-291062.3089, -64824.58571, -290599.4879, -64...</td>\n",
       "      <td>[-1164047.474, -259276.1547, -1162192.899, -25...</td>\n",
       "      <td>[0.999997829, 0.9999994575, 0.9999977473, 0.99...</td>\n",
       "      <td>[17.71803377, 9.675591171, 17.81342204, 9.6755...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>[[-1.26561964  5.23851633  3.27033527] Cl, [-1...</td>\n",
       "      <td>Molecule Graph\\nMolecule: \\nFull Formula (H13 ...</td>\n",
       "      <td>7587</td>\n",
       "      <td>TOX26619.xyz</td>\n",
       "      <td>[12544.52387, 5.807039466, 5.765816148, 5.7658...</td>\n",
       "      <td>[13929490.76, 64795.61745, 64799.65533, 64799....</td>\n",
       "      <td>[-13929490.76, -64795.61745, -64799.65533, -64...</td>\n",
       "      <td>[-55667784.94, -259159.2416, -259175.5581, -25...</td>\n",
       "      <td>[0.9999460363, 0.9999994047, 0.9999994132, 0.9...</td>\n",
       "      <td>[93.35583512, 9.580909278, 9.582890217, 9.5828...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7436 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               molecule  \\\n",
       "0     [[-5.59927678  1.48112456 -1.33989568] O, [-4....   \n",
       "1     [[ 1.06758983 -0.21282923  0.88839297] C, [ 0....   \n",
       "2     [[-5.61752152  0.74657833  4.0187152 ] C, [-4....   \n",
       "3     [[-0.38462572  6.17370301 -0.95055578] C, [-0....   \n",
       "4     [[-6.28839743  0.46064045 -1.76454156] C, [-6....   \n",
       "...                                                 ...   \n",
       "7431  [[ 2.40515855 -0.70636691  0.21986178] C, [ 1....   \n",
       "7432  [[2.89964224 0.29445404 0.26058588] C, [ 1.536...   \n",
       "7433  [[-2.48985245  1.44945143  0.32189716] C, [-1....   \n",
       "7434  [[-3.76490062 -2.82818984 -0.20446281] O, [-2....   \n",
       "7435  [[-1.26561964  5.23851633  3.27033527] Cl, [-1...   \n",
       "\n",
       "                                         molecule_graph   ids         names  \\\n",
       "0     Molecule Graph\\nMolecule: \\nFull Formula (H25 ...     0  TOX29129.xyz   \n",
       "1     Molecule Graph\\nMolecule: \\nFull Formula (H6 C...     1   TOX4798.xyz   \n",
       "2     Molecule Graph\\nMolecule: \\nFull Formula (H29 ...     2  TOX27257.xyz   \n",
       "3     Molecule Graph\\nMolecule: \\nFull Formula (H26 ...     4   TOX1296.xyz   \n",
       "4     Molecule Graph\\nMolecule: \\nFull Formula (H20 ...     5  TOX26480.xyz   \n",
       "...                                                 ...   ...           ...   \n",
       "7431  Molecule Graph\\nMolecule: \\nFull Formula (H9 C...  7582   TOX1363.xyz   \n",
       "7432  Molecule Graph\\nMolecule: \\nFull Formula (H14 ...  7583   TOX6714.xyz   \n",
       "7433  Molecule Graph\\nMolecule: \\nFull Formula (H16 ...  7585  TOX24756.xyz   \n",
       "7434  Molecule Graph\\nMolecule: \\nFull Formula (H10 ...  7586   TOX3063.xyz   \n",
       "7435  Molecule Graph\\nMolecule: \\nFull Formula (H13 ...  7587  TOX26619.xyz   \n",
       "\n",
       "                           extra_feat_atom_Lagrangian_K  \\\n",
       "0     [50.81971018, 5.585443688, 5.711909341, 5.7019...   \n",
       "1     [5.734997064, 5.735076844, 5.735076844, 12542....   \n",
       "2     [5.760381358, 5.760381358, 5.760381358, 5.7834...   \n",
       "3     [5.705418111, 5.728445003, 5.702548032, 5.8418...   \n",
       "4     [5.788115695, 5.825572445, 51.25525193, 5.6533...   \n",
       "...                                                 ...   \n",
       "7431  [5.740901694, 5.85087358, 5.757131288, 5.83672...   \n",
       "7432  [5.705500034, 5.705500034, 5.722837749, 5.7177...   \n",
       "7433  [5.737948507, 5.752416845, 5.737522607, 5.7375...   \n",
       "7434  [50.44032334, 5.547025545, 51.26326322, 5.5470...   \n",
       "7435  [12544.52387, 5.807039466, 5.765816148, 5.7658...   \n",
       "\n",
       "                          extra_feat_atom_Hamiltonian_K  \\\n",
       "0     [290541.2389, 64661.38151, 64623.63811, 64635....   \n",
       "1     [64635.5859, 64635.60486, 64635.60486, 1392991...   \n",
       "2     [64799.95269, 64799.95269, 64799.95269, 64791....   \n",
       "3     [64628.11906, 64633.90074, 64645.96397, 64666....   \n",
       "4     [64796.0617, 64794.11082, 290906.8442, 64738.7...   \n",
       "...                                                 ...   \n",
       "7431  [64610.00982, 64754.52467, 64824.13541, 64754....   \n",
       "7432  [64634.43649, 64634.43649, 64649.54335, 64620....   \n",
       "7433  [64858.03648, 64826.86106, 64652.59767, 64652....   \n",
       "7434  [291062.3089, 64824.58571, 290599.4879, 64824....   \n",
       "7435  [13929490.76, 64795.61745, 64799.65533, 64799....   \n",
       "\n",
       "                              extra_feat_atom_e_density  \\\n",
       "0     [-290541.2389, -64661.38151, -64623.63811, -64...   \n",
       "1     [-64635.5859, -64635.60486, -64635.60486, -139...   \n",
       "2     [-64799.95269, -64799.95269, -64799.95269, -64...   \n",
       "3     [-64628.11906, -64633.90074, -64645.96397, -64...   \n",
       "4     [-64796.0617, -64794.11082, -290906.8442, -647...   \n",
       "...                                                 ...   \n",
       "7431  [-64610.00982, -64754.52467, -64824.13541, -64...   \n",
       "7432  [-64634.43649, -64634.43649, -64649.54335, -64...   \n",
       "7433  [-64858.03648, -64826.86106, -64652.59767, -64...   \n",
       "7434  [-291062.3089, -64824.58571, -290599.4879, -64...   \n",
       "7435  [-13929490.76, -64795.61745, -64799.65533, -64...   \n",
       "\n",
       "                          extra_feat_atom_lap_e_density  \\\n",
       "0     [-1161961.677, -258623.1843, -258471.7048, -25...   \n",
       "1     [-258519.4036, -258519.4791, -258519.4791, -55...   \n",
       "2     [-259176.7693, -259176.7693, -259176.7693, -25...   \n",
       "3     [-258489.6546, -258512.6892, -258561.0457, -25...   \n",
       "4     [-259161.0943, -259153.141, -1163422.356, -258...   \n",
       "...                                                 ...   \n",
       "7431  [-258417.0757, -258994.6952, -259273.5131, -25...   \n",
       "7432  [-258514.924, -258514.924, -258575.2821, -2584...   \n",
       "7433  [-259409.1941, -259284.4346, -258587.4406, -25...   \n",
       "7434  [-1164047.474, -259276.1547, -1162192.899, -25...   \n",
       "7435  [-55667784.94, -259159.2416, -259175.5581, -25...   \n",
       "\n",
       "                             extra_feat_atom_e_loc_func  \\\n",
       "0     [0.9999977849, 0.9999994459, 0.9999994196, 0.9...   \n",
       "1     [0.9999994152, 0.9999994152, 0.9999994152, 0.9...   \n",
       "2     [0.9999994144, 0.9999994144, 0.9999994144, 0.9...   \n",
       "3     [0.999999421, 0.9999994165, 0.999999422, 0.999...   \n",
       "4     [0.9999994085, 0.9999994008, 0.9999977548, 0.9...   \n",
       "...                                                 ...   \n",
       "7431  [0.9999994133, 0.9999993946, 0.9999994157, 0.9...   \n",
       "7432  [0.9999994212, 0.9999994212, 0.999999418, 0.99...   \n",
       "7433  [0.9999994204, 0.9999994167, 0.9999994151, 0.9...   \n",
       "7434  [0.999997829, 0.9999994575, 0.9999977473, 0.99...   \n",
       "7435  [0.9999460363, 0.9999994047, 0.9999994132, 0.9...   \n",
       "\n",
       "                          extra_feat_atom_ave_loc_ion_E  ... NR-AhR  \\\n",
       "0     [17.74301941, 9.605406321, 9.562594876, 9.5598...  ...    NaN   \n",
       "1     [9.596681144, 9.596663915, 9.596663915, 93.340...  ...    0.0   \n",
       "2     [9.544216068, 9.544216068, 9.544216068, 9.5404...  ...    1.0   \n",
       "3     [9.564748614, 9.563678997, 9.582420779, 9.5963...  ...    0.0   \n",
       "4     [9.634017141, 9.627194883, 17.81962548, 9.7254...  ...    0.0   \n",
       "...                                                 ...  ...    ...   \n",
       "7431  [9.558765871, 9.530822629, 9.537826796, 9.5336...  ...    1.0   \n",
       "7432  [9.554152974, 9.554152974, 9.55711582, 9.55626...  ...    NaN   \n",
       "7433  [9.534232803, 9.531660645, 9.563305261, 9.5633...  ...    0.0   \n",
       "7434  [17.71803377, 9.675591171, 17.81342204, 9.6755...  ...    0.0   \n",
       "7435  [93.35583512, 9.580909278, 9.582890217, 9.5828...  ...    0.0   \n",
       "\n",
       "     NR-Aromatase NR-ER NR-ER-LBD NR-PPAR-gamma SR-ARE SR-ATAD5 SR-HSE SR-MMP  \\\n",
       "0             0.0   0.0       0.0           NaN    NaN      0.0    NaN    1.0   \n",
       "1             0.0   0.0       0.0           0.0    0.0      0.0    0.0    NaN   \n",
       "2             NaN   NaN       0.0           NaN    NaN      0.0    0.0    NaN   \n",
       "3             1.0   0.0       0.0           0.0    1.0      0.0    0.0    0.0   \n",
       "4             NaN   1.0       1.0           0.0    0.0      0.0    0.0    NaN   \n",
       "...           ...   ...       ...           ...    ...      ...    ...    ...   \n",
       "7431          0.0   0.0       0.0           0.0    0.0      0.0    0.0    0.0   \n",
       "7432          0.0   0.0       0.0           0.0    0.0      0.0    0.0    0.0   \n",
       "7433          0.0   0.0       0.0           0.0    0.0      0.0    0.0    0.0   \n",
       "7434          0.0   0.0       0.0           NaN    1.0      0.0    0.0    1.0   \n",
       "7435          1.0   NaN       NaN           0.0    NaN      0.0    1.0    NaN   \n",
       "\n",
       "     SR-p53  \n",
       "0       1.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "7431    0.0  \n",
       "7432    0.0  \n",
       "7433    0.0  \n",
       "7434    1.0  \n",
       "7435    NaN  \n",
       "\n",
       "[7436 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR-AR\n",
      "NR-AR\n",
      "0.0    6589\n",
      "1.0     301\n",
      "Name: count, dtype: int64\n",
      "NR-AR-LBD\n",
      "NR-AR-LBD\n",
      "0.0    6208\n",
      "1.0     226\n",
      "Name: count, dtype: int64\n",
      "NR-AhR\n",
      "NR-AhR\n",
      "0.0    5486\n",
      "1.0     748\n",
      "Name: count, dtype: int64\n",
      "NR-Aromatase\n",
      "NR-Aromatase\n",
      "0.0    5258\n",
      "1.0     273\n",
      "Name: count, dtype: int64\n",
      "NR-ER\n",
      "NR-ER\n",
      "0.0    5166\n",
      "1.0     757\n",
      "Name: count, dtype: int64\n",
      "NR-ER-LBD\n",
      "NR-ER-LBD\n",
      "0.0    6298\n",
      "1.0     321\n",
      "Name: count, dtype: int64\n",
      "NR-PPAR-gamma\n",
      "NR-PPAR-gamma\n",
      "0.0    5979\n",
      "1.0     162\n",
      "Name: count, dtype: int64\n",
      "SR-ARE\n",
      "SR-ARE\n",
      "0.0    4709\n",
      "1.0     879\n",
      "Name: count, dtype: int64\n",
      "SR-ATAD5\n",
      "SR-ATAD5\n",
      "0.0    6487\n",
      "1.0     248\n",
      "Name: count, dtype: int64\n",
      "SR-HSE\n",
      "SR-HSE\n",
      "0.0    5860\n",
      "1.0     325\n",
      "Name: count, dtype: int64\n",
      "SR-MMP\n",
      "SR-MMP\n",
      "0.0    4672\n",
      "1.0     866\n",
      "Name: count, dtype: int64\n",
      "SR-p53\n",
      "SR-p53\n",
      "0.0    6061\n",
      "1.0     390\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "full_set = [\n",
    "    \"NR-AR\",\n",
    "    \"NR-AR-LBD\",\n",
    "    \"NR-AhR\",\n",
    "    \"NR-Aromatase\",\n",
    "    \"NR-ER\",\n",
    "    \"NR-ER-LBD\",\n",
    "    \"NR-PPAR-gamma\",\n",
    "    \"SR-ARE\",\n",
    "    \"SR-ATAD5\",\n",
    "    \"SR-HSE\",\n",
    "    \"SR-MMP\",\n",
    "    \"SR-p53\",\n",
    "]\n",
    "\n",
    "labels_df = df[full_set]\n",
    "\n",
    "set_dict = {}\n",
    "for label in full_set:\n",
    "    list_set = list(set(labels_df[label].to_list()))\n",
    "    # remove nan\n",
    "    list_set = [x for x in list_set if str(x) != \"nan\"]\n",
    "    set_dict[label] = list_set\n",
    "\n",
    "# get counts of each label\n",
    "for label in full_set:\n",
    "    print(label)\n",
    "    print(labels_df[label].value_counts())\n",
    "# print(set_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7436/7436 [00:01<00:00, 6611.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'P', 'Ca', 'Cl', 'Ni', 'B', 'Se', 'Ge', 'O', 'C', 'Al', 'H', 'Br', 'Ti', 'Cr', 'N', 'Si', 'Zn', 'Na', 'As', 'Cu', 'V', 'S', 'Fe', 'F'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7436/7436 [00:22<00:00, 335.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_P', 'chemical_symbol_Ca', 'chemical_symbol_Cl', 'chemical_symbol_Ni', 'chemical_symbol_B', 'chemical_symbol_Se', 'chemical_symbol_Ge', 'chemical_symbol_O', 'chemical_symbol_C', 'chemical_symbol_Al', 'chemical_symbol_H', 'chemical_symbol_Br', 'chemical_symbol_Ti', 'chemical_symbol_Cr', 'chemical_symbol_N', 'chemical_symbol_Si', 'chemical_symbol_Zn', 'chemical_symbol_Na', 'chemical_symbol_As', 'chemical_symbol_Cu', 'chemical_symbol_V', 'chemical_symbol_S', 'chemical_symbol_Fe', 'chemical_symbol_F', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7436it [00:00, 17892.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > number of categories for each label: \n",
      "...... > label  NR-AR :  2 with distribution:  [7135, 301]\n",
      "...... > label  NR-AR-LBD :  2 with distribution:  [7210, 226]\n",
      "...... > label  NR-AhR :  2 with distribution:  [6688, 748]\n",
      "...... > label  NR-Aromatase :  2 with distribution:  [7163, 273]\n",
      "...... > label  NR-ER :  2 with distribution:  [6679, 757]\n",
      "...... > label  NR-ER-LBD :  2 with distribution:  [7115, 321]\n",
      "...... > label  NR-PPAR-gamma :  2 with distribution:  [7274, 162]\n",
      "...... > label  SR-ARE :  2 with distribution:  [6557, 879]\n",
      "...... > label  SR-ATAD5 :  2 with distribution:  [7188, 248]\n",
      "...... > label  SR-HSE :  2 with distribution:  [7111, 325]\n",
      "...... > label  SR-MMP :  2 with distribution:  [6570, 866]\n",
      "...... > label  SR-p53 :  2 with distribution:  [7046, 390]\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "number of graphs imputed:  4463\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [7.83398263e-01 2.46574854e-01 3.87910253e-02 6.14284505e-04\n",
      " 9.50318952e-03 1.82723611e-02 7.93624345e-03 2.46494672e-03\n",
      " 6.66342514e-04 2.60290044e-06 5.53376634e-03 5.20580089e-06\n",
      " 2.08232036e-05 1.30145022e-05 2.60290044e-06 5.18966291e-02\n",
      " 2.60256207e-01 1.56174027e-05 3.40139221e-01 9.73484766e-04\n",
      " 7.80870133e-06 1.04116018e-05 2.54433518e-02 2.44672642e-04\n",
      " 5.20580089e-06 5.20580089e-06 2.86319049e-05 5.20580089e-06\n",
      " 2.60290044e-06 4.34944664e-03 5.20580089e-06 3.51391560e-03\n",
      " 8.70652149e+00]\n",
      "std [6.29785791e-01 3.97069912e-01 1.59320891e-01 2.06255237e-02\n",
      " 8.06027197e-02 1.11047541e-01 7.37428019e-02 4.12613004e-02\n",
      " 2.14809084e-02 1.34320003e-03 6.16854276e-02 1.89956814e-03\n",
      " 3.79909348e-03 3.00346403e-03 1.34320003e-03 1.82424620e-01\n",
      " 3.35652444e-01 3.29012382e-03 3.46513857e-01 2.59580537e-02\n",
      " 2.32648197e-03 2.68638494e-03 1.30340414e-01 1.30205333e-02\n",
      " 1.89956814e-03 1.89956814e-03 4.45480689e-03 1.89956814e-03\n",
      " 1.34320003e-03 5.47347148e-02 1.89956814e-03 4.92271581e-02\n",
      " 5.79576701e+00]\n",
      "mean [0.00000000e+00 4.50542683e-02 7.07658664e-04 1.11523422e-02\n",
      " 2.13223229e-02 9.30406918e-03 3.00978875e-03 9.52775703e-01\n",
      " 6.34436039e-01]\n",
      "std [0.         0.17087818 0.02213619 0.08721147 0.11968653 0.07976543\n",
      " 0.04557596 0.37946125 0.27109543]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [3.46236463 3.29833277 5.46077513]\n",
      "std [0.53619094 0.59005241 0.50707055]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([7.8340e-01, 2.4657e-01, 3.8791e-02, 6.1428e-04, 9.5032e-03, 1.8272e-02,\n",
      "        7.9362e-03, 2.4649e-03, 6.6634e-04, 2.6029e-06, 5.5338e-03, 5.2058e-06,\n",
      "        2.0823e-05, 1.3015e-05, 2.6029e-06, 5.1897e-02, 2.6026e-01, 1.5617e-05,\n",
      "        3.4014e-01, 9.7348e-04, 7.8087e-06, 1.0412e-05, 2.5443e-02, 2.4467e-04,\n",
      "        5.2058e-06, 5.2058e-06, 2.8632e-05, 5.2058e-06, 2.6029e-06, 4.3494e-03,\n",
      "        5.2058e-06, 3.5139e-03, 8.7065e+00]), 'bond': tensor([0.0000e+00, 4.5054e-02, 7.0766e-04, 1.1152e-02, 2.1322e-02, 9.3041e-03,\n",
      "        3.0098e-03, 9.5278e-01, 6.3444e-01]), 'global': tensor([3.4624, 3.2983, 5.4608])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([6.2979e-01, 3.9707e-01, 1.5932e-01, 2.0626e-02, 8.0603e-02, 1.1105e-01,\n",
      "        7.3743e-02, 4.1261e-02, 2.1481e-02, 1.3432e-03, 6.1685e-02, 1.8996e-03,\n",
      "        3.7991e-03, 3.0035e-03, 1.3432e-03, 1.8242e-01, 3.3565e-01, 3.2901e-03,\n",
      "        3.4651e-01, 2.5958e-02, 2.3265e-03, 2.6864e-03, 1.3034e-01, 1.3021e-02,\n",
      "        1.8996e-03, 1.8996e-03, 4.4548e-03, 1.8996e-03, 1.3432e-03, 5.4735e-02,\n",
      "        1.8996e-03, 4.9227e-02, 5.7958e+00]), 'bond': tensor([0.0010, 0.1709, 0.0221, 0.0872, 0.1197, 0.0798, 0.0456, 0.3795, 0.2711]), 'global': tensor([0.5362, 0.5901, 0.5071])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_loc = \"../../../data/tox21_qtaim_1026_labelled.pkl\"\n",
    "classifier_dataset = HeteroGraphGraphLabelClassifierDataset(\n",
    "    file=dataset_loc,\n",
    "    standard_scale_features=True,\n",
    "    log_scale_features=True,\n",
    "    allowed_ring_size=[3, 4, 5, 6, 7],\n",
    "    allowed_charges=None,\n",
    "    self_loop=True,\n",
    "    debug=False,\n",
    "    extra_keys={\n",
    "        \"atom\": [\n",
    "            \"extra_feat_atom_esp_total\",\n",
    "        ],\n",
    "        \"bond\": [\n",
    "            \"extra_feat_bond_esp_total\",\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": [\n",
    "            \"NR-AR\",\n",
    "            \"NR-AR-LBD\",\n",
    "            \"NR-AhR\",\n",
    "            \"NR-Aromatase\",\n",
    "            \"NR-ER\",\n",
    "            \"NR-ER-LBD\",\n",
    "            \"NR-PPAR-gamma\",\n",
    "            \"SR-ARE\",\n",
    "            \"SR-ATAD5\",\n",
    "            \"SR-HSE\",\n",
    "            \"SR-MMP\",\n",
    "            \"SR-p53\",\n",
    "        ],\n",
    "    },\n",
    "    target_list=[\n",
    "        \"NR-AR\",\n",
    "        \"NR-AR-LBD\",\n",
    "        \"NR-AhR\",\n",
    "        \"NR-Aromatase\",\n",
    "        \"NR-ER\",\n",
    "        \"NR-ER-LBD\",\n",
    "        \"NR-PPAR-gamma\",\n",
    "        \"SR-ARE\",\n",
    "        \"SR-ATAD5\",\n",
    "        \"SR-HSE\",\n",
    "        \"SR-MMP\",\n",
    "        \"SR-p53\",\n",
    "    ],\n",
    "    extra_dataset_info={},\n",
    "    impute=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>config_settings<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n"
     ]
    }
   ],
   "source": [
    "import wandb, argparse, torch, json\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")  # might have to disable on older GPUs\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "\n",
    "\n",
    "on_gpu = bool(True)\n",
    "debug = bool(False)\n",
    "project_name = \"tox21_classifier_dev\"\n",
    "dataset_loc = \"../../../data/tox21_qtaim_1026_labelled.pkl\"\n",
    "log_save_dir = \"./tox21_dev/\"\n",
    "config = None\n",
    "if config is None:\n",
    "    config = get_default_graph_level_config()\n",
    "\n",
    "config[\"dataset\"][\"log_scale_features\"] = True\n",
    "config[\"dataset\"][\"debug\"] = False\n",
    "config[\"dataset\"][\"standard_scale_features\"] = True\n",
    "config[\"dataset\"][\"target_list\"] = [\n",
    "    \"NR-AR\",\n",
    "    \"NR-AR-LBD\",\n",
    "    \"NR-AhR\",\n",
    "    \"NR-Aromatase\",\n",
    "    \"NR-ER\",\n",
    "    \"NR-ER-LBD\",\n",
    "    \"NR-PPAR-gamma\",\n",
    "    \"SR-ARE\",\n",
    "    \"SR-ATAD5\",\n",
    "    \"SR-HSE\",\n",
    "    \"SR-MMP\",\n",
    "    \"SR-p53\",\n",
    "]\n",
    "config[\"dataset\"][\"train_batch_size\"] = 512\n",
    "config[\"dataset\"][\"extra_keys\"] = {\n",
    "    \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "    \"bond\": [\n",
    "        \"extra_feat_bond_esp_total\",\n",
    "        \"bond_length\",\n",
    "    ],\n",
    "    \"global\": [\n",
    "        \"NR-AR\",\n",
    "        \"NR-AR-LBD\",\n",
    "        \"NR-AhR\",\n",
    "        \"NR-Aromatase\",\n",
    "        \"NR-ER\",\n",
    "        \"NR-ER-LBD\",\n",
    "        \"NR-PPAR-gamma\",\n",
    "        \"SR-ARE\",\n",
    "        \"SR-ATAD5\",\n",
    "        \"SR-HSE\",\n",
    "        \"SR-MMP\",\n",
    "        \"SR-p53\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config[\"model\"] = {\n",
    "    \"n_conv_layers\": 4,\n",
    "    \"resid_n_graph_convs\": 1,\n",
    "    \"conv_fn\": \"GraphConvDropoutBatch\",\n",
    "    \"global_pooling_fn\": \"SumPoolingThenCat\",\n",
    "    \"dropout\": 0.2,\n",
    "    \"batch_norm\": True,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"bias\": True,\n",
    "    \"norm\": \"both\",\n",
    "    \"aggregate\": \"sum\",\n",
    "    \"lr\": 0.0002,\n",
    "    \"scheduler_name\": \"reduce_on_plateau\",\n",
    "    \"weight_decay\": 0.00001,\n",
    "    \"lr_plateau_patience\": 50,\n",
    "    \"lr_scale_factor\": 0.75,\n",
    "    \"loss_fn\": \"mse\",\n",
    "    \"embedding_size\": 50,\n",
    "    # \"fc_layer_size\": [256, 128],\n",
    "    \"shape_fc\": \"cone\",\n",
    "    \"fc_hidden_size_1\": 512,\n",
    "    \"fc_num_layers\": 1,\n",
    "    \"fc_dropout\": 0.2,\n",
    "    \"fc_batch_norm\": True,\n",
    "    \"lstm_iters\": 3,\n",
    "    \"lstm_layers\": 2,\n",
    "    \"output_dims\": 2,\n",
    "    \"pooling_ntypes\": [\"atom\", \"bond\", \"global\"],\n",
    "    \"pooling_ntypes_direct\": [\"global\"],\n",
    "    \"restore\": False,\n",
    "    \"max_epochs\": 10,\n",
    "}\n",
    "\n",
    "if config[\"optim\"][\"precision\"] == \"16\" or config[\"optim\"][\"precision\"] == \"32\":\n",
    "    config[\"optim\"][\"precision\"] = int(config[\"optim\"][\"precision\"])\n",
    "\n",
    "# set log save dir\n",
    "config[\"dataset\"][\"log_save_dir\"] = log_save_dir\n",
    "\n",
    "# dataset\n",
    "if dataset_loc is not None:\n",
    "    config[\"dataset\"][\"train_dataset_loc\"] = dataset_loc\n",
    "extra_keys = config[\"dataset\"][\"extra_keys\"]\n",
    "\n",
    "if debug:\n",
    "    config[\"dataset\"][\"debug\"] = debug\n",
    "print(\">\" * 40 + \"config_settings\" + \"<\" * 40)\n",
    "\n",
    "# for k, v in config.items():\n",
    "#    print(\"{}\\t\\t\\t{}\".format(str(k).ljust(20), str(v).ljust(20)))\n",
    "dm = QTAIMGraphTaskClassifyDataModule(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7436/7436 [00:01<00:00, 6888.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'V', 'C', 'P', 'Al', 'Ca', 'Zn', 'Ti', 'Na', 'Ge', 'O', 'B', 'As', 'Cl', 'S', 'Fe', 'Si', 'Ni', 'Cr', 'Cu', 'Br', 'F', 'H', 'N', 'Se'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7436/7436 [00:23<00:00, 320.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_V', 'chemical_symbol_C', 'chemical_symbol_P', 'chemical_symbol_Al', 'chemical_symbol_Ca', 'chemical_symbol_Zn', 'chemical_symbol_Ti', 'chemical_symbol_Na', 'chemical_symbol_Ge', 'chemical_symbol_O', 'chemical_symbol_B', 'chemical_symbol_As', 'chemical_symbol_Cl', 'chemical_symbol_S', 'chemical_symbol_Fe', 'chemical_symbol_Si', 'chemical_symbol_Ni', 'chemical_symbol_Cr', 'chemical_symbol_Cu', 'chemical_symbol_Br', 'chemical_symbol_F', 'chemical_symbol_H', 'chemical_symbol_N', 'chemical_symbol_Se', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7436it [00:00, 28740.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > number of categories for each label: \n",
      "...... > label  NR-AR :  2 with distribution:  [2914, 59]\n",
      "...... > label  NR-AR-LBD :  2 with distribution:  [2939, 34]\n",
      "...... > label  NR-AhR :  2 with distribution:  [2821, 152]\n",
      "...... > label  NR-Aromatase :  2 with distribution:  [2918, 55]\n",
      "...... > label  NR-ER :  2 with distribution:  [2742, 231]\n",
      "...... > label  NR-ER-LBD :  2 with distribution:  [2909, 64]\n",
      "...... > label  NR-PPAR-gamma :  2 with distribution:  [2948, 25]\n",
      "...... > label  SR-ARE :  2 with distribution:  [2787, 186]\n",
      "...... > label  SR-ATAD5 :  2 with distribution:  [2962, 11]\n",
      "...... > label  SR-HSE :  2 with distribution:  [2925, 48]\n",
      "...... > label  SR-MMP :  2 with distribution:  [2835, 138]\n",
      "...... > label  SR-p53 :  2 with distribution:  [2946, 27]\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "number of graphs filtered:  4463\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [7.46745535e-01 2.32889709e-01 4.08465865e-02 6.94208444e-04\n",
      " 9.92638280e-03 2.00362920e-02 7.82779866e-03 2.36190459e-03\n",
      " 0.00000000e+00 2.47114268e-01 6.14414370e-04 2.39382222e-05\n",
      " 0.00000000e+00 7.97940740e-06 0.00000000e+00 0.00000000e+00\n",
      " 7.97940740e-06 5.53850668e-02 4.78764444e-05 4.78764444e-05\n",
      " 5.37812059e-03 4.31685940e-03 7.97940740e-06 4.46846814e-04\n",
      " 0.00000000e+00 1.59588148e-05 7.97940740e-06 8.93693629e-04\n",
      " 2.83268963e-03 3.51532793e-01 2.44648631e-02 0.00000000e+00\n",
      " 8.50605893e+00]\n",
      "std [6.23622391e-01 3.90164733e-01 1.63230673e-01 2.19250245e-02\n",
      " 8.23523600e-02 1.16132021e-01 7.32430348e-02 4.03926840e-02\n",
      " 0.00000000e+00 3.31995628e-01 2.06277019e-02 4.07334485e-03\n",
      " 0.00000000e+00 2.35177382e-03 0.00000000e+00 0.00000000e+00\n",
      " 2.35177382e-03 1.87942803e-01 5.76048005e-03 5.76048005e-03\n",
      " 6.08186234e-02 5.45305754e-02 2.35177382e-03 1.75934914e-02\n",
      " 0.00000000e+00 3.32589128e-03 2.35177382e-03 2.48729277e-02\n",
      " 4.42204331e-02 3.46538108e-01 1.27903172e-01 0.00000000e+00\n",
      " 5.78410533e+00]\n",
      "Standard deviation for feature 8 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 12 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 14 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 15 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 24 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "Standard deviation for feature 31 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [0.00000000e+00 5.03213435e-02 8.43374472e-04 1.24179621e-02\n",
      " 2.48165362e-02 9.78120508e-03 3.07298515e-03 9.35661535e-01\n",
      " 6.48068695e-01]\n",
      "std [0.         0.17985511 0.02416343 0.09194166 0.12878529 0.08175661\n",
      " 0.04604984 0.38268947 0.2692539 ]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [3.28644665 3.07236252 5.25295031]\n",
      "std [0.49710084 0.5455226  0.46518589]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([7.4675e-01, 2.3289e-01, 4.0847e-02, 6.9421e-04, 9.9264e-03, 2.0036e-02,\n",
      "        7.8278e-03, 2.3619e-03, 0.0000e+00, 2.4711e-01, 6.1441e-04, 2.3938e-05,\n",
      "        0.0000e+00, 7.9794e-06, 0.0000e+00, 0.0000e+00, 7.9794e-06, 5.5385e-02,\n",
      "        4.7876e-05, 4.7876e-05, 5.3781e-03, 4.3169e-03, 7.9794e-06, 4.4685e-04,\n",
      "        0.0000e+00, 1.5959e-05, 7.9794e-06, 8.9369e-04, 2.8327e-03, 3.5153e-01,\n",
      "        2.4465e-02, 0.0000e+00, 8.5061e+00]), 'bond': tensor([0.0000e+00, 5.0321e-02, 8.4337e-04, 1.2418e-02, 2.4817e-02, 9.7812e-03,\n",
      "        3.0730e-03, 9.3566e-01, 6.4807e-01]), 'global': tensor([3.2864, 3.0724, 5.2530])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([6.2362e-01, 3.9016e-01, 1.6323e-01, 2.1925e-02, 8.2352e-02, 1.1613e-01,\n",
      "        7.3243e-02, 4.0393e-02, 1.0000e-03, 3.3200e-01, 2.0628e-02, 4.0733e-03,\n",
      "        1.0000e-03, 2.3518e-03, 1.0000e-03, 1.0000e-03, 2.3518e-03, 1.8794e-01,\n",
      "        5.7605e-03, 5.7605e-03, 6.0819e-02, 5.4531e-02, 2.3518e-03, 1.7593e-02,\n",
      "        1.0000e-03, 3.3259e-03, 2.3518e-03, 2.4873e-02, 4.4220e-02, 3.4654e-01,\n",
      "        1.2790e-01, 1.0000e-03, 5.7841e+00]), 'bond': tensor([0.0010, 0.1799, 0.0242, 0.0919, 0.1288, 0.0818, 0.0460, 0.3827, 0.2693]), 'global': tensor([0.4971, 0.5455, 0.4652])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "feature_names, feature_size = dm.prepare_data(stage=\"fit\")\n",
    "config[\"model\"][\"atom_feature_size\"] = feature_size[\"atom\"]\n",
    "config[\"model\"][\"bond_feature_size\"] = feature_size[\"bond\"]\n",
    "config[\"model\"][\"global_feature_size\"] = feature_size[\"global\"]\n",
    "config[\"model\"][\"target_dict\"] = {\"global\": config[\"dataset\"][\"target_list\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.full_dataset.target_dict[\"global\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > number of tasks: 12\n"
     ]
    }
   ],
   "source": [
    "from qtaim_embed.models.graph_level.base_gcn_classifier import GCNGraphPredClassifier\n",
    "\n",
    "\n",
    "def load_graph_level_model_from_config(config):\n",
    "    \"\"\"\n",
    "    returns model and optimizer from dict of parameters\n",
    "\n",
    "    Args:\n",
    "        dict_train(dict): dictionary\n",
    "    Returns:\n",
    "        model (pytorch model): model to train\n",
    "        optimizer (pytorch optimizer obj): optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    shape_fc = config[\"shape_fc\"]\n",
    "    base_fc = config[\"fc_hidden_size_1\"]\n",
    "\n",
    "    if shape_fc == \"flat\":\n",
    "        fc_layers = [base_fc for i in range(config[\"fc_num_layers\"])]\n",
    "    else:\n",
    "        fc_layers = [int(base_fc / (2**i)) for i in range(config[\"fc_num_layers\"])]\n",
    "\n",
    "    model = GCNGraphPredClassifier(\n",
    "        atom_input_size=config[\"atom_feature_size\"],\n",
    "        bond_input_size=config[\"bond_feature_size\"],\n",
    "        global_input_size=config[\"global_feature_size\"],\n",
    "        n_conv_layers=config[\"n_conv_layers\"],\n",
    "        resid_n_graph_convs=config[\"resid_n_graph_convs\"],\n",
    "        target_dict=config[\"target_dict\"],\n",
    "        conv_fn=config[\"conv_fn\"],\n",
    "        global_pooling=config[\"global_pooling_fn\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        batch_norm=config[\"batch_norm\"],\n",
    "        activation=config[\"activation\"],\n",
    "        bias=config[\"bias\"],\n",
    "        norm=config[\"norm\"],\n",
    "        aggregate=config[\"aggregate\"],\n",
    "        lr=config[\"lr\"],\n",
    "        scheduler_name=\"reduce_on_plateau\",\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        lr_plateau_patience=config[\"lr_plateau_patience\"],\n",
    "        lr_scale_factor=config[\"lr_scale_factor\"],\n",
    "        loss_fn=\"cross_entropy\",\n",
    "        embedding_size=config[\"embedding_size\"],\n",
    "        fc_layer_size=fc_layers,\n",
    "        fc_dropout=config[\"fc_dropout\"],\n",
    "        fc_batch_norm=config[\"fc_batch_norm\"],\n",
    "        lstm_iters=config[\"lstm_iters\"],\n",
    "        lstm_layers=config[\"lstm_layers\"],\n",
    "        output_dims=2,\n",
    "        pooling_ntypes=[\"atom\", \"bond\", \"global\"],\n",
    "        pooling_ntypes_direct=[\"global\"],\n",
    "    )\n",
    "    # model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_graph_level_model_from_config(config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': ['NR-AR',\n",
       "  'NR-AR-LBD',\n",
       "  'NR-AhR',\n",
       "  'NR-Aromatase',\n",
       "  'NR-ER',\n",
       "  'NR-ER-LBD',\n",
       "  'NR-PPAR-gamma',\n",
       "  'SR-ARE',\n",
       "  'SR-ATAD5',\n",
       "  'SR-HSE',\n",
       "  'SR-MMP',\n",
       "  'SR-p53']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"model\"][\"target_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=150, out_features=512, bias=True)\n",
       "  (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       "  (4): MultitaskLinearSoftmax(\n",
       "    (layers_dict): ModuleDict(\n",
       "      (0): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (7): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (8): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (9): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (10): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "      (11): ModuleList(\n",
       "        (0): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (1): Softmax(dim=1)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.ntasks\n",
    "model.fc_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torchmetrics.wrappers import MultioutputWrapper\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "auroc = torchmetrics.classification.AUROC(task=\"binary\")\n",
    "f1 = torchmetrics.F1Score(num_classes=2, task=\"binary\")\n",
    "accuracy = torchmetrics.Accuracy(num_classes=2, task=\"binary\")\n",
    "\n",
    "\n",
    "multi_auroc = torchmetrics.classification.MultilabelAUROC(num_labels=12)\n",
    "multi_acc = torchmetrics.classification.MultilabelAccuracy(\n",
    "    num_labels=12,\n",
    ")\n",
    "multi_f1 = torchmetrics.classification.MultilabelF1Score(num_labels=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.ntasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/core/module.py:419: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"def shared_step(model, batch):\n",
    "    batch_graph, batch_label = batch\n",
    "    labels = batch_label[\"global\"]\n",
    "    logits = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "    logits_one_hot = torch.argmax(logits, axis=-1)\n",
    "    # get argmax\n",
    "    labels_one_hot = torch.argmax(labels, axis=2)\n",
    "    if model.hparams.ntasks < 2:\n",
    "        labels_one_hot = labels_one_hot.reshape(-1)\n",
    "\n",
    "    all_loss = model.compute_loss(logits, labels_one_hot)\n",
    "\n",
    "    # log loss\n",
    "    print(all_loss)\n",
    "    auroc.update(target=labels_one_hot, preds=logits_one_hot)\n",
    "    f1.update(target=labels_one_hot, preds=logits_one_hot)\n",
    "    accuracy.update(target=labels_one_hot, preds=logits_one_hot)\n",
    "    # model.update_metrics(pred=logits, target=labels_one_hot, mode=mode)\n",
    "    return all_loss\"\"\"\n",
    "\n",
    "\n",
    "dataloader = dm.train_dataloader()\n",
    "for ind, batch in enumerate(dataloader):\n",
    "    print(ind)\n",
    "    # shared_step(model, batch)\n",
    "    model.shared_step(batch, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([183, 12])\n",
      "Epoch: 0 Loss: 42.16858673095703 \n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([183, 12])\n",
      "Epoch: 1 Loss: 42.17369842529297 \n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([183, 12])\n",
      "Epoch: 2 Loss: 42.218868255615234 \n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([183, 12])\n",
      "Epoch: 3 Loss: 42.24433135986328 \n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([183, 12])\n",
      "Epoch: 4 Loss: 42.25460433959961 \n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n",
      "torch.Size([512, 12])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m labels \u001b[39m=\u001b[39m batch_label[\u001b[39m\"\u001b[39m\u001b[39mglobal\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(labels.shape)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch_graph, batch_graph\u001b[39m.\u001b[39;49mndata[\u001b[39m\"\u001b[39;49m\u001b[39mfeat\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     13\u001b[0m \u001b[39m# print(\"label datatype {}\".format(labels.dtype))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m labels_one_hot \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(labels, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# multi\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/graph_level/base_gcn_classifier.py:387\u001b[0m, in \u001b[0;36mGCNGraphPredClassifier.forward\u001b[0;34m(self, graph, inputs)\u001b[0m\n\u001b[1;32m    384\u001b[0m feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(inputs)\n\u001b[1;32m    385\u001b[0m \u001b[39mfor\u001b[39;00m ind, conv \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layers):\n\u001b[1;32m    386\u001b[0m     \u001b[39m# print(\"conv layer\", ind)\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m     feats \u001b[39m=\u001b[39m conv(graph, feats)\n\u001b[1;32m    389\u001b[0m readout_feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreadout(graph, feats)\n\u001b[1;32m    390\u001b[0m \u001b[39mfor\u001b[39;00m ind, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_layers):\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/dgl/nn/pytorch/hetero.py:210\u001b[0m, in \u001b[0;36mHeteroGraphConv.forward\u001b[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[39mif\u001b[39;00m stype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m inputs:\n\u001b[1;32m    209\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m         dstdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module((stype, etype, dtype))(\n\u001b[1;32m    211\u001b[0m             rel_graph,\n\u001b[1;32m    212\u001b[0m             (inputs[stype], inputs[dtype]),\n\u001b[1;32m    213\u001b[0m             \u001b[39m*\u001b[39;49mmod_args\u001b[39m.\u001b[39;49mget(etype, ()),\n\u001b[1;32m    214\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmod_kwargs\u001b[39m.\u001b[39;49mget(etype, {})\n\u001b[1;32m    215\u001b[0m         )\n\u001b[1;32m    216\u001b[0m         outputs[dtype]\u001b[39m.\u001b[39mappend(dstdata)\n\u001b[1;32m    217\u001b[0m rsts \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/layers.py:90\u001b[0m, in \u001b[0;36mGraphConvDropoutBatch.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph, feat, weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, edge_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     89\u001b[0m     \u001b[39m# apply graph convolutional layer\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_conv(graph, feat, weight, edge_weight)\n\u001b[1;32m     91\u001b[0m     \u001b[39m# apply dropout to output features\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/dgl/nn/pytorch/conv/graphconv.py:460\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    458\u001b[0m     rst \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mdstdata[\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    459\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m         rst \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mmatmul(rst, weight)\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    463\u001b[0m     degs \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39min_degrees()\u001b[39m.\u001b[39mto(feat_dst)\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = dm.train_dataloader()\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "for epoch in range(100):\n",
    "    loss_val = 0\n",
    "    for ind, batch in enumerate(dataloader):\n",
    "        batch_graph, batch_label = batch\n",
    "        batch_size = batch_graph.batch_size\n",
    "        labels = batch_label[\"global\"]\n",
    "        # print(labels.shape)\n",
    "        out = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "        # print(\"label datatype {}\".format(labels.dtype))\n",
    "        labels_one_hot = torch.argmax(labels, axis=-1)  # multi\n",
    "        # labels_one_hot = torch.argmax(labels, axis=2).reshape(-1)\n",
    "        logits_one_hot = torch.argmax(out, axis=-1)\n",
    "        # labels_one_hot = labels_one_hot.reshape(model.hparams.ntasks, batch_size)\n",
    "        # print(labels.shape)\n",
    "        # print(out.shape)  # model.compute_loss(out, labels)\n",
    "        # print(labels_one_hot.shape)\n",
    "        # print(logits_one_hot.shape)\n",
    "        # loss = cross_entropy(out, labels)\n",
    "        loss_val += model.compute_loss(out, labels_one_hot)\n",
    "\n",
    "        multi_auroc.update(target=labels, preds=out)  # multi\n",
    "        multi_f1.update(target=labels, preds=out)  # multi\n",
    "        multi_acc.update(target=labels, preds=out)  # multi\n",
    "        # auroc.update(target=labels_one_hot, preds=logits_one_hot)\n",
    "        # f1.update(target=labels_one_hot, preds=logits_one_hot)\n",
    "        # accuracy.update(target=labels_one_hot, preds=logits_one_hot)\n",
    "        print(logits_one_hot.shape)\n",
    "        optimizer.step()\n",
    "\n",
    "    # acc = accuracy.compute()\n",
    "    # accuracy.reset()\n",
    "    # print(acc)\n",
    "    # f1_val = f1.compute()\n",
    "    # f1.reset()\n",
    "    # print(f1_val)\n",
    "    # auroc_val = auroc.compute()\n",
    "    # auroc.reset()\n",
    "    # print(auroc_val)\n",
    "    # print(loss_val)\n",
    "    if epoch % 1 == 0:\n",
    "        # print(\n",
    "        #    \"Epoch: {} Loss: {} Acc: {} AUROC: {} F1: {}\".format(\n",
    "        #        epoch, loss_val, acc.mean(), auroc_val.mean(), f1_val.mean()\n",
    "        #    )\n",
    "        # )\n",
    "        print(\"Epoch: {} Loss: {} \".format(epoch, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5556)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.functional.classification import multilabel_f1_score\n",
    "\n",
    "target = torch.tensor([[0, 1, 0], [1, 0, 1]])\n",
    "preds = torch.tensor([[0, 0, 1], [1, 0, 1]])\n",
    "print(preds.shape, target.shape)\n",
    "multilabel_f1_score(preds, target, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m out \u001b[39m=\u001b[39m model(batch_graph, batch_graph\u001b[39m.\u001b[39mndata[\u001b[39m\"\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     26\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, np\u001b[39m.\u001b[39margmax(labels, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 27\u001b[0m auroc\u001b[39m.\u001b[39;49mupdate(out, np\u001b[39m.\u001b[39;49margmax(labels, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     28\u001b[0m f1\u001b[39m.\u001b[39mupdate(out, np\u001b[39m.\u001b[39margmax(labels, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     29\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(out, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/wrappers/multioutput.py:132\u001b[0m, in \u001b[0;36mMultioutputWrapper.update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m reshaped_args_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_args_kwargs_by_output(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m metric, (selected_args, selected_kwargs) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, reshaped_args_kwargs):\n\u001b[0;32m--> 132\u001b[0m     metric\u001b[39m.\u001b[39;49mupdate(\u001b[39m*\u001b[39;49mselected_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mselected_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[1;32m    456\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m         update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    458\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    459\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/classification/precision_recall_curve.py:345\u001b[0m, in \u001b[0;36mMulticlassPrecisionRecallCurve.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update metric states.\"\"\"\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 345\u001b[0m     _multiclass_precision_recall_curve_tensor_validation(preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index)\n\u001b[1;32m    346\u001b[0m preds, target, _ \u001b[39m=\u001b[39m _multiclass_precision_recall_curve_format(\n\u001b[1;32m    347\u001b[0m     preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthresholds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index\n\u001b[1;32m    348\u001b[0m )\n\u001b[1;32m    349\u001b[0m state \u001b[39m=\u001b[39m _multiclass_precision_recall_curve_update(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthresholds)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/functional/classification/precision_recall_curve.py:399\u001b[0m, in \u001b[0;36m_multiclass_precision_recall_curve_tensor_validation\u001b[0;34m(preds, target, num_classes, ignore_index)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m preds\u001b[39m.\u001b[39mis_floating_point():\n\u001b[1;32m    398\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected `preds` to be a float tensor, but got \u001b[39m\u001b[39m{\u001b[39;00mpreds\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 399\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m!=\u001b[39m num_classes:\n\u001b[1;32m    400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected `preds.shape[1]` to be equal to the number of classes but\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m got \u001b[39m\u001b[39m{\u001b[39;00mpreds\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mnum_classes\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m target\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mor\u001b[39;00m preds\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:] \u001b[39m!=\u001b[39m target\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "# import accuracy\n",
    "import numpy as np\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# import softmax\n",
    "\n",
    "dataloader = dm.train_dataloader()\n",
    "correct_list = []\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    correct_count = 0\n",
    "    # iterate\n",
    "    for ind, batch in enumerate(dataloader):\n",
    "        # model.shared_step(batch, \"train\")\n",
    "\n",
    "        batch_graph, batch_label = batch\n",
    "        batch_size = batch_graph.batch_size\n",
    "        labels = batch_label[\"global\"]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "        loss = criterion(out, np.argmax(labels, axis=2).reshape(-1))\n",
    "        auroc.update(out, np.argmax(labels, axis=2).reshape(-1))\n",
    "        f1.update(out, np.argmax(labels, axis=2).reshape(-1))\n",
    "        out = torch.argmax(out, axis=1)\n",
    "        # accuracy = out == torch.argmax(labels, axis=2).reshape(-1)\n",
    "        # print(torch.sum(accuracy) / batch_size)\n",
    "        # correct_count += torch.sum(accuracy)\n",
    "        # count += batch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    auroc_epoch = auroc.compute()\n",
    "    f1_epoch = f1.compute()\n",
    "    auroc.reset()\n",
    "    f1.reset()\n",
    "\n",
    "    print(\n",
    "        f\"[{epoch + 1}] loss: {running_loss:.3f} auroc: {auroc_epoch:.3f} f1: {f1_epoch:.3f}\"\n",
    "    )\n",
    "    # accuracy = correct_count / count\n",
    "    # print(f\"[{epoch + 1}] loss: {running_loss:.3f} accuracy: {accuracy:.3f}\")\n",
    "    running_loss = 0.0\n",
    "    # print(out.shape, labels.shape)\n",
    "    # labels = np.argmax(labels, axis=2)\n",
    "    # print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m ind, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m---> 16\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mshared_step(batch, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch, loss))\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/graph_level/base_gcn_classifier.py:464\u001b[0m, in \u001b[0;36mGCNGraphPredClassifier.shared_step\u001b[0;34m(self, batch, mode)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39m# logits = logits.view(-1, self.hparams.output_dims)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# labels = labels.view(-1, self.hparams.output_dims)\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[1;32m    454\u001b[0m \u001b[39m# log loss\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\n\u001b[1;32m    456\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    457\u001b[0m     all_loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     sync_dist\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    463\u001b[0m )\n\u001b[0;32m--> 464\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_metrics(logits, labels, mode)\n\u001b[1;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m all_loss\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/graph_level/base_gcn_classifier.py:516\u001b[0m, in \u001b[0;36mGCNGraphPredClassifier.update_metrics\u001b[0;34m(self, pred, target, mode)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[39mUpdate metrics using torchmetrics interfaces\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_auroc\u001b[39m.\u001b[39;49mupdate(pred, target)\n\u001b[1;32m    517\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_f1\u001b[39m.\u001b[39mupdate(pred, target)\n\u001b[1;32m    519\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/wrappers/multioutput.py:130\u001b[0m, in \u001b[0;36mMultioutputWrapper.update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Update each underlying metric with the corresponding output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     reshaped_args_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_args_kwargs_by_output(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m metric, (selected_args, selected_kwargs) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, reshaped_args_kwargs):\n\u001b[1;32m    132\u001b[0m         metric\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39mselected_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mselected_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/wrappers/multioutput.py:110\u001b[0m, in \u001b[0;36mMultioutputWrapper._get_args_kwargs_by_output\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m args_kwargs_by_output \u001b[39m=\u001b[39m []\n\u001b[1;32m    109\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics)):\n\u001b[0;32m--> 110\u001b[0m     selected_args \u001b[39m=\u001b[39m apply_to_collection(\n\u001b[1;32m    111\u001b[0m         args, Tensor, torch\u001b[39m.\u001b[39;49mindex_select, dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_dim, index\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor(i, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     selected_kwargs \u001b[39m=\u001b[39m apply_to_collection(\n\u001b[1;32m    114\u001b[0m         kwargs, Tensor, torch\u001b[39m.\u001b[39mindex_select, dim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dim, index\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(i, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_nans:\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:80\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m out \u001b[39m=\u001b[39m []\n\u001b[1;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data:\n\u001b[0;32m---> 80\u001b[0m     v \u001b[39m=\u001b[39m apply_to_collection(\n\u001b[1;32m     81\u001b[0m         d,\n\u001b[1;32m     82\u001b[0m         dtype,\n\u001b[1;32m     83\u001b[0m         function,\n\u001b[1;32m     84\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m     85\u001b[0m         wrong_dtype\u001b[39m=\u001b[39;49mwrong_dtype,\n\u001b[1;32m     86\u001b[0m         include_none\u001b[39m=\u001b[39;49minclude_none,\n\u001b[1;32m     87\u001b[0m         allow_frozen\u001b[39m=\u001b[39;49mallow_frozen,\n\u001b[1;32m     88\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m include_none \u001b[39mor\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m         out\u001b[39m.\u001b[39mappend(v)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:51\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Breaking condition\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, dtype) \u001b[39mand\u001b[39;00m (wrong_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     53\u001b[0m elem_type \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(data)\n\u001b[1;32m     55\u001b[0m \u001b[39m# Recursively apply to collection items\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# import softmax\n",
    "\n",
    "dataloader = dm.train_dataloader()\n",
    "correct_list = []\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    correct_count = 0\n",
    "    # iterate\n",
    "    loss = 0.0\n",
    "    for ind, batch in enumerate(dataloader):\n",
    "        loss += model.shared_step(batch, \"train\")\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>config_settings<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "... > running in debug mode\n",
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 6220.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'Si', 'H', 'C', 'S', 'Cl', 'N', 'F', 'O', 'P', 'Br'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['NR-AR']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 350.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['NR-AR']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_Si', 'chemical_symbol_H', 'chemical_symbol_C', 'chemical_symbol_S', 'chemical_symbol_Cl', 'chemical_symbol_N', 'chemical_symbol_F', 'chemical_symbol_O', 'chemical_symbol_P', 'chemical_symbol_Br', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 32263.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > number of categories for each label: \n",
      "...... > label  NR-AR :  2\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "number of graphs filtered:  2\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [7.72802422e-01 2.49407062e-01 3.59204975e-02 5.92096113e-04\n",
      " 6.51305724e-03 1.87497102e-02 5.92096113e-03 4.14467279e-03\n",
      " 3.94730742e-04 3.43810476e-01 2.54798694e-01 4.14467279e-03\n",
      " 6.90778798e-03 2.05259986e-02 7.49988409e-03 5.32886501e-02\n",
      " 1.18419223e-03 5.92096113e-04 8.65353752e+00]\n",
      "std [0.63642293 0.40298627 0.15364866 0.02024992 0.06687367 0.11244891\n",
      " 0.06378903 0.05343866 0.01653634 0.34656258 0.33420147 0.05343866\n",
      " 0.06885054 0.11749988 0.07170966 0.18465426 0.02862546 0.02024992\n",
      " 5.79526049]\n",
      "mean [0.00000000e+00 4.23400249e-02 6.82903628e-04 7.96720899e-03\n",
      " 2.25358197e-02 6.82903628e-03 4.78032540e-03 9.56019622e-01\n",
      " 6.24117839e-01]\n",
      "std [0.         0.16599756 0.02174595 0.07388486 0.12293403 0.06846088\n",
      " 0.0573639  0.3912309  0.2821842 ]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [3.46121519 3.29351807 5.46860528]\n",
      "std [0.54716629 0.60049239 0.49787203]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([7.7280e-01, 2.4941e-01, 3.5920e-02, 5.9210e-04, 6.5131e-03, 1.8750e-02,\n",
      "        5.9210e-03, 4.1447e-03, 3.9473e-04, 3.4381e-01, 2.5480e-01, 4.1447e-03,\n",
      "        6.9078e-03, 2.0526e-02, 7.4999e-03, 5.3289e-02, 1.1842e-03, 5.9210e-04,\n",
      "        8.6535e+00]), 'bond': tensor([0.0000e+00, 4.2340e-02, 6.8290e-04, 7.9672e-03, 2.2536e-02, 6.8290e-03,\n",
      "        4.7803e-03, 9.5602e-01, 6.2412e-01]), 'global': tensor([3.4612, 3.2935, 5.4686])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([0.6364, 0.4030, 0.1536, 0.0202, 0.0669, 0.1124, 0.0638, 0.0534, 0.0165,\n",
      "        0.3466, 0.3342, 0.0534, 0.0689, 0.1175, 0.0717, 0.1847, 0.0286, 0.0202,\n",
      "        5.7953]), 'bond': tensor([0.0010, 0.1660, 0.0217, 0.0739, 0.1229, 0.0685, 0.0574, 0.3912, 0.2822]), 'global': tensor([0.5472, 0.6005, 0.4979])}\n",
      "... > loaded dataset\n",
      ":::CLASSIFIER MODEL:::\n",
      "... > number of tasks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/lightning_fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type              | Params\n",
      "---------------------------------------------------\n",
      "0  | embedding   | UnifySize         | 1.6 K \n",
      "1  | conv_layers | ModuleList        | 176 K \n",
      "2  | readout     | SumPoolingThenCat | 0     \n",
      "3  | fc_layers   | ModuleList        | 68.3 K\n",
      "4  | train_auroc | BinaryAUROC       | 0     \n",
      "5  | train_f1    | BinaryF1Score     | 0     \n",
      "6  | train_acc   | BinaryAccuracy    | 0     \n",
      "7  | val_auroc   | BinaryAUROC       | 0     \n",
      "8  | val_f1      | BinaryF1Score     | 0     \n",
      "9  | val_acc     | BinaryAccuracy    | 0     \n",
      "10 | test_auroc  | BinaryAUROC       | 0     \n",
      "11 | test_f1     | BinaryF1Score     | 0     \n",
      "12 | test_acc    | BinaryAccuracy    | 0     \n",
      "13 | loss        | CrossEntropyLoss  | 0     \n",
      "---------------------------------------------------\n",
      "245 K     Trainable params\n",
      "0         Non-trainable params\n",
      "245 K     Total params\n",
      "0.984     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model constructed!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df5b87b64354132862f3f7b05f9c595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d112b0010b44a790ab563f0761cb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a8422c4a5b42d2ba1e65fb417ba87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d944ca5bd0094b98b0b5b9a1268b1f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5311675d4634498ba1fd87a447d28500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4804cb3505a4cc99b126cad5d9f6627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80399a70e6744426b8098e77d6e0c804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4059986fb14a47689a5edc978870a1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5f342f2c0d45a8a97d8a207cf23607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50b5896c4cb46148656e44570031422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e72e48e7e24a6da6f7a09fae5c3bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a2172f01ad4f63baa352a3d99d873d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb5d3285545466cabc74fa19aec461c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d18372e430c4a77a28d5cc453f8f8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecdedbfe6064c74b63617303238b57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279b7bb58a8b4f19b9421f0fcceee94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db49743dcab455293482b9cb599ec7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43a3791f07f40a19f155f7de50baadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0721a7e4ed74c80b2becdb04d5bbd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10da802395f4091bb1a5bc76ba976a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8d60cfd87b44f5b152a1f83ee86c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e5c8e139144d89abf4eee7d72b5bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92462e97af54f859db9f84a743d7f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8232b227f77a4c21a195757298e0c3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e652b5a0b104321a80d70ba24830125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2f077635a44aeca3008ccfabb48b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9784f39384b1488e8d79a863080c68ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6675b10af9f54c72b137722cf8fe06d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237d79e5e24b44fea7fecd8a49707348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad439ef2c052483db44c0c6d21dcc253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028: reducing learning rate of group 0 to 1.2000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae947a048b5a4f1b82ec3ce52ada61fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387957b9d7854f91a8c45714aa3f41b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1a621ebc2747c28f2cd4f2744513ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d06cc180f74e6bac6847d906a35298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef742549a9c4175ad6daa1cbe9d63da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca3a33500c405b9db686ba3c6867ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50701bf1180a4e09ba162f5ee93d6048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3526e943e34445c9e9e9c9425f7e34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053027fce9844da7bb9d055a7e59bb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d75cc271a44448839ccf3143dd296e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9c452bcfe64792ab4c9766156c8cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d0fe434c68477daa36c55efee5bc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875bdeb8c47140b885bd15f9477a694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22f9137f4b2416d88f5615f934b9a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825a189d9d664ea5a37a8950c7325082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf5c77a88a94e34aebbe27b107eb318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1ab31e1dcf4768b03c7b3f32feba30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138d4842cc1743ea9c12167af8760242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834f46d89a434e4d8c68e206193bb430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d1eb71a55f42f9ba7a34fc81d7e217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed792f900b94433fba6067e05d2c0b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5db1d112f4844db8cb4f750ecd233a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17421c07222b41c49abb6cce7271a2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d33f7913a54d2b872f6c874de403df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959b009309754c5d85d01e201527716e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cb21faa4cf43baa3ccabe073700b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00054: reducing learning rate of group 0 to 7.2000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663fe76dec8742e9993c019b8d0c1534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b649ae9d22f418496cb7fa33bd84fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156913677b3b4a8bb73132af8b15fe3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c88011abce46378ddcfcad88aa6480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ff43598d934f0aa9595929378bf5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcdfab78eeb4b8eb0fb58c29d6eb3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b99434f0174458eaa31c04370e0754e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e916ba9d934486c9154ed15e525f3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9186017f724a039dd1e64a3f72836b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c99243285a4272b1456b8dd157aacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5386f7005da443d8a2d694641ebaf111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd068d58c6a7492faef1275bcce10eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285235c4451546d3b99260b06613301f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee5b42f3acc464b8cc5083f06e882de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96a7d990ea3457c87eb15acbe1e8e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7c8b1a84c141dc9ac413a3ef3ec7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f4c9bd237b46c89c4360eb9792a5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3008d43429924a869a55c53edcccc13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81674b784cf345f3ac46be644c24c46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39090bdb0ba44b5cacba9d4e404ec90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd2382e89f44fdaa8d8dc4465b63bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c174ff34a89b4b5590f5c31c5af79b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eab7ca48fb545f387750a181f1014f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370c18454b34988b91d46ea1343b3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b33c683e72b423a898676a16b895c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f1231a735a49c385091cb8798c075e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00080: reducing learning rate of group 0 to 4.3200e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef681b4c20b4bb1a51e08f4ff9f910b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac2848a56024a708cfabd1870cf606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22178c97841349fd8b212c5e2d371cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d041ed2b6c844f89b94e0185f0aa75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc4754609264f0f9959ca88acfe679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d470ab773dd4856a4184f52e8efe1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3784bd352a84547ba89021bd313f11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad30026b7da43359c8860d0c9646875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22fbbb954f34b849f7dbfc9cac4707e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabf127a2f5c40198e4044384393d95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba774c68ee2453983996dda2f4f418c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726826c6906f45808f12fe786e79fa94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f391a0ff54140b28aeab88b531acc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576a68f177c64d1884f80806822ed06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afcc494204f4becb94e9274e0b5507b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fb28b3a18245da9a19c38ef39102f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e539df1bfad46ed92d5ecbc31ca8107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce4388592b84abcbf51ae58d321f01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8e2d8b0a2c4aad8ed8838ad3ad1748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76faf5551da542cd84e55e40991384e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58323b31d994c4fab1c81f7c0f04c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.49357515573501587    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.49357515573501587   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.49357515573501587, 'test_f1': 0.0, 'test_auroc': 0.0}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb, argparse, torch, json\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from qtaim_embed.core.datamodule import QTAIMGraphTaskClassifyDataModule\n",
    "from qtaim_embed.models.utils import LogParameters, load_graph_level_model_from_config\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config_classif\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "\n",
    "\n",
    "debug = True\n",
    "dataset_loc = \"../../../data/tox21_qtaim_1026_labelled.pkl\"\n",
    "config = get_default_graph_level_config_classif()\n",
    "\n",
    "if config[\"optim\"][\"precision\"] == \"16\" or config[\"optim\"][\"precision\"] == \"32\":\n",
    "    config[\"optim\"][\"precision\"] = int(config[\"optim\"][\"precision\"])\n",
    "\n",
    "# set log save dir\n",
    "config[\"dataset\"][\"log_save_dir\"] = \"./test/\"\n",
    "\n",
    "# dataset\n",
    "if dataset_loc is not None:\n",
    "    config[\"dataset\"][\"train_dataset_loc\"] = dataset_loc\n",
    "extra_keys = config[\"dataset\"][\"extra_keys\"]\n",
    "\n",
    "if debug:\n",
    "    config[\"dataset\"][\"debug\"] = debug\n",
    "print(\">\" * 40 + \"config_settings\" + \"<\" * 40)\n",
    "\n",
    "\n",
    "dm = QTAIMGraphTaskClassifyDataModule(config=config)\n",
    "\n",
    "feature_names, feature_size = dm.prepare_data(stage=\"fit\")\n",
    "config[\"model\"][\"classifier\"] = True\n",
    "config[\"model\"][\"atom_feature_size\"] = feature_size[\"atom\"]\n",
    "config[\"model\"][\"bond_feature_size\"] = feature_size[\"bond\"]\n",
    "config[\"model\"][\"global_feature_size\"] = feature_size[\"global\"]\n",
    "config[\"model\"][\"target_dict\"][\"global\"] = config[\"dataset\"][\"target_list\"]\n",
    "config[\"model\"][\"lr\"] = 0.0002\n",
    "\n",
    "model = load_graph_level_model_from_config(config[\"model\"])\n",
    "print(\"model constructed!\")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    devices=1,\n",
    "    strategy=\"auto\",\n",
    "    enable_checkpointing=False,\n",
    "    default_root_dir=config[\"dataset\"][\"log_save_dir\"],\n",
    "    precision=16,\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
