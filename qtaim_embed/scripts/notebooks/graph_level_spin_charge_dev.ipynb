{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb, argparse, torch, json\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from qtaim_embed.models.utils import LogParameters, load_graph_level_model_from_config\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config\n",
    "from qtaim_embed.core.datamodule import QTAIMGraphTaskDataModule\n",
    "import pytorch_lightning as pl\n",
    "from qtaim_embed.core.dataset import HeteroGraphGraphLabelDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from qtaim_embed.models.graph_level.base_gcn import GCNGraphPred\n",
    "from qtaim_embed.utils.data import get_default_graph_level_config\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "from qtaim_embed.models.utils import load_graph_level_model_from_config\n",
    "from qtaim_embed.core.datamodule import QTAIMGraphTaskDataModule\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")  # might have to disable on older GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -12391.737598\n",
       "1        -9956.767902\n",
       "2       -16909.526727\n",
       "3        -9539.808335\n",
       "4        -7278.828211\n",
       "             ...     \n",
       "17152   -30509.130168\n",
       "17153    -8436.280139\n",
       "17154    -6406.817348\n",
       "17155    -9954.759794\n",
       "17156   -26718.224922\n",
       "Name: shifted_rrho_ev_free_energy, Length: 17157, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "libe_loc = \"../../../data/libe_qtaim_1029_labelled.pkl\"\n",
    "df = pd.read_pickle(libe_loc)\n",
    "df[\"shifted_rrho_ev_free_energy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_default_graph_level_config()\n",
    "on_gpu = bool(True)\n",
    "debug = bool(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17157/17157 [00:01<00:00, 13033.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'H', 'F', 'O', 'P', 'S', 'Li', 'N', 'C'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['shifted_rrho_ev_free_energy', 'charge', 'spin']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17157/17157 [00:26<00:00, 655.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['shifted_rrho_ev_free_energy']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_H', 'chemical_symbol_F', 'chemical_symbol_O', 'chemical_symbol_P', 'chemical_symbol_S', 'chemical_symbol_Li', 'chemical_symbol_N', 'chemical_symbol_C', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight', 'charge one hot', 'charge one hot', 'charge one hot', 'spin one hot', 'spin one hot', 'spin one hot']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17157/17157 [00:00<00:00, 34776.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [8.18990584e-01 1.22892184e-01 7.86921816e-02 6.38917142e-03\n",
      " 4.93583899e-02 1.25445927e-02 8.69699060e-03 1.70303698e-03\n",
      " 2.12144979e-01 4.27985438e-02 1.69057031e-01 1.17913977e-02\n",
      " 4.44496363e-03 4.64198163e-02 1.90339427e-03 2.04587057e-01\n",
      " 1.10351290e+01]\n",
      "std [0.52944732 0.31076984 0.21989271 0.06624058 0.1782593  0.09240066\n",
      " 0.07715346 0.03431552 0.31944045 0.16683517 0.29765941 0.08963335\n",
      " 0.05532862 0.17326559 0.03627271 0.31615357 5.02713615]\n",
      "mean [0.         0.09399185 0.00773844 0.05891471 0.01545498 0.01059545\n",
      " 0.00226983 0.85905631 0.74908361]\n",
      "std [0.         0.23730933 0.07282854 0.19330189 0.10234118 0.08504081\n",
      " 0.03960015 0.34912601 0.31340345]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [2.40839803 2.24223518 4.6358566  0.25197639 0.2367051  0.20446569\n",
      " 0.28817502 0.30688034 0.09809182]\n",
      "std [0.37237286 0.41590354 0.40973797 0.33341359 0.32869768 0.31609903\n",
      " 0.341618   0.34429304 0.24159897]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([8.1899e-01, 1.2289e-01, 7.8692e-02, 6.3892e-03, 4.9358e-02, 1.2545e-02,\n",
      "        8.6970e-03, 1.7030e-03, 2.1214e-01, 4.2799e-02, 1.6906e-01, 1.1791e-02,\n",
      "        4.4450e-03, 4.6420e-02, 1.9034e-03, 2.0459e-01, 1.1035e+01]), 'bond': tensor([0.0000, 0.0940, 0.0077, 0.0589, 0.0155, 0.0106, 0.0023, 0.8591, 0.7491]), 'global': tensor([2.4084, 2.2422, 4.6359, 0.2520, 0.2367, 0.2045, 0.2882, 0.3069, 0.0981])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([0.5294, 0.3108, 0.2199, 0.0662, 0.1783, 0.0924, 0.0772, 0.0343, 0.3194,\n",
      "        0.1668, 0.2977, 0.0896, 0.0553, 0.1733, 0.0363, 0.3162, 5.0271]), 'bond': tensor([0.0010, 0.2373, 0.0728, 0.1933, 0.1023, 0.0850, 0.0396, 0.3491, 0.3134]), 'global': tensor([0.3724, 0.4159, 0.4097, 0.3334, 0.3287, 0.3161, 0.3416, 0.3443, 0.2416])}\n",
      "... > Scaling targets\n",
      "mean [-13318.98637082]\n",
      "std [7300.17118105]\n",
      "... > Scaling targets complete\n",
      "... > feature mean(s): \n",
      " {'global': tensor([-13318.9863])}\n",
      "... > feature std(s):  \n",
      " {'global': tensor([7300.1714])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_loc = \"../../../data/libe_qtaim_1029_labelled.pkl\"\n",
    "log_save_dir = \"./libe_dev/\"\n",
    "\n",
    "config[\"dataset\"][\"log_scale_features\"] = True\n",
    "config[\"dataset\"][\"debug\"] = False\n",
    "config[\"dataset\"][\"standard_scale_features\"] = True\n",
    "config[\"dataset\"][\"target_list\"] = [\"shifted_rrho_ev_free_energy\"]\n",
    "config[\"dataset\"][\"train_batch_size\"] = 512\n",
    "config[\"dataset\"][\"allowed_charges\"] = [-1, 0, 1]\n",
    "config[\"dataset\"][\"allowed_spins\"] = [1, 2, 3]\n",
    "config[\"dataset\"][\"extra_keys\"] = {\n",
    "    \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "    \"bond\": [\n",
    "        \"extra_feat_bond_esp_total\",\n",
    "        \"bond_length\",\n",
    "    ],\n",
    "    \"global\": [\"shifted_rrho_ev_free_energy\", \"charge\", \"spin\"],\n",
    "}\n",
    "# set log save dir/\n",
    "config[\"dataset\"][\"log_save_dir\"] = log_save_dir\n",
    "# dataset\n",
    "if dataset_loc is not None:\n",
    "    config[\"dataset\"][\"train_dataset_loc\"] = dataset_loc\n",
    "extra_keys = config[\"dataset\"][\"extra_keys\"]\n",
    "if debug:\n",
    "    config[\"dataset\"][\"debug\"] = debug\n",
    "\n",
    "\n",
    "if config[\"optim\"][\"precision\"] == \"16\" or config[\"optim\"][\"precision\"] == \"32\":\n",
    "    config[\"optim\"][\"precision\"] = int(config[\"optim\"][\"precision\"])\n",
    "\n",
    "dm = QTAIMGraphTaskDataModule(config=config)\n",
    "feature_names, feature_size = dm.prepare_data(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>config_settings<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      ":::REGRESSION MODEL:::\n"
     ]
    }
   ],
   "source": [
    "config[\"model\"] = {\n",
    "    \"n_conv_layers\": 4,\n",
    "    \"resid_n_graph_convs\": 1,\n",
    "    \"conv_fn\": \"GraphConvDropoutBatch\",\n",
    "    \"global_pooling_fn\": \"SumPoolingThenCat\",\n",
    "    \"dropout\": 0.2,\n",
    "    \"batch_norm\": True,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"bias\": True,\n",
    "    \"norm\": \"both\",\n",
    "    \"aggregate\": \"sum\",\n",
    "    \"lr\": 0.0002,\n",
    "    \"scheduler_name\": \"reduce_on_plateau\",\n",
    "    \"weight_decay\": 0.00001,\n",
    "    \"lr_plateau_patience\": 50,\n",
    "    \"lr_scale_factor\": 0.75,\n",
    "    \"loss_fn\": \"mse\",\n",
    "    \"embedding_size\": 50,\n",
    "    \"shape_fc\": \"cone\",\n",
    "    \"fc_hidden_size_1\": 512,\n",
    "    \"fc_num_layers\": 1,\n",
    "    \"fc_dropout\": 0.2,\n",
    "    \"fc_batch_norm\": True,\n",
    "    \"lstm_iters\": 3,\n",
    "    \"lstm_layers\": 2,\n",
    "    \"output_dims\": 1,\n",
    "    \"pooling_ntypes\": [\"atom\", \"bond\", \"global\"],\n",
    "    \"pooling_ntypes_direct\": [\"global\"],\n",
    "    \"restore\": False,\n",
    "    \"max_epochs\": 10,\n",
    "    \"classifier\": False,\n",
    "    \"target_dict\": {},\n",
    "}\n",
    "\n",
    "\n",
    "print(\">\" * 40 + \"config_settings\" + \"<\" * 40)\n",
    "# for k, v in config.items():\n",
    "#    print(\"{}\\t\\t\\t{}\".format(str(k).ljust(20), str(v).ljust(20)))\n",
    "\n",
    "config[\"model\"][\"atom_feature_size\"] = feature_size[\"atom\"]\n",
    "config[\"model\"][\"bond_feature_size\"] = feature_size[\"bond\"]\n",
    "config[\"model\"][\"global_feature_size\"] = feature_size[\"global\"]\n",
    "config[\"model\"][\"target_dict\"][\"global\"] = config[\"dataset\"][\"target_list\"]\n",
    "model = load_graph_level_model_from_config(config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > running in debug mode\n",
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 11085.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > bond_feats_error_count:  0\n",
      "... > atom_feats_error_count:  0\n",
      "element set {'H', 'F', 'O', 'P', 'S', 'Li', 'N', 'C'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys ['shifted_rrho_ev_free_energy', 'charge']\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 656.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'global': ['shifted_rrho_ev_free_energy']}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_H', 'chemical_symbol_F', 'chemical_symbol_O', 'chemical_symbol_P', 'chemical_symbol_S', 'chemical_symbol_Li', 'chemical_symbol_N', 'chemical_symbol_C', 'extra_feat_atom_esp_total'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_total'], 'global': ['num atoms', 'num bonds', 'molecule weight', 'charge one hot', 'charge one hot', 'charge one hot']}\n",
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys([])\n",
      "include names:  dict_keys(['global'])\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 32135.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loader node types: dict_keys(['atom', 'bond', 'global'])\n",
      "original loader label types: dict_keys(['global'])\n",
      "... > Log scaling features\n",
      "... > Log scaling features complete\n",
      "... > Scaling features\n",
      "mean [8.34848989e-01 1.23115579e-01 9.71204306e-02 5.98687586e-03\n",
      " 5.92035501e-02 2.32822950e-02 3.99125057e-03 4.65645900e-03\n",
      " 2.04884196e-01 4.05777141e-02 1.72954191e-01 1.06433349e-02\n",
      " 3.32604214e-03 5.18862574e-02 1.99562529e-03 2.06879821e-01\n",
      " 1.10942913e+01]\n",
      "std [0.51957164 0.30872377 0.24059587 0.06414003 0.19373103 0.12488391\n",
      " 0.05244611 0.05662092 0.31628685 0.16272608 0.29994926 0.08522979\n",
      " 0.04789963 0.18240787 0.03713865 0.3171733  4.94329215]\n",
      "mean [0.         0.11384652 0.0069702  0.07125088 0.02710631 0.0046468\n",
      " 0.00542126 0.8582797  0.75317434]\n",
      "std [0.         0.25680998 0.0691577  0.21050098 0.13436485 0.05656254\n",
      " 0.06106016 0.34376201 0.31424738]\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "mean [2.36313864 2.20857913 4.57559107 0.25646446 0.22873857 0.20794415]\n",
      "std [0.38747485 0.43925042 0.47999846 0.33465445 0.32592662 0.31763994]\n",
      "... > Scaling features complete\n",
      "... > feature mean(s): \n",
      " {'atom': tensor([8.3485e-01, 1.2312e-01, 9.7120e-02, 5.9869e-03, 5.9204e-02, 2.3282e-02,\n",
      "        3.9913e-03, 4.6565e-03, 2.0488e-01, 4.0578e-02, 1.7295e-01, 1.0643e-02,\n",
      "        3.3260e-03, 5.1886e-02, 1.9956e-03, 2.0688e-01, 1.1094e+01]), 'bond': tensor([0.0000, 0.1138, 0.0070, 0.0713, 0.0271, 0.0046, 0.0054, 0.8583, 0.7532]), 'global': tensor([2.3631, 2.2086, 4.5756, 0.2565, 0.2287, 0.2079])}\n",
      "... > feature std(s):  \n",
      " {'atom': tensor([0.5196, 0.3087, 0.2406, 0.0641, 0.1937, 0.1249, 0.0524, 0.0566, 0.3163,\n",
      "        0.1627, 0.2999, 0.0852, 0.0479, 0.1824, 0.0371, 0.3172, 4.9433]), 'bond': tensor([0.0010, 0.2568, 0.0692, 0.2105, 0.1344, 0.0566, 0.0611, 0.3438, 0.3142]), 'global': tensor([0.3875, 0.4393, 0.4800, 0.3347, 0.3259, 0.3176])}\n",
      "... > Scaling targets\n",
      "mean [-12485.30132721]\n",
      "std [6707.04733157]\n",
      "... > Scaling targets complete\n",
      "... > feature mean(s): \n",
      " {'global': tensor([-12485.3018])}\n",
      "... > feature std(s):  \n",
      " {'global': tensor([6707.0474])}\n",
      "... > loaded dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "libe_loc = \"../../../data/libe_qtaim_1029_labelled.pkl\"\n",
    "full_dataset = HeteroGraphGraphLabelDataset(\n",
    "    file=libe_loc,\n",
    "    standard_scale_features=config[\"dataset\"][\"standard_scale_features\"],\n",
    "    log_scale_features=config[\"dataset\"][\"log_scale_features\"],\n",
    "    allowed_ring_size=config[\"dataset\"][\"allowed_ring_size\"],\n",
    "    allowed_charges=config[\"dataset\"][\"allowed_charges\"],\n",
    "    allowed_spins=config[\"dataset\"][\"allowed_spins\"],\n",
    "    self_loop=True,\n",
    "    debug=debug,\n",
    "    extra_keys=config[\"dataset\"][\"extra_keys\"],\n",
    "    target_list=config[\"dataset\"][\"target_list\"],\n",
    "    extra_dataset_info=config[\"dataset\"][\"extra_dataset_info\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name            | Type               | Params\n",
      "--------------------------------------------------------\n",
      "0  | embedding       | UnifySize          | 1.8 K \n",
      "1  | conv_layers     | ModuleList         | 95.4 K\n",
      "2  | readout         | SumPoolingThenCat  | 0     \n",
      "3  | loss            | MultioutputWrapper | 0     \n",
      "4  | fc_layers       | ModuleList         | 78.8 K\n",
      "5  | train_r2        | MultioutputWrapper | 0     \n",
      "6  | train_torch_l1  | MultioutputWrapper | 0     \n",
      "7  | train_torch_mse | MultioutputWrapper | 0     \n",
      "8  | val_r2          | MultioutputWrapper | 0     \n",
      "9  | val_torch_l1    | MultioutputWrapper | 0     \n",
      "10 | val_torch_mse   | MultioutputWrapper | 0     \n",
      "11 | test_r2         | MultioutputWrapper | 0     \n",
      "12 | test_torch_l1   | MultioutputWrapper | 0     \n",
      "13 | test_torch_mse  | MultioutputWrapper | 0     \n",
      "--------------------------------------------------------\n",
      "175 K     Trainable params\n",
      "0         Non-trainable params\n",
      "175 K     Total params\n",
      "0.704     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef4a82007914d45a701d603439bc9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a602c8ef64754a0b9e078b03775eef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dfc5b512b740cda3b9d96def3e5f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaff5733e7ca4767a18d229e653c7c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73307ff65dcf49018e826817bed26a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f58cb515dd4f6fba59cbaa32348f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9d4ba39bc84e6ea6fd6045202596db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c256f6c173d478cb92d8c09b2ac5192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6ee080ea7a40ad9019131a67b10556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227511504b49436d94d077b13d45561f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907c8ab0677549288e8511323303c0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffcdebc436c4c99b4f8850b25ffa0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# import softmax\n",
    "\n",
    "dataloader = dm.train_dataloader()\n",
    "correct_list = []\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    loss = 0.0\n",
    "    count = 0\n",
    "    correct_count = 0\n",
    "    # iterate\n",
    "    for ind, batch in enumerate(dm.train_dataloader()):\n",
    "        loss += model.shared_step(batch, \"train\")\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch, loss))\n",
    "    \"\"\"\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    gradient_clip_val=3.0,\n",
    "    default_root_dir=\"./test/\",\n",
    "    precision=\"32\",\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# trainer.fit(model, dm)\n",
    "from qtaim_embed.data.dataloader import DataLoaderMoleculeGraphTask\n",
    "\n",
    "data_loader_manual = DataLoaderMoleculeGraphTask(\n",
    "    dataset=full_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_3146907/312747333.py:27: UserWarning: Using a target size (torch.Size([75, 1])) that is different to the input size (torch.Size([75, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(logits, labels)\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.1493707299232483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 3.065988302230835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.5086823105812073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.5653993487358093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 1.0022978782653809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.6530622243881226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.16519446671009064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.23297515511512756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.3134811818599701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.28704142570495605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.20579640567302704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.16815496981143951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.21025310456752777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5e9ac922a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/multiprocessing/connection.py\", line 930, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/santiagovargas/anaconda3/envs/qtaim_embed/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.11412043124437332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.20004548132419586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.14991675317287445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.0520099513232708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.07179593294858932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.08888241648674011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.08803244680166245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.1588078737258911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.17506250739097595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.06662168353796005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.03884604200720787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.06486049294471741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.08747197687625885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.06181082874536514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.07576818764209747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.08073711395263672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.09973303973674774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.09223935753107071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.10336043685674667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.1202014908194542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.060065414756536484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.11973586678504944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.13905350863933563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.1161910891532898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.03109150566160679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.06885021179914474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.08317699283361435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.11143694818019867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.05883011594414711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.03514017537236214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.04997489973902702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.043268490582704544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.04349842295050621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.08937433362007141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.04116618633270264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.03423915058374405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.049261752516031265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# basic training loop\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "\n",
    "# move model to cpu\n",
    "model = model.cpu()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "dataloader = dm.train_dataloader()\n",
    "\n",
    "for epoch in range(10):\n",
    "    training_loss_list = []\n",
    "    with tqdm(dataloader) as tq:\n",
    "        model.train()\n",
    "        r2_list = []\n",
    "        tq.set_description(f\"Epoch {epoch+1}\")\n",
    "        training_loss = 0\n",
    "        for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "            # forward propagation by using all nodes and extracting the user embeddings\n",
    "            batch_graph, batch_label = next(iter(dataloader))\n",
    "            labels = batch_label[\"global\"]\n",
    "\n",
    "            logits = model.forward(batch_graph, batch_graph.ndata[\"feat\"])\n",
    "            loss = F.mse_loss(logits, labels)\n",
    "            training_loss_list.append(loss.item())\n",
    "            # loss_mae = F.l1_loss(logits, labels)\n",
    "            # compute r2 score\n",
    "            # r2 = r2_score(logits.detach().numpy(), labels.detach().numpy())\n",
    "            # r2_list.append(r2)\n",
    "            # Compute validation accuracy.  Omitted in this example.\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            training_loss += loss.item()\n",
    "            # tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\n",
    "\n",
    "        r2_mean = np.mean(r2_list)\n",
    "        loss = np.mean(training_loss_list)\n",
    "        tq.set_postfix({\"final_t_loss\": training_loss, \"R_2\": r2_mean})\n",
    "        print(r2_mean, loss)\n",
    "\n",
    "        # tq.update()\n",
    "        tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 2]' is invalid for input of size 75",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m labels \u001b[39m=\u001b[39m batch_label[\u001b[39m\"\u001b[39m\u001b[39mglobal\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, model\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39moutput_dims)\n\u001b[0;32m---> 29\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, model\u001b[39m.\u001b[39;49mhparams\u001b[39m.\u001b[39;49moutput_dims)\n\u001b[1;32m     30\u001b[0m all_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcompute_loss(logits, labels)\n\u001b[1;32m     32\u001b[0m training_loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 2]' is invalid for input of size 75"
     ]
    }
   ],
   "source": [
    "# basic training loop\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "\n",
    "# move model to cpu\n",
    "model = model.cpu()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "dataloader = dm.train_dataloader()\n",
    "\n",
    "for epoch in range(50):\n",
    "    training_loss_list = []\n",
    "    with tqdm(dataloader) as tq:\n",
    "        model.train()\n",
    "        r2_list = []\n",
    "        tq.set_description(f\"Epoch {epoch+1}\")\n",
    "        training_loss = 0\n",
    "        for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "            # loss = model.shared_step((batch_graph, batch_label), \"train\")\n",
    "\n",
    "            logits = model.forward(\n",
    "                batch_graph, batch_graph.ndata[\"feat\"]\n",
    "            )  # returns a dict of node types\n",
    "            labels = batch_label[\"global\"]\n",
    "            logits = logits.view(-1, model.hparams.output_dims)\n",
    "            labels = labels.view(-1, model.hparams.output_dims)\n",
    "            all_loss = model.compute_loss(logits, labels)\n",
    "\n",
    "            training_loss_list.append(loss.item())\n",
    "            # loss_mae = F.l1_loss(logits, labels)\n",
    "            # compute r2 score\n",
    "            # r2 = r2_score(logits.detach().numpy(), labels.detach().numpy())\n",
    "            # r2_list.append(r2)\n",
    "            # Compute validation accuracy.  Omitted in this example.\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            training_loss += loss.item()\n",
    "            # tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\n",
    "\n",
    "        r2_mean = np.mean(r2_list)\n",
    "        loss = np.mean(training_loss_list)\n",
    "        tq.set_postfix({\"final_t_loss\": training_loss, \"R_2\": r2_mean})\n",
    "        print(r2_mean, loss)\n",
    "\n",
    "        # tq.update()\n",
    "        tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.hparams.output_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoaderMoleculeGraphTask' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mnext\u001b[39;49m(dataloader)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoaderMoleculeGraphTask' object is not an iterator"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
