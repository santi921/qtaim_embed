{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "\n",
    "from qtaim_embed.utils.grapher import get_grapher\n",
    "from qtaim_embed.data.molwrapper import mol_wrappers_from_df\n",
    "from qtaim_embed.utils.tests import get_data\n",
    "from qtaim_embed.core.dataset import HeteroGraphNodeLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/home/santiagovargas/dev/qtaim_embed/data/qm8/molecules_full.pkl\"\n",
    "df = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21786/21786 [00:02<00:00, 10442.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element set {'O', 'N', 'C', 'H', 'F'}\n",
      "selected keys ['extra_feat_atom_esp_total']\n"
     ]
    }
   ],
   "source": [
    "atom_keys = [\n",
    "    \"extra_feat_atom_esp_total\",\n",
    "]\n",
    "bond_keys = [\n",
    "    \"extra_feat_bond_esp_total\",\n",
    "    \"extra_feat_bond_esp_nuc\",\n",
    "    \"bond_length\",\n",
    "]\n",
    "\n",
    "mol_wrappers, element_set = mol_wrappers_from_df(df, atom_keys, bond_keys)\n",
    "\n",
    "grapher = get_grapher(\n",
    "    element_set,\n",
    "    atom_keys=atom_keys,\n",
    "    bond_keys=bond_keys,\n",
    "    global_keys=[],\n",
    "    allowed_ring_size=[3, 4, 5, 6, 7],\n",
    "    allowed_charges=None,\n",
    "    self_loop=True,\n",
    ")\n",
    "\n",
    "graph_list = []\n",
    "print(\"... Building graphs and featurizing\")\n",
    "for mol in tqdm(mol_wrappers):\n",
    "    graph = grapher.build_graph(mol)\n",
    "    graph, names = grapher.featurize(graph, mol, ret_feat_names=True)\n",
    "    graph_list.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(graph_list[2].ndata[\"feat\"][\"atom\"].shape[0])\n",
    "print(graph_list[2].num_nodes(\"atom\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'atom': ['extra_feat_atom_esp_total'], 'bond': ['extra_feat_bond_esp_total'], 'global': []}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_O', 'chemical_symbol_N', 'chemical_symbol_C', 'chemical_symbol_H', 'chemical_symbol_F'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length', 'extra_feat_bond_esp_nuc'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "# TODO: build dataloader class\n",
    "\n",
    "\n",
    "target_dict = {\n",
    "    \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "    \"bond\": [\"extra_feat_bond_esp_total\"],\n",
    "}\n",
    "\n",
    "graph_list_temp = deepcopy(graph_list)\n",
    "extra_info = {\n",
    "    \"allowed_ring_size\": [3, 4, 5, 6, 7],\n",
    "    \"element_set\": element_set,\n",
    "}\n",
    "train_dataset = HeteroGraphNodeLabelDataset(\n",
    "    mol_wrappers,\n",
    "    graph_list_temp,\n",
    "    names,\n",
    "    target_dict=target_dict,\n",
    "    extra_dataset_info=extra_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': tensor([[4., 3., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [2., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [2., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [3., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]),\n",
       " 'bond': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.5053,\n",
       "          18.3283],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0900,\n",
       "          14.7121],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0936,\n",
       "          15.0641],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0939,\n",
       "          15.0222],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.2094,\n",
       "          23.0239],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.5246,\n",
       "          20.2331],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.2632,\n",
       "          21.9854],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.3693,\n",
       "          22.3534],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0227,\n",
       "          15.9521],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.3838,\n",
       "          21.3550],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1867,\n",
       "          21.9796],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0963,\n",
       "          17.0645]]),\n",
       " 'global': tensor([[ 13.0000,  12.0000, 115.0880]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata[\"feat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': tensor([[5.5136e+06],\n",
       "         [1.3306e+06],\n",
       "         [1.4497e+06],\n",
       "         [3.2892e+01],\n",
       "         [1.4663e+06],\n",
       "         [1.4663e+06],\n",
       "         [1.4497e+06],\n",
       "         [1.3306e+06],\n",
       "         [6.1929e+06],\n",
       "         [1.0323e+06],\n",
       "         [5.5136e+06],\n",
       "         [2.6634e+01],\n",
       "         [3.2892e+01]]),\n",
       " 'bond': tensor([[0.7334],\n",
       "         [0.8547],\n",
       "         [0.8573],\n",
       "         [0.8570],\n",
       "         [2.3834],\n",
       "         [0.7249],\n",
       "         [1.8967],\n",
       "         [1.7703],\n",
       "         [1.2688],\n",
       "         [1.6803],\n",
       "         [2.4584],\n",
       "         [0.8952]]),\n",
       " 'global': tensor([], size=(1, 0))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "\n",
    "\n",
    "class DataLoaderMoleculeNodeTask(DataLoader):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        if \"collate_fn\" in kwargs:\n",
    "            raise ValueError(\n",
    "                \"'collate_fn' provided internally by 'bondnet.data', you need not to \"\n",
    "                \"provide one\"\n",
    "            )\n",
    "\n",
    "        def collate(samples):\n",
    "            graphs = samples\n",
    "\n",
    "            count_label_atom = 0\n",
    "            for i in graphs:\n",
    "                count_label_atom = count_label_atom + i.ndata[\"labels\"][\"bond\"].shape[0]\n",
    "            batched_graphs = dgl.batch(graphs)\n",
    "            batched_labels = batched_graphs.ndata[\"labels\"]\n",
    "            return batched_graphs, batched_labels\n",
    "\n",
    "        super(DataLoaderMoleculeNodeTask, self).__init__(\n",
    "            dataset, collate_fn=collate, **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoaderMoleculeNodeTask(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_graph, batch_label = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 13])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([1, 3])\n",
      "14\n",
      "10\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(graph.ndata[\"feat\"][\"atom\"].shape)\n",
    "print(graph.ndata[\"feat\"][\"bond\"].shape)\n",
    "print(graph.ndata[\"feat\"][\"global\"].shape)\n",
    "print(len(grapher.atom_featurizer._feature_name))\n",
    "print(len(grapher.bond_featurizer._feature_name))\n",
    "print(len(grapher.global_featurizer._feature_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "atom_input_size = int(len(grapher.atom_featurizer._feature_name)) - 1\n",
    "bond_input_size = int(len(grapher.bond_featurizer._feature_name)) - 1\n",
    "global_input_size = 3\n",
    "conv = dglnn.HeteroGraphConv(\n",
    "    {\n",
    "        \"a2b\": dglnn.GraphConv(in_feats=atom_input_size, out_feats=bond_input_size),\n",
    "        \"b2a\": dglnn.GraphConv(in_feats=bond_input_size, out_feats=atom_input_size),\n",
    "        \"a2g\": dglnn.GraphConv(in_feats=atom_input_size, out_feats=global_input_size),\n",
    "        \"g2a\": dglnn.GraphConv(in_feats=global_input_size, out_feats=atom_input_size),\n",
    "        \"b2g\": dglnn.GraphConv(in_feats=bond_input_size, out_feats=global_input_size),\n",
    "        \"g2b\": dglnn.GraphConv(in_feats=global_input_size, out_feats=bond_input_size),\n",
    "        \"a2a\": dglnn.GraphConv(in_feats=atom_input_size, out_feats=atom_input_size),\n",
    "        \"b2b\": dglnn.GraphConv(in_feats=bond_input_size, out_feats=bond_input_size),\n",
    "        \"g2g\": dglnn.GraphConv(in_feats=global_input_size, out_feats=global_input_size),\n",
    "    },\n",
    "    aggregate=\"sum\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
