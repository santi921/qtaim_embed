{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "from tqdm import tqdm\n",
    "from qtaim_embed.utils.grapher import get_grapher\n",
    "from qtaim_embed.data.molwrapper import mol_wrappers_from_df\n",
    "from qtaim_embed.utils.tests import get_data\n",
    "from qtaim_embed.core.dataset import HeteroGraphNodeLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#import pymatgen\n",
    "#import pickle5 as pickle\n",
    "#with open(\"/home/santiagovargas/dev/qtaim_embed/data/xyz_qm8/molecules_qtaim.pkl\", \"rb\") as fh:\n",
    "#    df = pickle.load(fh)\n",
    "df = pd.read_pickle(\"/home/santiagovargas/dev/qtaim_embed/data/xyz_qm8/molecules_qtaim.pkl\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['molecule', 'molecule_graph', 'bonds', 'ids', 'names',\n",
       "       'extra_feat_atom_Lagrangian_K', 'extra_feat_atom_Hamiltonian_K',\n",
       "       'extra_feat_atom_e_density', 'extra_feat_atom_lap_e_density',\n",
       "       'extra_feat_atom_e_loc_func', 'extra_feat_atom_ave_loc_ion_E',\n",
       "       'extra_feat_atom_delta_g_promolecular', 'extra_feat_atom_delta_g_hirsh',\n",
       "       'extra_feat_atom_esp_nuc', 'extra_feat_atom_esp_e',\n",
       "       'extra_feat_atom_esp_total', 'extra_feat_atom_grad_norm',\n",
       "       'extra_feat_atom_lap_norm', 'extra_feat_atom_eig_hess',\n",
       "       'extra_feat_atom_det_hessian', 'extra_feat_atom_ellip_e_dens',\n",
       "       'extra_feat_atom_eta', 'extra_feat_bond_Lagrangian_K',\n",
       "       'extra_feat_bond_Hamiltonian_K', 'extra_feat_bond_e_density',\n",
       "       'extra_feat_bond_lap_e_density', 'extra_feat_bond_e_loc_func',\n",
       "       'extra_feat_bond_ave_loc_ion_E', 'extra_feat_bond_delta_g_promolecular',\n",
       "       'extra_feat_bond_delta_g_hirsh', 'extra_feat_bond_esp_nuc',\n",
       "       'extra_feat_bond_esp_e', 'extra_feat_bond_esp_total',\n",
       "       'extra_feat_bond_grad_norm', 'extra_feat_bond_lap_norm',\n",
       "       'extra_feat_bond_eig_hess', 'extra_feat_bond_det_hessian',\n",
       "       'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta',\n",
       "       'extra_feat_bond_indices_qtaim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > running in debug mode\n",
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3058.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element set {'N', 'O', 'C', 'H'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta', 'bond_length']\n",
      "selected global keys []\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 123.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'atom': ['extra_feat_atom_esp_total'], 'bond': ['extra_feat_bond_esp_total', 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta'], 'global': []}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_N', 'chemical_symbol_O', 'chemical_symbol_C', 'chemical_symbol_H'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3840.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > Scaling features\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "... > Scaling features complete\n",
      "... > mean: \n",
      " {'atom': tensor([2.0438, 0.5204, 0.2786, 0.0332, 0.0576, 0.0983, 0.0620, 0.0276, 0.0657,\n",
      "        0.0802, 0.3413, 0.5128]), 'bond': tensor([0.0000, 0.2825, 0.0349, 0.0637, 0.1011, 0.0662, 0.0300, 1.2698]), 'global': tensor([ 15.9700,  16.3200, 108.9015])}\n",
      "... > std:  \n",
      " {'atom': tensor([1.2534, 0.8735, 0.4483, 0.1791, 0.2330, 0.2977, 0.2411, 0.1637, 0.2478,\n",
      "        0.2715, 0.4741, 0.4998]), 'bond': tensor([0.0010, 0.4502, 0.1836, 0.2443, 0.3015, 0.2486, 0.1707, 0.2240]), 'global': tensor([2.6700, 2.8562, 6.5972])}\n",
      "... > Scaling targets\n",
      "... > Scaling targets complete\n",
      "... > mean: \n",
      " {'atom': tensor([2084470.5000]), 'bond': tensor([0.9842, 0.0764, 1.4701])}\n",
      "... > std:  \n",
      " {'atom': tensor([5203774.5000]), 'bond': tensor([0.4207, 0.1651, 0.4141])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HeteroGraphNodeLabelDataset(\n",
    "    #file=\"/home/santiagovargas/dev/qtaim_embed/data/xyz_qm8/molecules_full.pkl\",\n",
    "    file=\"/home/santiagovargas/dev/qtaim_embed/data/xyz_qm8/molecules_qtaim.pkl\",\n",
    "    allowed_ring_size=[3, 4, 5, 6, 7],\n",
    "    allowed_charges=None,\n",
    "    self_loop=True,\n",
    "    extra_keys={\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\n",
    "            \"extra_feat_bond_esp_total\",\n",
    "            'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta',\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": [],\n",
    "    },\n",
    "    target_dict={\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\"extra_feat_bond_esp_total\", 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta',],\n",
    "    },\n",
    "    extra_dataset_info={},\n",
    "    debug=True,\n",
    "    log_scale_targets=False,\n",
    "    standard_scale_targets=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': ['total_degree',\n",
       "  'total_H',\n",
       "  'is_in_ring',\n",
       "  'ring_size_3',\n",
       "  'ring_size_4',\n",
       "  'ring_size_5',\n",
       "  'ring_size_6',\n",
       "  'ring_size_7',\n",
       "  'chemical_symbol_N',\n",
       "  'chemical_symbol_O',\n",
       "  'chemical_symbol_C',\n",
       "  'chemical_symbol_H'],\n",
       " 'bond': ['metal bond',\n",
       "  'ring inclusion',\n",
       "  'ring size_3',\n",
       "  'ring size_4',\n",
       "  'ring size_5',\n",
       "  'ring size_6',\n",
       "  'ring size_7',\n",
       "  'bond_length'],\n",
       " 'global': ['num atoms', 'num bonds', 'molecule weight']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: build dataloader class\n",
    "from qtaim_embed.core.dataset import HeteroGraphNodeLabelDataset, Subset\n",
    "\n",
    "test_subset = Subset(train_dataset, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "test_subset.feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': 12, 'bond': 8, 'global': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dict = {}\n",
    "for key, value in test_subset.dataset.exclude_names.items():\n",
    "    len_dict[key] = len(value)\n",
    "len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qtaim_embed.data.dataloader import DataLoaderMoleculeNodeTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoaderMoleculeNodeTask(train_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_graph, batch_label = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 8 3\n"
     ]
    }
   ],
   "source": [
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "len_dict = train_dataset.featuze_size()\n",
    "atom_input_size = len_dict[\"atom\"]\n",
    "bond_input_size = len_dict[\"bond\"]\n",
    "global_input_size = len_dict[\"global\"]\n",
    "bond_output_size = 3\n",
    "print(atom_input_size, bond_input_size, global_input_size)\n",
    "\n",
    "from dgl import apply_each\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from qtaim_embed.models.layers import GraphConvDropoutBatch\n",
    "\n",
    "\n",
    "n_heads = 1\n",
    "hidden_feats = 64\n",
    "\n",
    "class testmodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"a2b\": GraphConvDropoutBatch(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"b2a\": GraphConvDropoutBatch(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"a2g\": GraphConvDropoutBatch(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"g2a\": GraphConvDropoutBatch(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"b2g\": GraphConvDropoutBatch(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"g2b\": GraphConvDropoutBatch(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"a2a\": GraphConvDropoutBatch(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"b2b\": GraphConvDropoutBatch(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "                \"g2g\": GraphConvDropoutBatch(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                    dropout=0.2\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "\n",
    "        self.conv2 = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"a2b\": GraphConvDropoutBatch(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=bond_output_size,\n",
    "                ),\n",
    "                \"b2a\": GraphConvDropoutBatch(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"a2g\": GraphConvDropoutBatch(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2a\": GraphConvDropoutBatch(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"b2g\": GraphConvDropoutBatch(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2b\": GraphConvDropoutBatch(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=bond_output_size,\n",
    "                ),\n",
    "                \"a2a\": GraphConvDropoutBatch(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"b2b\": GraphConvDropoutBatch(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=bond_output_size,\n",
    "                ),\n",
    "                \"g2g\": GraphConvDropoutBatch(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "        \"\"\"\n",
    "        # get max feature length \n",
    "        self.max_feature_len = max([atom_input_size, bond_input_size, global_input_size])\n",
    "        \n",
    "        self.conv3 = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"b2a\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len, \n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"g2a\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len, \n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"a2a\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len, \n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"g2b\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len,\n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"a2b\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len,\n",
    "                    out_feats=hidden_feats ,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"b2b\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len,\n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "\n",
    "                \"b2g\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len,\n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"g2g\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len,\n",
    "                    out_feats=hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"a2g\": dglnn.GATConv(\n",
    "                    in_feats=self.max_feature_len,\n",
    "                    out_feats= hidden_feats,\n",
    "                    num_heads = n_heads, \n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "\n",
    "        self.conv4 = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"b2a\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads, \n",
    "                    out_feats=atom_input_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"g2a\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads, \n",
    "                    out_feats=atom_input_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"a2a\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads, \n",
    "                    out_feats=atom_input_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"g2b\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads,\n",
    "                    out_feats=bond_output_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"a2b\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads,\n",
    "                    out_feats=bond_output_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"b2b\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads,\n",
    "                    out_feats=bond_output_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "\n",
    "                \"b2g\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads,\n",
    "                    out_feats=global_input_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"g2g\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads,\n",
    "                    out_feats=global_input_size,\n",
    "                    #aggregator_type=\"lstm\",\n",
    "                ),\n",
    "                \"a2g\": dglnn.GraphConv(\n",
    "                    in_feats=hidden_feats * n_heads,\n",
    "                    out_feats= global_input_size,\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "        \"\"\"\n",
    "    def forward(self, graph, inputs):\n",
    "\n",
    "        \"\"\"\n",
    "        # feats = self.conv(graph, inputs)\n",
    "        # feats = self.conv2(graph, feats)\n",
    "        #print(inputs.keys())\n",
    "        #for i in inputs.keys():\n",
    "        #    print(i)\n",
    "        #    print(inputs[i].shape)\n",
    "        # zero pad with typed linear to get max feature length for each feature \n",
    "        inputs = {k: F.pad(v, (0, self.max_feature_len - v.shape[1])) for k, v in inputs.items()}\n",
    "        feats = self.conv3(graph, inputs)\n",
    "        #print(\"pass\" * 30)\n",
    "        feats = {k: torch.reshape(F.relu(v), (v.shape[0], -1)) for k, v in feats.items()}\n",
    "        feats = self.conv4(graph, feats)\n",
    "        return feats\n",
    "        \"\"\"\n",
    "\n",
    "        #print(inputs)\n",
    "        feats = self.conv(graph, inputs)\n",
    "        #print(feats)\n",
    "        feats = self.conv2(graph, feats)\n",
    "        return feats\n",
    "\n",
    "\n",
    "\n",
    "model = testmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = batch_graph\n",
    "forward_out = model(graph, graph.ndata[\"feat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = batch_graph\n",
    "forward_out = model(graph, graph.ndata[\"feat\"])\n",
    "\n",
    "from qtaim_embed.models.node_level.base_gnn import GCNNodePred \n",
    "\n",
    "model_imported = GCNNodePred(\n",
    "    atom_input_size=atom_input_size,\n",
    "    bond_input_size=bond_input_size,\n",
    "    global_input_size=global_input_size,\n",
    "    n_conv_layers=2,\n",
    "    target_dict={\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\"extra_feat_bond_esp_total\", 'extra_feat_bond_ellip_e_dens', 'extra_feat_bond_eta',],\n",
    "    },\n",
    "    dropout=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1597x1 and 12x12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoaderMoleculeNodeTask(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m batch_graph, batch_label \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mforward(batch_graph, batch_label)\n",
      "\u001b[1;32m/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39m# feats = self.conv(graph, inputs)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=233'>234</a>\u001b[0m \u001b[39m# feats = self.conv2(graph, feats)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=244'>245</a>\u001b[0m \u001b[39mreturn feats\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=245'>246</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=247'>248</a>\u001b[0m \u001b[39m#print(inputs)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=248'>249</a>\u001b[0m feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(graph, inputs)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=249'>250</a>\u001b[0m \u001b[39m#print(feats)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X26sZmlsZQ%3D%3D?line=250'>251</a>\u001b[0m feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(graph, feats)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.9/site-packages/dgl/nn/pytorch/hetero.py:210\u001b[0m, in \u001b[0;36mHeteroGraphConv.forward\u001b[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[39mif\u001b[39;00m stype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m inputs:\n\u001b[1;32m    209\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m         dstdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module((stype, etype, dtype))(\n\u001b[1;32m    211\u001b[0m             rel_graph,\n\u001b[1;32m    212\u001b[0m             (inputs[stype], inputs[dtype]),\n\u001b[1;32m    213\u001b[0m             \u001b[39m*\u001b[39;49mmod_args\u001b[39m.\u001b[39;49mget(etype, ()),\n\u001b[1;32m    214\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmod_kwargs\u001b[39m.\u001b[39;49mget(etype, {})\n\u001b[1;32m    215\u001b[0m         )\n\u001b[1;32m    216\u001b[0m         outputs[dtype]\u001b[39m.\u001b[39mappend(dstdata)\n\u001b[1;32m    217\u001b[0m rsts \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/layers.py:46\u001b[0m, in \u001b[0;36mGraphConvDropoutBatch.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph, feat, weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, edge_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m     \n\u001b[1;32m     45\u001b[0m     \u001b[39m# apply graph convolutional layer\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_conv(graph, feat, weight, edge_weight)\n\u001b[1;32m     47\u001b[0m     \u001b[39m# apply dropout to output features  \u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.9/site-packages/dgl/nn/pytorch/conv/graphconv.py:460\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    458\u001b[0m     rst \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mdstdata[\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    459\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m         rst \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mmatmul(rst, weight)\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    463\u001b[0m     degs \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39min_degrees()\u001b[39m.\u001b[39mto(feat_dst)\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1597x1 and 12x12)"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoaderMoleculeNodeTask(train_dataset, batch_size=100, shuffle=True)\n",
    "batch_graph, batch_label = next(iter(dataloader))\n",
    "model.forward(batch_graph, batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m batch_graph, batch_label \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m labels \u001b[39m=\u001b[39m batch_label[target_type]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m logits \u001b[39m=\u001b[39m model_imported(batch_graph, batch_graph\u001b[39m.\u001b[39;49mndata[\u001b[39m\"\u001b[39;49m\u001b[39mfeat\u001b[39;49m\u001b[39m\"\u001b[39;49m])[target_type]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#print(logits.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#print(labels.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/santiagovargas/dev/qtaim_embed/qtaim_embed/scripts/notebooks/baseline_data_handling.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(logits, labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/node_level/base_gnn.py:233\u001b[0m, in \u001b[0;36mGCNNodePred.forward\u001b[0;34m(self, graph, inputs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[1;32m    232\u001b[0m         feats \u001b[39m=\u001b[39m conv(graph, feats)\n\u001b[0;32m--> 233\u001b[0m dictionary_targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_targets(inputs)\n\u001b[1;32m    234\u001b[0m \u001b[39m# flatten targets\u001b[39;00m\n\u001b[1;32m    235\u001b[0m targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\u001b[39mlist\u001b[39m(dictionary_targets\u001b[39m.\u001b[39mvalues()), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/dev/qtaim_embed/qtaim_embed/models/node_level/base_gnn.py:248\u001b[0m, in \u001b[0;36mGCNNodePred.get_targets\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m    246\u001b[0m targets \u001b[39m=\u001b[39m {}\n\u001b[1;32m    247\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_dict\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 248\u001b[0m     targets[k] \u001b[39m=\u001b[39m feats[k][v]\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    training_loss_list = []\n",
    "    with tqdm(dataloader) as tq:\n",
    "        model_imported.train()\n",
    "        r2_list = []\n",
    "        tq.set_description(f\"Epoch {epoch+1}\")\n",
    "        training_loss = 0\n",
    "        target_type = \"bond\"\n",
    "        for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "            # forward propagation by using all nodes and extracting the user embeddings\n",
    "            batch_graph, batch_label = next(iter(dataloader))\n",
    "            labels = batch_label[target_type]\n",
    "            logits = model_imported(batch_graph, batch_graph.ndata[\"feat\"])[target_type]\n",
    "            #print(logits.shape)\n",
    "            #print(labels.shape)\n",
    "            # compute loss\n",
    "            loss = F.mse_loss(logits, labels)\n",
    "            training_loss_list.append(loss.item())\n",
    "            # loss_mae = F.l1_loss(logits, labels)\n",
    "            # compute r2 score\n",
    "            r2 = r2_score(logits.detach().numpy(), labels.detach().numpy())\n",
    "            r2_list.append(r2)\n",
    "            # Compute validation accuracy.  Omitted in this example.\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            training_loss += loss.item()\n",
    "            # tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\n",
    "\n",
    "        r2_mean = np.mean(r2_list)\n",
    "        loss = np.mean(training_loss_list)\n",
    "        tq.set_postfix({\"final_t_loss\": training_loss, \"R_2\": r2_mean})\n",
    "        print(r2_mean, loss)\n",
    "\n",
    "        # tq.update()\n",
    "        tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7205302931984163 14.68019962310791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.9273690115274005 14.689446449279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.718336389191752 14.703181266784668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.780627066867511 14.21032428741455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7316928396393387 13.965476036071777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.457277128817072 13.535135269165039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 30.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.8366539567068187 14.601213455200195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 26.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.747202690314173 13.935641288757324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.9264098983236377 14.054888725280762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 27.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7085638304547572 13.922420501708984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.656725223457279 13.761919975280762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.633013457811136 13.758620262145996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.657660576856241 13.473957061767578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.4632583343516097 12.75365161895752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 29.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.4518971826937594 12.83767032623291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7413966232441367 13.785242080688477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.4143438067061944 12.265037536621094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 28.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5086722726556574 12.938258171081543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 26.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.367915942005236 13.06378173828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 26.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.4021242200252733 12.947981834411621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.5004966946170217 13.00985050201416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 29.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.384844404794242 13.28810977935791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.2244815688494857 12.474140167236328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 29.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.4690267312767773 12.989046096801758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 26.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.293178347443883 12.189672470092773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 23.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.944777341708965 12.390623092651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 27.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.2695326133095257 13.350651741027832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.14580230252143 13.373291015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.8243291473717504 11.924619674682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 30.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.725302388567427 12.089298248291016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.9819645963794534 13.01147747039795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 29.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.6896620456346993 12.334114074707031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 30.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.7278466857037436 12.893320083618164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 26.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.616202893829377 12.038164138793945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 26.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.6583123846388705 12.17487621307373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 28.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.606168197946101 12.371857643127441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 27.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4723748630432736 11.408025741577148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 23.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.5818821454983367 12.557168960571289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.654099973147433 13.04965591430664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4009333073236205 12.38421630859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.433594242284192 12.333194732666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.296300125466566 11.27975845336914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.21173228676126 11.798844337463379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 27.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.338361850020438 12.338628768920898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.377102747756087 12.205547332763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 27.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.3047446336976147 12.556431770324707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 30.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.3145441427097544 12.91015911102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 30.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.2101164541132303 11.880921363830566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 26.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.021475935807809 11.253496170043945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.181490068655195 12.423982620239258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "    training_loss_list = []\n",
    "    with tqdm(dataloader) as tq:\n",
    "        model.train()\n",
    "        r2_list = []\n",
    "        tq.set_description(f\"Epoch {epoch+1}\")\n",
    "        training_loss = 0\n",
    "        target_type = \"bond\"\n",
    "        for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "            # forward propagation by using all nodes and extracting the user embeddings\n",
    "            batch_graph, batch_label = next(iter(dataloader))\n",
    "            labels = batch_label[target_type]\n",
    "            logits = model(batch_graph, batch_graph.ndata[\"feat\"])[target_type]\n",
    "            #print(logits.shape)\n",
    "            #print(labels.shape)\n",
    "            # compute loss\n",
    "            loss = F.mse_loss(logits, labels)\n",
    "            training_loss_list.append(loss.item())\n",
    "            # loss_mae = F.l1_loss(logits, labels)\n",
    "            # compute r2 score\n",
    "            r2 = r2_score(logits.detach().numpy(), labels.detach().numpy())\n",
    "            r2_list.append(r2)\n",
    "            # Compute validation accuracy.  Omitted in this example.\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            training_loss += loss.item()\n",
    "            # tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\n",
    "\n",
    "        r2_mean = np.mean(r2_list)\n",
    "        loss = np.mean(training_loss_list)\n",
    "        tq.set_postfix({\"final_t_loss\": training_loss, \"R_2\": r2_mean})\n",
    "        print(r2_mean, loss)\n",
    "\n",
    "        # tq.update()\n",
    "        tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.51it/s]\n"
     ]
    }
   ],
   "source": [
    "label_list = []\n",
    "predictions_list = []\n",
    "\n",
    "with tqdm(dataloader) as tq, torch.no_grad():\n",
    "    for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "        batch_graph, batch_label = next(iter(dataloader))\n",
    "        labels = batch_label[target_type]\n",
    "        logits = model(batch_graph, batch_graph.ndata[\"feat\"])[target_type]\n",
    "        label_list.append(labels.cpu().numpy())\n",
    "        predictions_list.append(logits.cpu().numpy())\n",
    "\n",
    "\n",
    "cat_labels = np.concatenate(label_list)\n",
    "cat_preds = np.concatenate(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1632, 1)\n",
      "(1632, 1)\n"
     ]
    }
   ],
   "source": [
    "print(cat_labels.shape)\n",
    "print(cat_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8445300518290597\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(cat_labels[:,0], cat_preds[:,0])\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6478962999038074\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(cat_labels[:,1], cat_preds[:,1])\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43115008510261954\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(cat_labels[:,2], cat_preds[:,2])\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
