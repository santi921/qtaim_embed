{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "from tqdm import tqdm\n",
    "from qtaim_embed.utils.grapher import get_grapher\n",
    "from qtaim_embed.data.molwrapper import mol_wrappers_from_df\n",
    "from qtaim_embed.utils.tests import get_data\n",
    "from qtaim_embed.core.dataset import HeteroGraphNodeLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > creating MoleculeWrapper objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21786/21786 [00:02<00:00, 10888.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element set {'H', 'C', 'O', 'F', 'N'}\n",
      "selected atomic keys ['extra_feat_atom_esp_total']\n",
      "selected bond keys ['extra_feat_bond_esp_total', 'bond_length']\n",
      "selected global keys []\n",
      "... > Building graphs and featurizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21785/21785 [01:03<00:00, 344.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included in labels\n",
      "{'atom': ['extra_feat_atom_esp_total'], 'bond': ['extra_feat_bond_esp_total'], 'global': []}\n",
      "included in graph features\n",
      "{'atom': ['total_degree', 'total_H', 'is_in_ring', 'ring_size_3', 'ring_size_4', 'ring_size_5', 'ring_size_6', 'ring_size_7', 'chemical_symbol_H', 'chemical_symbol_C', 'chemical_symbol_O', 'chemical_symbol_F', 'chemical_symbol_N'], 'bond': ['metal bond', 'ring inclusion', 'ring size_3', 'ring size_4', 'ring size_5', 'ring size_6', 'ring size_7', 'bond_length'], 'global': ['num atoms', 'num bonds', 'molecule weight']}\n",
      "... > parsing labels and features in graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21785/21785 [00:05<00:00, 3676.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... > Scaling features\n",
      "Standard deviation for feature 0 is 0.0, smaller than 0.001. You may want to exclude this feature.\n",
      "... > Scaling features complete\n",
      "... > mean: \n",
      " {'atom': tensor([2.0525e+00, 5.2508e-01, 2.5562e-01, 5.0526e-02, 5.3274e-02, 9.2300e-02,\n",
      "        5.0783e-02, 8.7325e-03, 5.1693e-01, 3.4349e-01, 7.8644e-02, 1.4606e-03,\n",
      "        5.9473e-02]), 'bond': tensor([0.0000, 0.2584, 0.0523, 0.0571, 0.0956, 0.0543, 0.0101, 1.2687]), 'global': tensor([ 16.0904,  16.5128, 108.8643])}\n",
      "... > std:  \n",
      " {'atom': tensor([1.2716, 0.8735, 0.4362, 0.2190, 0.2246, 0.2894, 0.2196, 0.0930, 0.4997,\n",
      "        0.4749, 0.2692, 0.0382, 0.2365]), 'bond': tensor([0.0010, 0.4377, 0.2226, 0.2320, 0.2941, 0.2267, 0.1002, 0.2146]), 'global': tensor([2.9101, 3.1555, 8.0615])}\n",
      "... > Scaling targets\n",
      "... > Scaling targets complete\n",
      "... > mean: \n",
      " {'atom': tensor([2260655.2500]), 'bond': tensor([0.9732])}\n",
      "... > std:  \n",
      " {'atom': tensor([63750496.]), 'bond': tensor([0.4235])}\n",
      "... > loaded dataset\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HeteroGraphNodeLabelDataset(\n",
    "    # file=\"/home/santiagovargas/dev/qtaim_embed/data/qm8/molecules_full.pkl\",\n",
    "    file=\"/home/santiagovargas/dev/qtaim_generator/data/xyz_qm8/molecules_qtaim.pkl\",\n",
    "    allowed_ring_size=[3, 4, 5, 6, 7],\n",
    "    allowed_charges=None,\n",
    "    self_loop=True,\n",
    "    extra_keys={\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\n",
    "            \"extra_feat_bond_esp_total\",\n",
    "            \"bond_length\",\n",
    "        ],\n",
    "        \"global\": [],\n",
    "    },\n",
    "    target_dict={\n",
    "        \"atom\": [\"extra_feat_atom_esp_total\"],\n",
    "        \"bond\": [\"extra_feat_bond_esp_total\"],\n",
    "    },\n",
    "    extra_dataset_info={},\n",
    "    debug=False,\n",
    "    log_scale_targets=False,\n",
    "    standard_scale_targets=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': ['total_degree',\n",
       "  'total_H',\n",
       "  'is_in_ring',\n",
       "  'ring_size_3',\n",
       "  'ring_size_4',\n",
       "  'ring_size_5',\n",
       "  'ring_size_6',\n",
       "  'ring_size_7',\n",
       "  'chemical_symbol_H',\n",
       "  'chemical_symbol_C',\n",
       "  'chemical_symbol_O',\n",
       "  'chemical_symbol_F',\n",
       "  'chemical_symbol_N'],\n",
       " 'bond': ['metal bond',\n",
       "  'ring inclusion',\n",
       "  'ring size_3',\n",
       "  'ring size_4',\n",
       "  'ring size_5',\n",
       "  'ring size_6',\n",
       "  'ring size_7',\n",
       "  'bond_length'],\n",
       " 'global': ['num atoms', 'num bonds', 'molecule weight']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: build dataloader class\n",
    "from qtaim_embed.core.dataset import HeteroGraphNodeLabelDataset, Subset\n",
    "\n",
    "test_subset = Subset(train_dataset, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "test_subset.feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': 13, 'bond': 8, 'global': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dict = {}\n",
    "for key, value in test_subset.dataset.exclude_names.items():\n",
    "    len_dict[key] = len(value)\n",
    "len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "\n",
    "\n",
    "class DataLoaderMoleculeNodeTask(DataLoader):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        if \"collate_fn\" in kwargs:\n",
    "            raise ValueError(\n",
    "                \"'collate_fn' provided internally by 'bondnet.data', you need not to \"\n",
    "                \"provide one\"\n",
    "            )\n",
    "\n",
    "        def collate(samples):\n",
    "            graphs = samples\n",
    "\n",
    "            # count_label_atom = 0\n",
    "            # for i in graphs:\n",
    "            #    count_label_atom = count_label_atom + i.ndata[\"labels\"][\"bond\"].shape[0]\n",
    "            batched_graphs = dgl.batch(graphs)\n",
    "            batched_labels = batched_graphs.ndata[\"labels\"]\n",
    "            return batched_graphs, batched_labels\n",
    "\n",
    "        super(DataLoaderMoleculeNodeTask, self).__init__(\n",
    "            dataset, collate_fn=collate, **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoaderMoleculeNodeTask(train_dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_graph, batch_label = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 8 3\n"
     ]
    }
   ],
   "source": [
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "len_dict = train_dataset.featuze_size()\n",
    "atom_input_size = len_dict[\"atom\"]\n",
    "bond_input_size = len_dict[\"bond\"]\n",
    "global_input_size = len_dict[\"global\"]\n",
    "\n",
    "print(atom_input_size, bond_input_size, global_input_size)\n",
    "\n",
    "\n",
    "class testmodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        self.conv = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"a2b\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                ),\n",
    "                \"b2a\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"a2g\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2a\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"b2g\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2b\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                ),\n",
    "                \"a2a\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"b2b\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                ),\n",
    "                \"g2g\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "        \n",
    "        self.conv2 = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"a2b\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                ),\n",
    "                \"b2a\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"a2g\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2a\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"b2g\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2b\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                ),\n",
    "                \"a2a\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=atom_input_size,\n",
    "                ),\n",
    "                \"b2b\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=bond_input_size,\n",
    "                ),\n",
    "                \"g2g\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "        \"\"\"\n",
    "        self.conv3 = dglnn.HeteroGraphConv(\n",
    "            {\n",
    "                \"b2a\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size, out_feats=atom_input_size\n",
    "                ),\n",
    "                \"g2a\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size, out_feats=atom_input_size\n",
    "                ),\n",
    "                \"a2a\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size, out_feats=atom_input_size\n",
    "                ),\n",
    "                \"b2b\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=1,\n",
    "                ),\n",
    "                \"g2g\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"b2g\": dglnn.GraphConv(\n",
    "                    in_feats=bond_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "                \"g2b\": dglnn.GraphConv(\n",
    "                    in_feats=global_input_size,\n",
    "                    out_feats=1,\n",
    "                ),\n",
    "                \"a2b\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=1,\n",
    "                ),\n",
    "                \"a2g\": dglnn.GraphConv(\n",
    "                    in_feats=atom_input_size,\n",
    "                    out_feats=global_input_size,\n",
    "                ),\n",
    "            },\n",
    "            aggregate=\"sum\",\n",
    "        )\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # feats = self.conv(graph, inputs)\n",
    "        # feats = self.conv2(graph, feats)\n",
    "        feats = self.conv3(graph, inputs)\n",
    "        return feats\n",
    "\n",
    "\n",
    "testmodel = testmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_out = testmodel(graph, graph.ndata[\"feat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1090/1090 [00:05<00:00, 185.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7427236132021471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1090/1090 [00:05<00:00, 186.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853391413574738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1090/1090 [00:05<00:00, 186.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8561014642033615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1090/1090 [00:05<00:00, 184.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964085067857632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1090/1090 [00:05<00:00, 187.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8648924246156215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1090/1090 [00:05<00:00, 184.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8560766812986726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1090/1090 [00:05<00:00, 186.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7489454548787985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1090/1090 [00:05<00:00, 186.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7221625750138655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1090/1090 [00:05<00:00, 185.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8042726870907742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1090/1090 [00:05<00:00, 182.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696785244373213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1090/1090 [00:05<00:00, 184.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8590227890760046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1090/1090 [00:05<00:00, 186.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8557021661209665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1090/1090 [00:05<00:00, 184.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7939983025859828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1090/1090 [00:05<00:00, 185.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749473668718486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1090/1090 [00:05<00:00, 190.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7289840153706296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1090/1090 [00:05<00:00, 190.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8167637425104097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1090/1090 [00:05<00:00, 190.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8082830181251383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1090/1090 [00:05<00:00, 191.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8017221977719801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1090/1090 [00:05<00:00, 189.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8601777549926136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 1090/1090 [00:05<00:00, 189.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666194436998685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1090/1090 [00:05<00:00, 190.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8073748379334775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 1090/1090 [00:05<00:00, 181.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8186835782749826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1090/1090 [00:05<00:00, 184.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8467949922671845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1090/1090 [00:05<00:00, 189.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8724163208836805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25:  50%|█████     | 546/1090 [00:02<00:02, 189.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     33\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m opt\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     35\u001b[0m training_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     36\u001b[0m \u001b[39m# tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/optim/adam.py:262\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39m# Respect when the user inputs False/True for foreach or fused. We only want to change\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# the default when neither have been user-specified. Note that we default to foreach\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# and pass False to use_fused. This is not a mistake--we want to give the fused impl\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m# bake-in time before making it the default, even if it is typically faster.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m fused \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m foreach \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     _, foreach \u001b[39m=\u001b[39m _default_to_fused_or_foreach(params, differentiable, use_fused\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m fused \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     fused \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/qtaim_embed/lib/python3.11/site-packages/torch/optim/optimizer.py:72\u001b[0m, in \u001b[0;36m_default_to_fused_or_foreach\u001b[0;34m(params, differentiable, use_fused)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     69\u001b[0m fused \u001b[39m=\u001b[39m use_fused \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m     70\u001b[0m     p \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39mtype\u001b[39m(p) \u001b[39min\u001b[39;00m _foreach_supported_types \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mis_cuda \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mis_floating_point(p)) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params\n\u001b[1;32m     71\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m foreach \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m fused \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m     73\u001b[0m     p \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39mtype\u001b[39m(p) \u001b[39min\u001b[39;00m _foreach_supported_types \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mis_cuda) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m fused, foreach\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "opt = torch.optim.Adam(testmodel.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "    with tqdm(dataloader) as tq:\n",
    "        testmodel.train()\n",
    "        r2_list = []\n",
    "        tq.set_description(f\"Epoch {epoch+1}\")\n",
    "        training_loss = 0\n",
    "        target_type = \"bond\"\n",
    "        for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "            # forward propagation by using all nodes and extracting the user embeddings\n",
    "            batch_graph, batch_label = next(iter(dataloader))\n",
    "            labels = batch_label[target_type]\n",
    "            logits = testmodel(batch_graph, batch_graph.ndata[\"feat\"])[target_type]\n",
    "            # print(logits.shape)\n",
    "            # print(labels.shape)\n",
    "            # compute loss\n",
    "            loss = F.mse_loss(logits, labels)\n",
    "            # loss_mae = F.l1_loss(logits, labels)\n",
    "            # compute r2 score\n",
    "            r2 = r2_score(logits.detach().numpy(), labels.detach().numpy())\n",
    "            r2_list.append(r2)\n",
    "            # Compute validation accuracy.  Omitted in this example.\n",
    "            # backward propagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            training_loss += loss.item()\n",
    "            # tq.set_postfix({\"Step\": step, \"MSE\": loss.item()})\n",
    "\n",
    "        r2_mean = np.mean(r2_list)\n",
    "        tq.set_postfix({\"final_t_loss\": training_loss, \"R_2\": r2_mean})\n",
    "        print(r2_mean)\n",
    "\n",
    "        # tq.update()\n",
    "        tq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090/1090 [00:04<00:00, 223.05it/s]\n"
     ]
    }
   ],
   "source": [
    "label_list = []\n",
    "predictions_list = []\n",
    "\n",
    "with tqdm(dataloader) as tq, torch.no_grad():\n",
    "    for step, (batch_graph, batch_label) in enumerate(tq):\n",
    "        batch_graph, batch_label = next(iter(dataloader))\n",
    "        labels = batch_label[target_type]\n",
    "        logits = testmodel(batch_graph, batch_graph.ndata[\"feat\"])[target_type]\n",
    "        label_list.append(labels.cpu().numpy())\n",
    "        predictions_list.append(logits.cpu().numpy())\n",
    "\n",
    "\n",
    "cat_labels = np.concatenate(label_list)\n",
    "cat_preds = np.concatenate(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360755, 1)\n",
      "(360755, 1)\n"
     ]
    }
   ],
   "source": [
    "print(cat_labels.shape)\n",
    "print(cat_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7884027468940493\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(cat_labels, cat_preds)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtaim_embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
